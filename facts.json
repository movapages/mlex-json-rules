[
  {
    "title": "A List of AI and ML Terms",
    "body": "Here’s an extensive list of terms related to modern AI, ML, deep learning, computer vision, and related fields:\n\n| **Term**                           | **Definition**                                                                                                          |\n|------------------------------------|----------------------------------------------------------------------------------------------------------------------|\n| **Algorithm**                      | A set of rules or instructions for solving a problem or performing a task.                                            |\n| **Artificial Intelligence (AI)**   | The simulation of human intelligence in machines that are programmed to think and learn.                              |\n| **Machine Learning (ML)**          | A subset of AI where computers use algorithms to learn from data and improve their performance over time.              |\n| **Deep Learning**                  | A subset of ML involving neural networks with many layers to learn complex patterns in large datasets.                 |\n| **Neural Network**                 | A computational model inspired by the human brain, consisting of interconnected nodes (neurons).                        |\n| **Supervised Learning**            | ML where the model is trained on labeled data, learning the relationship between inputs and outputs.                    |\n| **Unsupervised Learning**          | ML where the model learns patterns and structures from unlabeled data.                                                  |\n| **Reinforcement Learning**         | ML where an agent learns to make decisions by receiving rewards or penalties.                                           |\n| **Regression**                     | A type of supervised learning used to predict continuous values.                                                        |\n| **Classification**                 | A type of supervised learning used to categorize data into predefined classes.                                         |\n| **Clustering**                     | An unsupervised learning technique for grouping similar data points together.                                           |\n| **Dimensionality Reduction**       | Techniques for reducing the number of features in a dataset while retaining important information.                    |\n| **Feature Engineering**            | The process of creating or modifying features to improve model performance.                                            |\n| **Overfitting**                    | When a model learns the training data too well and performs poorly on new, unseen data.                                |\n| **Underfitting**                   | When a model is too simple to capture the underlying patterns in the data.                                              |\n| **Cross-Validation**               | A technique for assessing how the results of a model will generalize to an independent dataset by splitting data into subsets. |\n| **Hyperparameter**                 | Settings for a learning algorithm that are set before the training process begins.                                      |\n| **Gradient Descent**               | An optimization algorithm for minimizing the loss function by adjusting model parameters iteratively.                   |\n| **Loss Function**                  | A function that quantifies the difference between predicted and actual values, guiding the training process.            |\n| **Activation Function**            | A function applied to a neuron's output to introduce non-linearity into the model.                                     |\n| **Epoch**                          | One complete pass through the entire training dataset during model training.                                           |\n| **Batch Size**                     | The number of training examples processed before updating model weights.                                              |\n| **Learning Rate**                  | A hyperparameter that determines the size of the steps taken during optimization.                                      |\n| **Optimizer**                      | An algorithm that adjusts the model parameters to minimize the loss function.                                          |\n| **Transfer Learning**              | Using a pre-trained model on a new, but related task, to leverage previously learned features.                         |\n| **Ensemble Learning**              | Combining multiple models to improve overall performance, such as bagging, boosting, and stacking.                     |\n| **Data Augmentation**             | Techniques to artificially increase the size and diversity of the training dataset by modifying existing data.         |\n| **Regularization**                 | Techniques to prevent overfitting by adding a penalty to the model's complexity, such as L1 or L2 regularization.       |\n| **Principal Component Analysis (PCA)** | A dimensionality reduction method that transforms data into orthogonal components to capture variance.              |\n| **Support Vector Machine (SVM)**   | A supervised learning algorithm for classification and regression tasks that finds the hyperplane that best separates classes. |\n| **K-Nearest Neighbors (KNN)**       | A classification algorithm that assigns a class based on the majority label of its nearest neighbors.                  |\n| **Decision Tree**                  | A supervised learning algorithm that uses a tree-like model of decisions and their possible consequences.               |\n| **Random Forest**                  | An ensemble method that combines multiple decision trees to improve classification or regression performance.           |\n| **Gradient Boosting**              | An ensemble technique that builds models sequentially to correct the errors of previous models.                        |\n| **Generative Adversarial Network (GAN)** | A framework of two neural networks, a generator and a discriminator, that compete to create realistic data.          |\n| **Autoencoder**                    | A neural network used for unsupervised learning to encode and then decode input data, often for dimensionality reduction. |\n| **Recurrent Neural Network (RNN)** | A neural network designed for sequential data, maintaining context through recurrent connections.                      |\n| **Long Short-Term Memory (LSTM)**  | A type of RNN capable of learning long-term dependencies and mitigating the vanishing gradient problem.                 |\n| **Transformer**                    | A deep learning model architecture designed for sequential data, known for its self-attention mechanism.               |\n| **BERT (Bidirectional Encoder Representations from Transformers)** | A transformer-based model for capturing context in both directions for NLP tasks.                                   |\n| **GPT (Generative Pre-trained Transformer)** | A series of transformer-based models for generating human-like text.                                                |\n| **Hyperparameter Tuning**           | The process of finding the optimal set of hyperparameters for a machine learning model.                               |\n| **Explainable AI (XAI)**            | Methods and techniques to make AI models and their predictions more transparent and understandable.                   |\n| **Precision**                       | A metric for evaluating classification models, defined as the ratio of true positive predictions to the total predicted positives. |\n| **Recall**                          | A metric for evaluating classification models, defined as the ratio of true positive predictions to the total actual positives. |\n| **F1 Score**                        | A metric combining precision and recall into a single measure of a model's performance, calculated as their harmonic mean. |\n| **ROC Curve**                      | A graphical plot of the true positive rate against the false positive rate at various threshold settings.              |\n| **AUC (Area Under the Curve)**      | The area under the ROC curve, representing the overall performance of the model.                                      |\n| **Confusion Matrix**                | A matrix showing the true positives, false positives, true negatives, and false negatives of a classification model.  |\n| **Feature Importance**              | A measure of the impact of each feature on the predictions made by a model.                                           |\n| **Bagging**                         | An ensemble method that trains multiple models on different subsets of the data and combines their predictions.        |\n| **Boosting**                        | An ensemble method that trains models sequentially, with each model focusing on correcting the errors of its predecessors. |\n| **Stacking**                        | An ensemble method where multiple models are combined by a meta-model that learns the best way to aggregate their predictions. |\n| **Simulated Annealing**             | An optimization technique inspired by the annealing process in metallurgy, used to find approximate solutions to complex problems. |\n| **Genetic Algorithm**               | An optimization method based on natural selection, involving evolution of solutions over generations.                |\n| **Monte Carlo Simulation**          | A method using random sampling to estimate the behavior of a system or process.                                       |\n| **Image Classification**            | A computer vision task where the goal is to categorize images into predefined classes.                               |\n| **Object Detection**               | A computer vision task that involves identifying and locating objects within an image.                              |\n| **Semantic Segmentation**          | A computer vision task that involves labeling each pixel in an image with a class.                                  |\n| **Instance Segmentation**          | A computer vision task that combines object detection and semantic segmentation, identifying each object instance.   |\n| **Image Recognition**              | The process of identifying and classifying objects or features within an image.                                      |\n| **Feature Extraction**             | The process of transforming raw data into a set of features that can be used for model training.                     |\n| **Transfer Learning**              | Leveraging a pre-trained model on a related task to improve performance on a new task.                               |\n| **Few-Shot Learning**              | Training models to perform well with very few training examples.                                                      |\n| **Zero-Shot Learning**             | Training models to recognize classes or tasks they have never seen during training.                                 |\n| **Meta-Learning**                  | Techniques that enable models to learn how to learn, improving their ability to generalize to new tasks.             |\n| **Self-Supervised Learning**       | A type of unsupervised learning where the data itself provides supervision, often used for pre-training models.      |\n| **Contrastive Learning**           | A self-supervised learning approach that learns to differentiate between similar and dissimilar data instances.       |\n| **Attention Mechanism**            | A technique used in neural networks to focus on specific parts of the input data, enhancing performance on tasks like translation. |\n\nThis expanded list includes terms across various areas including AI, ML, deep learning, computer vision, and related fields.\n\n#AI \n#ML \n#definition ",
    "tags": [
      "AI",
      "ML",
      "definition"
    ],
    "htmlContent": "<p>Here’s an extensive list of terms related to modern AI, ML, deep learning, computer vision, and related fields:</p>\n<table>\n<thead>\n<tr>\n<th><strong>Term</strong></th>\n<th><strong>Definition</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Algorithm</strong></td>\n<td>A set of rules or instructions for solving a problem or performing a task.</td>\n</tr>\n<tr>\n<td><strong>Artificial Intelligence (AI)</strong></td>\n<td>The simulation of human intelligence in machines that are programmed to think and learn.</td>\n</tr>\n<tr>\n<td><strong>Machine Learning (ML)</strong></td>\n<td>A subset of AI where computers use algorithms to learn from data and improve their performance over time.</td>\n</tr>\n<tr>\n<td><strong>Deep Learning</strong></td>\n<td>A subset of ML involving neural networks with many layers to learn complex patterns in large datasets.</td>\n</tr>\n<tr>\n<td><strong>Neural Network</strong></td>\n<td>A computational model inspired by the human brain, consisting of interconnected nodes (neurons).</td>\n</tr>\n<tr>\n<td><strong>Supervised Learning</strong></td>\n<td>ML where the model is trained on labeled data, learning the relationship between inputs and outputs.</td>\n</tr>\n<tr>\n<td><strong>Unsupervised Learning</strong></td>\n<td>ML where the model learns patterns and structures from unlabeled data.</td>\n</tr>\n<tr>\n<td><strong>Reinforcement Learning</strong></td>\n<td>ML where an agent learns to make decisions by receiving rewards or penalties.</td>\n</tr>\n<tr>\n<td><strong>Regression</strong></td>\n<td>A type of supervised learning used to predict continuous values.</td>\n</tr>\n<tr>\n<td><strong>Classification</strong></td>\n<td>A type of supervised learning used to categorize data into predefined classes.</td>\n</tr>\n<tr>\n<td><strong>Clustering</strong></td>\n<td>An unsupervised learning technique for grouping similar data points together.</td>\n</tr>\n<tr>\n<td><strong>Dimensionality Reduction</strong></td>\n<td>Techniques for reducing the number of features in a dataset while retaining important information.</td>\n</tr>\n<tr>\n<td><strong>Feature Engineering</strong></td>\n<td>The process of creating or modifying features to improve model performance.</td>\n</tr>\n<tr>\n<td><strong>Overfitting</strong></td>\n<td>When a model learns the training data too well and performs poorly on new, unseen data.</td>\n</tr>\n<tr>\n<td><strong>Underfitting</strong></td>\n<td>When a model is too simple to capture the underlying patterns in the data.</td>\n</tr>\n<tr>\n<td><strong>Cross-Validation</strong></td>\n<td>A technique for assessing how the results of a model will generalize to an independent dataset by splitting data into subsets.</td>\n</tr>\n<tr>\n<td><strong>Hyperparameter</strong></td>\n<td>Settings for a learning algorithm that are set before the training process begins.</td>\n</tr>\n<tr>\n<td><strong>Gradient Descent</strong></td>\n<td>An optimization algorithm for minimizing the loss function by adjusting model parameters iteratively.</td>\n</tr>\n<tr>\n<td><strong>Loss Function</strong></td>\n<td>A function that quantifies the difference between predicted and actual values, guiding the training process.</td>\n</tr>\n<tr>\n<td><strong>Activation Function</strong></td>\n<td>A function applied to a neuron&#39;s output to introduce non-linearity into the model.</td>\n</tr>\n<tr>\n<td><strong>Epoch</strong></td>\n<td>One complete pass through the entire training dataset during model training.</td>\n</tr>\n<tr>\n<td><strong>Batch Size</strong></td>\n<td>The number of training examples processed before updating model weights.</td>\n</tr>\n<tr>\n<td><strong>Learning Rate</strong></td>\n<td>A hyperparameter that determines the size of the steps taken during optimization.</td>\n</tr>\n<tr>\n<td><strong>Optimizer</strong></td>\n<td>An algorithm that adjusts the model parameters to minimize the loss function.</td>\n</tr>\n<tr>\n<td><strong>Transfer Learning</strong></td>\n<td>Using a pre-trained model on a new, but related task, to leverage previously learned features.</td>\n</tr>\n<tr>\n<td><strong>Ensemble Learning</strong></td>\n<td>Combining multiple models to improve overall performance, such as bagging, boosting, and stacking.</td>\n</tr>\n<tr>\n<td><strong>Data Augmentation</strong></td>\n<td>Techniques to artificially increase the size and diversity of the training dataset by modifying existing data.</td>\n</tr>\n<tr>\n<td><strong>Regularization</strong></td>\n<td>Techniques to prevent overfitting by adding a penalty to the model&#39;s complexity, such as L1 or L2 regularization.</td>\n</tr>\n<tr>\n<td><strong>Principal Component Analysis (PCA)</strong></td>\n<td>A dimensionality reduction method that transforms data into orthogonal components to capture variance.</td>\n</tr>\n<tr>\n<td><strong>Support Vector Machine (SVM)</strong></td>\n<td>A supervised learning algorithm for classification and regression tasks that finds the hyperplane that best separates classes.</td>\n</tr>\n<tr>\n<td><strong>K-Nearest Neighbors (KNN)</strong></td>\n<td>A classification algorithm that assigns a class based on the majority label of its nearest neighbors.</td>\n</tr>\n<tr>\n<td><strong>Decision Tree</strong></td>\n<td>A supervised learning algorithm that uses a tree-like model of decisions and their possible consequences.</td>\n</tr>\n<tr>\n<td><strong>Random Forest</strong></td>\n<td>An ensemble method that combines multiple decision trees to improve classification or regression performance.</td>\n</tr>\n<tr>\n<td><strong>Gradient Boosting</strong></td>\n<td>An ensemble technique that builds models sequentially to correct the errors of previous models.</td>\n</tr>\n<tr>\n<td><strong>Generative Adversarial Network (GAN)</strong></td>\n<td>A framework of two neural networks, a generator and a discriminator, that compete to create realistic data.</td>\n</tr>\n<tr>\n<td><strong>Autoencoder</strong></td>\n<td>A neural network used for unsupervised learning to encode and then decode input data, often for dimensionality reduction.</td>\n</tr>\n<tr>\n<td><strong>Recurrent Neural Network (RNN)</strong></td>\n<td>A neural network designed for sequential data, maintaining context through recurrent connections.</td>\n</tr>\n<tr>\n<td><strong>Long Short-Term Memory (LSTM)</strong></td>\n<td>A type of RNN capable of learning long-term dependencies and mitigating the vanishing gradient problem.</td>\n</tr>\n<tr>\n<td><strong>Transformer</strong></td>\n<td>A deep learning model architecture designed for sequential data, known for its self-attention mechanism.</td>\n</tr>\n<tr>\n<td><strong>BERT (Bidirectional Encoder Representations from Transformers)</strong></td>\n<td>A transformer-based model for capturing context in both directions for NLP tasks.</td>\n</tr>\n<tr>\n<td><strong>GPT (Generative Pre-trained Transformer)</strong></td>\n<td>A series of transformer-based models for generating human-like text.</td>\n</tr>\n<tr>\n<td><strong>Hyperparameter Tuning</strong></td>\n<td>The process of finding the optimal set of hyperparameters for a machine learning model.</td>\n</tr>\n<tr>\n<td><strong>Explainable AI (XAI)</strong></td>\n<td>Methods and techniques to make AI models and their predictions more transparent and understandable.</td>\n</tr>\n<tr>\n<td><strong>Precision</strong></td>\n<td>A metric for evaluating classification models, defined as the ratio of true positive predictions to the total predicted positives.</td>\n</tr>\n<tr>\n<td><strong>Recall</strong></td>\n<td>A metric for evaluating classification models, defined as the ratio of true positive predictions to the total actual positives.</td>\n</tr>\n<tr>\n<td><strong>F1 Score</strong></td>\n<td>A metric combining precision and recall into a single measure of a model&#39;s performance, calculated as their harmonic mean.</td>\n</tr>\n<tr>\n<td><strong>ROC Curve</strong></td>\n<td>A graphical plot of the true positive rate against the false positive rate at various threshold settings.</td>\n</tr>\n<tr>\n<td><strong>AUC (Area Under the Curve)</strong></td>\n<td>The area under the ROC curve, representing the overall performance of the model.</td>\n</tr>\n<tr>\n<td><strong>Confusion Matrix</strong></td>\n<td>A matrix showing the true positives, false positives, true negatives, and false negatives of a classification model.</td>\n</tr>\n<tr>\n<td><strong>Feature Importance</strong></td>\n<td>A measure of the impact of each feature on the predictions made by a model.</td>\n</tr>\n<tr>\n<td><strong>Bagging</strong></td>\n<td>An ensemble method that trains multiple models on different subsets of the data and combines their predictions.</td>\n</tr>\n<tr>\n<td><strong>Boosting</strong></td>\n<td>An ensemble method that trains models sequentially, with each model focusing on correcting the errors of its predecessors.</td>\n</tr>\n<tr>\n<td><strong>Stacking</strong></td>\n<td>An ensemble method where multiple models are combined by a meta-model that learns the best way to aggregate their predictions.</td>\n</tr>\n<tr>\n<td><strong>Simulated Annealing</strong></td>\n<td>An optimization technique inspired by the annealing process in metallurgy, used to find approximate solutions to complex problems.</td>\n</tr>\n<tr>\n<td><strong>Genetic Algorithm</strong></td>\n<td>An optimization method based on natural selection, involving evolution of solutions over generations.</td>\n</tr>\n<tr>\n<td><strong>Monte Carlo Simulation</strong></td>\n<td>A method using random sampling to estimate the behavior of a system or process.</td>\n</tr>\n<tr>\n<td><strong>Image Classification</strong></td>\n<td>A computer vision task where the goal is to categorize images into predefined classes.</td>\n</tr>\n<tr>\n<td><strong>Object Detection</strong></td>\n<td>A computer vision task that involves identifying and locating objects within an image.</td>\n</tr>\n<tr>\n<td><strong>Semantic Segmentation</strong></td>\n<td>A computer vision task that involves labeling each pixel in an image with a class.</td>\n</tr>\n<tr>\n<td><strong>Instance Segmentation</strong></td>\n<td>A computer vision task that combines object detection and semantic segmentation, identifying each object instance.</td>\n</tr>\n<tr>\n<td><strong>Image Recognition</strong></td>\n<td>The process of identifying and classifying objects or features within an image.</td>\n</tr>\n<tr>\n<td><strong>Feature Extraction</strong></td>\n<td>The process of transforming raw data into a set of features that can be used for model training.</td>\n</tr>\n<tr>\n<td><strong>Transfer Learning</strong></td>\n<td>Leveraging a pre-trained model on a related task to improve performance on a new task.</td>\n</tr>\n<tr>\n<td><strong>Few-Shot Learning</strong></td>\n<td>Training models to perform well with very few training examples.</td>\n</tr>\n<tr>\n<td><strong>Zero-Shot Learning</strong></td>\n<td>Training models to recognize classes or tasks they have never seen during training.</td>\n</tr>\n<tr>\n<td><strong>Meta-Learning</strong></td>\n<td>Techniques that enable models to learn how to learn, improving their ability to generalize to new tasks.</td>\n</tr>\n<tr>\n<td><strong>Self-Supervised Learning</strong></td>\n<td>A type of unsupervised learning where the data itself provides supervision, often used for pre-training models.</td>\n</tr>\n<tr>\n<td><strong>Contrastive Learning</strong></td>\n<td>A self-supervised learning approach that learns to differentiate between similar and dissimilar data instances.</td>\n</tr>\n<tr>\n<td><strong>Attention Mechanism</strong></td>\n<td>A technique used in neural networks to focus on specific parts of the input data, enhancing performance on tasks like translation.</td>\n</tr>\n</tbody></table>\n<p>This expanded list includes terms across various areas including AI, ML, deep learning, computer vision, and related fields.</p>\n<p>#AI \n#ML \n#definition </p>\n"
  },
  {
    "title": "AI Terms Dictionary URLs",
    "body": "\nThere isn't a single definitive source for a complete dictionary of AI terms, as the field is broad and continually evolving. However, several reputable resources can serve as comprehensive references for AI terms:\n\n1. **[# Machine Learning Glossary](https://developers.google.com/machine-learning/glossary)**: Provides definitions for a wide range of AI and machine learning terms used in Google Cloud's AI services.\n\n2. **[# Explainers](https://www.ibm.com/topics)**: Offers explanations for various AI concepts and terminology used in IBM's AI solutions.\n\n3. **[NVIDIA Glossary](https://www.nvidia.com/en-us/glossary/)**: A glossary of terms related to AI and deep learning as used in NVIDIA's ecosystem.\n\n4. **[# Artificial Intelligence Terms: A to Z Glossary](https://www.coursera.org/resources/ai-terms)**: Review common artificial intelligence (AI) terms to know when preparing for an exam, interviews, or job search.\n\n\nThese resources should provide a broad overview of AI terminology and concepts. If you're looking for specific terms or a more extensive dictionary, you might need to refer to academic textbooks, online courses, or specialized dictionaries on AI and machine learning.",
    "tags": [],
    "htmlContent": "<p>There isn&#39;t a single definitive source for a complete dictionary of AI terms, as the field is broad and continually evolving. However, several reputable resources can serve as comprehensive references for AI terms:</p>\n<ol>\n<li><p><strong><a href=\"https://developers.google.com/machine-learning/glossary\"># Machine Learning Glossary</a></strong>: Provides definitions for a wide range of AI and machine learning terms used in Google Cloud&#39;s AI services.</p>\n</li>\n<li><p><strong><a href=\"https://www.ibm.com/topics\"># Explainers</a></strong>: Offers explanations for various AI concepts and terminology used in IBM&#39;s AI solutions.</p>\n</li>\n<li><p><strong><a href=\"https://www.nvidia.com/en-us/glossary/\">NVIDIA Glossary</a></strong>: A glossary of terms related to AI and deep learning as used in NVIDIA&#39;s ecosystem.</p>\n</li>\n<li><p><strong><a href=\"https://www.coursera.org/resources/ai-terms\"># Artificial Intelligence Terms: A to Z Glossary</a></strong>: Review common artificial intelligence (AI) terms to know when preparing for an exam, interviews, or job search.</p>\n</li>\n</ol>\n<p>These resources should provide a broad overview of AI terminology and concepts. If you&#39;re looking for specific terms or a more extensive dictionary, you might need to refer to academic textbooks, online courses, or specialized dictionaries on AI and machine learning.</p>\n"
  },
  {
    "title": "AI and ML packages to use",
    "body": "Here’s a more comprehensive mapping between Python and Rust libraries for machine learning and AI, covering a broader range of functionalities and use cases:\n\n| **Functionality**                  | **Python Library**                | **Rust Library**                    | **Description**                                                                            |\n|-----------------------------------|-----------------------------------|-------------------------------------|--------------------------------------------------------------------------------------------|\n| **General Machine Learning**       | scikit-learn                       | `linfa`                            | `linfa` provides a wide range of ML algorithms similar to scikit-learn.                    |\n| **Deep Learning**                 | TensorFlow, PyTorch                | `tch-rs` (for PyTorch), `burn`       | `tch-rs` is a Rust binding to PyTorch. `burn` is a newer deep learning library in Rust.     |\n| **Data Manipulation**             | pandas                             | `polars`, `dataframe`                | `polars` and `dataframe` provide DataFrame operations similar to pandas.                   |\n| **Numerical Computation**         | NumPy                              | `ndarray`, `nalgebra`                | `ndarray` and `nalgebra` offer numerical and matrix computations similar to NumPy.         |\n| **Optimization**                  | SciPy (optimize module)            | `ndarray`, custom implementations     | `ndarray` can be used with custom optimization algorithms in Rust.                        |\n| **Natural Language Processing**   | spaCy, NLTK, Hugging Face Transformers | `rust-bert`, `tch-rs`, `nlp`         | `rust-bert` and `tch-rs` support BERT models. The `nlp` crate provides various NLP utilities.|\n| **Visualization**                 | Matplotlib, Seaborn, Plotly         | `plotters`, `gnuplot`, `conrod`      | `plotters`, `gnuplot`, and `conrod` are used for creating visualizations and plots.         |\n| **Reinforcement Learning**        | OpenAI Gym                         | `rllab`, `rl` (experimental)        | `rllab` and `rl` libraries provide reinforcement learning functionalities.                  |\n| **Feature Engineering**           | Feature-engine, Featuretools       | Custom Rust code, `ndarray`          | Feature engineering often involves custom implementations or using `ndarray`.               |\n| **Model Serving**                 | TensorFlow Serving, TorchServe     | Custom implementations, `actix-web`  | Model serving often requires custom implementations or using `actix-web` for APIs.          |\n| **Time Series Analysis**          | Statsmodels, Prophet                | `time-series`, `ndarray`             | `time-series` crate provides time series functionalities.                                  |\n| **Anomaly Detection**             | PyOD, scikit-learn                  | `linfa`, custom implementations       | `linfa` provides some anomaly detection algorithms.                                        |\n| **Clustering**                    | scikit-learn, DBSCAN                | `linfa`, `rustlearn`                 | `linfa` and `rustlearn` offer clustering algorithms like K-means and DBSCAN.               |\n| **Dimensionality Reduction**      | scikit-learn, PCA, TSNE             | `linfa`, custom implementations       | `linfa` includes some dimensionality reduction methods.                                    |\n| **Graph Neural Networks**         | DGL, PyTorch Geometric              | `tch-rs` (with custom implementations) | `tch-rs` can be used for GNNs with custom implementations.                                  |\n| **Hyperparameter Tuning**          | Optuna, Hyperopt                    | `optuna`, custom implementations      | `optuna` crate offers hyperparameter tuning similar to Python libraries.                   |\n| **Automated Machine Learning**    | Auto-sklearn, TPOT                   | `auto_ml` (experimental)             | `auto_ml` is an experimental crate for automated machine learning.                         |\n| **Bayesian Methods**              | PyMC3, Stan                         | `ndarray`, custom implementations     | Bayesian methods often require custom implementations in Rust.                              |\n| **Neural Architecture Search**    | Keras Tuner, NNI                     | `burn`, custom implementations        | `burn` can be used for architecture search with custom implementations.                    |\n\n### Key Points:\n\n- **Python Libraries**: Python has a vast array of specialized libraries for various machine learning and AI tasks, often with extensive support and documentation.\n- **Rust Libraries**: Rust’s ecosystem is growing, with increasing support for machine learning, deep learning, and related tasks. Libraries like `linfa`, `tch-rs`, and `polars` are expanding Rust’s capabilities in these areas.\n- **Integration**: For some tasks, especially those not yet fully supported in Rust, integrating with Python or using custom implementations may be necessary.\n\nThis table provides a detailed comparison, highlighting both existing Rust libraries and areas where custom implementations or integrations may be required. Rust’s machine learning ecosystem is rapidly evolving, and new libraries and tools are continually being developed.\n\n#AI \n#ML\n#Rust\n#Python\n#package",
    "tags": [
      "**Python Libraries**: Python has a vast array of specialized libraries for various machine learning and AI tasks, often with extensive support and documentation.",
      "**Rust Libraries**: Rust’s ecosystem is growing, with increasing support for machine learning, deep learning, and related tasks. Libraries like `linfa`, `tch",
      "rs`, and `polars` are expanding Rust’s capabilities in these areas.",
      "**Integration**: For some tasks, especially those not yet fully supported in Rust, integrating with Python or using custom implementations may be necessary.",
      "AI",
      "ML",
      "Rust",
      "Python",
      "package"
    ],
    "htmlContent": "<p>Here’s a more comprehensive mapping between Python and Rust libraries for machine learning and AI, covering a broader range of functionalities and use cases:</p>\n<table>\n<thead>\n<tr>\n<th><strong>Functionality</strong></th>\n<th><strong>Python Library</strong></th>\n<th><strong>Rust Library</strong></th>\n<th><strong>Description</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>General Machine Learning</strong></td>\n<td>scikit-learn</td>\n<td><code>linfa</code></td>\n<td><code>linfa</code> provides a wide range of ML algorithms similar to scikit-learn.</td>\n</tr>\n<tr>\n<td><strong>Deep Learning</strong></td>\n<td>TensorFlow, PyTorch</td>\n<td><code>tch-rs</code> (for PyTorch), <code>burn</code></td>\n<td><code>tch-rs</code> is a Rust binding to PyTorch. <code>burn</code> is a newer deep learning library in Rust.</td>\n</tr>\n<tr>\n<td><strong>Data Manipulation</strong></td>\n<td>pandas</td>\n<td><code>polars</code>, <code>dataframe</code></td>\n<td><code>polars</code> and <code>dataframe</code> provide DataFrame operations similar to pandas.</td>\n</tr>\n<tr>\n<td><strong>Numerical Computation</strong></td>\n<td>NumPy</td>\n<td><code>ndarray</code>, <code>nalgebra</code></td>\n<td><code>ndarray</code> and <code>nalgebra</code> offer numerical and matrix computations similar to NumPy.</td>\n</tr>\n<tr>\n<td><strong>Optimization</strong></td>\n<td>SciPy (optimize module)</td>\n<td><code>ndarray</code>, custom implementations</td>\n<td><code>ndarray</code> can be used with custom optimization algorithms in Rust.</td>\n</tr>\n<tr>\n<td><strong>Natural Language Processing</strong></td>\n<td>spaCy, NLTK, Hugging Face Transformers</td>\n<td><code>rust-bert</code>, <code>tch-rs</code>, <code>nlp</code></td>\n<td><code>rust-bert</code> and <code>tch-rs</code> support BERT models. The <code>nlp</code> crate provides various NLP utilities.</td>\n</tr>\n<tr>\n<td><strong>Visualization</strong></td>\n<td>Matplotlib, Seaborn, Plotly</td>\n<td><code>plotters</code>, <code>gnuplot</code>, <code>conrod</code></td>\n<td><code>plotters</code>, <code>gnuplot</code>, and <code>conrod</code> are used for creating visualizations and plots.</td>\n</tr>\n<tr>\n<td><strong>Reinforcement Learning</strong></td>\n<td>OpenAI Gym</td>\n<td><code>rllab</code>, <code>rl</code> (experimental)</td>\n<td><code>rllab</code> and <code>rl</code> libraries provide reinforcement learning functionalities.</td>\n</tr>\n<tr>\n<td><strong>Feature Engineering</strong></td>\n<td>Feature-engine, Featuretools</td>\n<td>Custom Rust code, <code>ndarray</code></td>\n<td>Feature engineering often involves custom implementations or using <code>ndarray</code>.</td>\n</tr>\n<tr>\n<td><strong>Model Serving</strong></td>\n<td>TensorFlow Serving, TorchServe</td>\n<td>Custom implementations, <code>actix-web</code></td>\n<td>Model serving often requires custom implementations or using <code>actix-web</code> for APIs.</td>\n</tr>\n<tr>\n<td><strong>Time Series Analysis</strong></td>\n<td>Statsmodels, Prophet</td>\n<td><code>time-series</code>, <code>ndarray</code></td>\n<td><code>time-series</code> crate provides time series functionalities.</td>\n</tr>\n<tr>\n<td><strong>Anomaly Detection</strong></td>\n<td>PyOD, scikit-learn</td>\n<td><code>linfa</code>, custom implementations</td>\n<td><code>linfa</code> provides some anomaly detection algorithms.</td>\n</tr>\n<tr>\n<td><strong>Clustering</strong></td>\n<td>scikit-learn, DBSCAN</td>\n<td><code>linfa</code>, <code>rustlearn</code></td>\n<td><code>linfa</code> and <code>rustlearn</code> offer clustering algorithms like K-means and DBSCAN.</td>\n</tr>\n<tr>\n<td><strong>Dimensionality Reduction</strong></td>\n<td>scikit-learn, PCA, TSNE</td>\n<td><code>linfa</code>, custom implementations</td>\n<td><code>linfa</code> includes some dimensionality reduction methods.</td>\n</tr>\n<tr>\n<td><strong>Graph Neural Networks</strong></td>\n<td>DGL, PyTorch Geometric</td>\n<td><code>tch-rs</code> (with custom implementations)</td>\n<td><code>tch-rs</code> can be used for GNNs with custom implementations.</td>\n</tr>\n<tr>\n<td><strong>Hyperparameter Tuning</strong></td>\n<td>Optuna, Hyperopt</td>\n<td><code>optuna</code>, custom implementations</td>\n<td><code>optuna</code> crate offers hyperparameter tuning similar to Python libraries.</td>\n</tr>\n<tr>\n<td><strong>Automated Machine Learning</strong></td>\n<td>Auto-sklearn, TPOT</td>\n<td><code>auto_ml</code> (experimental)</td>\n<td><code>auto_ml</code> is an experimental crate for automated machine learning.</td>\n</tr>\n<tr>\n<td><strong>Bayesian Methods</strong></td>\n<td>PyMC3, Stan</td>\n<td><code>ndarray</code>, custom implementations</td>\n<td>Bayesian methods often require custom implementations in Rust.</td>\n</tr>\n<tr>\n<td><strong>Neural Architecture Search</strong></td>\n<td>Keras Tuner, NNI</td>\n<td><code>burn</code>, custom implementations</td>\n<td><code>burn</code> can be used for architecture search with custom implementations.</td>\n</tr>\n</tbody></table>\n<h3>Key Points:</h3>\n<ul>\n<li><strong>Python Libraries</strong>: Python has a vast array of specialized libraries for various machine learning and AI tasks, often with extensive support and documentation.</li>\n<li><strong>Rust Libraries</strong>: Rust’s ecosystem is growing, with increasing support for machine learning, deep learning, and related tasks. Libraries like <code>linfa</code>, <code>tch-rs</code>, and <code>polars</code> are expanding Rust’s capabilities in these areas.</li>\n<li><strong>Integration</strong>: For some tasks, especially those not yet fully supported in Rust, integrating with Python or using custom implementations may be necessary.</li>\n</ul>\n<p>This table provides a detailed comparison, highlighting both existing Rust libraries and areas where custom implementations or integrations may be required. Rust’s machine learning ecosystem is rapidly evolving, and new libraries and tools are continually being developed.</p>\n<p>#AI \n#ML\n#Rust\n#Python\n#package</p>\n"
  },
  {
    "title": "Architecture of CNN",
    "body": "The architecture of a Convolutional Neural Network (CNN) is typically structured in a series of layers that process and transform the input data through a series of stages. Here’s a structured overview of a typical CNN architecture:\n\n### Architecture of Convolutional Neural Networks (CNNs)\n\n| **Layer Type**          | **Purpose**                                                                 | **Operation**                                                                                                           | **Output Size (Example)**                        |\n|-------------------------|-----------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------|\n| **1. Input Layer**      | Accepts raw data (e.g., images)                                               | Takes input data, often an image with dimensions (height, width, channels)                                              | E.g., 32x32x3 for a 32x32 RGB image               |\n| **2. Convolutional Layer** | Extracts features from the input data                                      | Applies multiple convolutional filters (kernels) to detect features like edges or textures. Produces feature maps.    | Depends on filter size, stride, and padding.      |\n| **3. Activation Layer** | Introduces non-linearity into the network                                      | Applies activation functions (e.g., ReLU) to the output of the convolutional layer to introduce non-linear properties. | Same dimensions as the convolutional layer output |\n| **4. Pooling Layer**    | Reduces dimensionality and computational load                                  | Applies pooling operations (e.g., max pooling or average pooling) to downsample the feature maps.                       | Reduces spatial dimensions (e.g., 2x2 pooling reduces by half) |\n| **5. Convolutional Layer** | Further extracts higher-level features from pooled feature maps.            | Applies additional convolutional filters to the pooled feature maps.                                                    | Depends on filter size, stride, and padding.      |\n| **6. Activation Layer** | Applies non-linearity after additional convolutions                           | ReLU or other activation functions to maintain non-linearity.                                                            | Same dimensions as the convolutional layer output |\n| **7. Pooling Layer**    | Further reduces dimensionality and retains important features                  | Further pooling to reduce size and computational complexity.                                                             | Further reduced dimensions                        |\n| **8. Fully Connected Layer** | Combines features learned by previous layers for final classification or regression | Flattens the output from the previous layers and passes it through dense (fully connected) layers.                      | Vector of neurons, often with softmax for classification |\n| **9. Output Layer**     | Produces final output (e.g., class probabilities)                              | Uses an activation function like softmax (for classification) or linear (for regression) to produce the final predictions. | E.g., 10 for a 10-class classification problem     |\n\n#AI \n#CNN\n#definition \n#article ",
    "tags": [
      "AI",
      "CNN",
      "definition",
      "article"
    ],
    "htmlContent": "<p>The architecture of a Convolutional Neural Network (CNN) is typically structured in a series of layers that process and transform the input data through a series of stages. Here’s a structured overview of a typical CNN architecture:</p>\n<h3>Architecture of Convolutional Neural Networks (CNNs)</h3>\n<table>\n<thead>\n<tr>\n<th><strong>Layer Type</strong></th>\n<th><strong>Purpose</strong></th>\n<th><strong>Operation</strong></th>\n<th><strong>Output Size (Example)</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>1. Input Layer</strong></td>\n<td>Accepts raw data (e.g., images)</td>\n<td>Takes input data, often an image with dimensions (height, width, channels)</td>\n<td>E.g., 32x32x3 for a 32x32 RGB image</td>\n</tr>\n<tr>\n<td><strong>2. Convolutional Layer</strong></td>\n<td>Extracts features from the input data</td>\n<td>Applies multiple convolutional filters (kernels) to detect features like edges or textures. Produces feature maps.</td>\n<td>Depends on filter size, stride, and padding.</td>\n</tr>\n<tr>\n<td><strong>3. Activation Layer</strong></td>\n<td>Introduces non-linearity into the network</td>\n<td>Applies activation functions (e.g., ReLU) to the output of the convolutional layer to introduce non-linear properties.</td>\n<td>Same dimensions as the convolutional layer output</td>\n</tr>\n<tr>\n<td><strong>4. Pooling Layer</strong></td>\n<td>Reduces dimensionality and computational load</td>\n<td>Applies pooling operations (e.g., max pooling or average pooling) to downsample the feature maps.</td>\n<td>Reduces spatial dimensions (e.g., 2x2 pooling reduces by half)</td>\n</tr>\n<tr>\n<td><strong>5. Convolutional Layer</strong></td>\n<td>Further extracts higher-level features from pooled feature maps.</td>\n<td>Applies additional convolutional filters to the pooled feature maps.</td>\n<td>Depends on filter size, stride, and padding.</td>\n</tr>\n<tr>\n<td><strong>6. Activation Layer</strong></td>\n<td>Applies non-linearity after additional convolutions</td>\n<td>ReLU or other activation functions to maintain non-linearity.</td>\n<td>Same dimensions as the convolutional layer output</td>\n</tr>\n<tr>\n<td><strong>7. Pooling Layer</strong></td>\n<td>Further reduces dimensionality and retains important features</td>\n<td>Further pooling to reduce size and computational complexity.</td>\n<td>Further reduced dimensions</td>\n</tr>\n<tr>\n<td><strong>8. Fully Connected Layer</strong></td>\n<td>Combines features learned by previous layers for final classification or regression</td>\n<td>Flattens the output from the previous layers and passes it through dense (fully connected) layers.</td>\n<td>Vector of neurons, often with softmax for classification</td>\n</tr>\n<tr>\n<td><strong>9. Output Layer</strong></td>\n<td>Produces final output (e.g., class probabilities)</td>\n<td>Uses an activation function like softmax (for classification) or linear (for regression) to produce the final predictions.</td>\n<td>E.g., 10 for a 10-class classification problem</td>\n</tr>\n</tbody></table>\n<p>#AI \n#CNN\n#definition \n#article </p>\n"
  },
  {
    "title": "Binarization",
    "body": "Binarization refers to the process of reducing precision to 1 bit by representing integer values -1 and 1 with binary values 0 and 1 respectively.\n\nBinarization is a data preprocessing technique used to transform numerical variables into binary values (0s and 1s) based on a threshold. This method can be particularly useful for converting continuous variables into a form that machine learning algorithms can more easily process.\n\nBinarization is a digital image processing technique used to convert a grayscale image or a color image into a binary image. The binary image created as a result of binarization contains only two pixel values, typically 0 and 1, where 0 represents the background (usually black) and 1 represents the foreground or the object of interest (usually white).\n\n#ML\n#definition \n#binarization\n#image-processing\n#threshold\n#supervised-ml ",
    "tags": [
      "ML",
      "definition",
      "binarization",
      "image",
      "threshold",
      "supervised"
    ],
    "htmlContent": "<p>Binarization refers to the process of reducing precision to 1 bit by representing integer values -1 and 1 with binary values 0 and 1 respectively.</p>\n<p>Binarization is a data preprocessing technique used to transform numerical variables into binary values (0s and 1s) based on a threshold. This method can be particularly useful for converting continuous variables into a form that machine learning algorithms can more easily process.</p>\n<p>Binarization is a digital image processing technique used to convert a grayscale image or a color image into a binary image. The binary image created as a result of binarization contains only two pixel values, typically 0 and 1, where 0 represents the background (usually black) and 1 represents the foreground or the object of interest (usually white).</p>\n<p>#ML\n#definition \n#binarization\n#image-processing\n#threshold\n#supervised-ml </p>\n"
  },
  {
    "title": "Building a K-Nearest Neighbors classifier",
    "body": "KNN is a non-parametric, lazy learning algorithm for classification and regression tasks. It classifies a data point based on the majority class of its k nearest neighbors in the feature space. The choice of k and the distance metric (such as Euclidean or Manhattan distance) significantly impact the algorithm's performance.  \n\nThe concept is simple: You decide how many neighbors you want to look for based on a distance metric, take their target feature label, and assign the majority class of those neighbors to our new data.\n\n![[Pasted image 20240916183528.png]]\n\n\nMore: \n* https://medium.com/@fayam69420/building-a-k-nearest-neighbors-classifier-from-scratch-in-python-84870ebe5266\n* https://www.datacamp.com/tutorial/k-nearest-neighbor-classification-scikit-learn\n\n#ML \n#supervised-ml \n#algorithm \n#definition ",
    "tags": [
      "ML",
      "supervised",
      "algorithm",
      "definition"
    ],
    "htmlContent": "<p>KNN is a non-parametric, lazy learning algorithm for classification and regression tasks. It classifies a data point based on the majority class of its k nearest neighbors in the feature space. The choice of k and the distance metric (such as Euclidean or Manhattan distance) significantly impact the algorithm&#39;s performance.  </p>\n<p>The concept is simple: You decide how many neighbors you want to look for based on a distance metric, take their target feature label, and assign the majority class of those neighbors to our new data.</p>\n<p>![[Pasted image 20240916183528.png]]</p>\n<p>More: </p>\n<ul>\n<li><a href=\"https://medium.com/@fayam69420/building-a-k-nearest-neighbors-classifier-from-scratch-in-python-84870ebe5266\">https://medium.com/@fayam69420/building-a-k-nearest-neighbors-classifier-from-scratch-in-python-84870ebe5266</a></li>\n<li><a href=\"https://www.datacamp.com/tutorial/k-nearest-neighbor-classification-scikit-learn\">https://www.datacamp.com/tutorial/k-nearest-neighbor-classification-scikit-learn</a></li>\n</ul>\n<p>#ML \n#supervised-ml \n#algorithm \n#definition </p>\n"
  },
  {
    "title": "Building blocks of reinforcement learning",
    "body": "\nReinforcement Learning (RL) is a type of machine learning where an agent learns to make decisions by taking actions in an environment to maximize a cumulative reward. Here’s a summary of the key building blocks:\n\n1. **Agent**: The learner or decision-maker that interacts with the environment.\n\n2. **Environment**: Everything the agent interacts with and aims to control or influence. It provides feedback to the agent.\n\n3. **State**: A representation of the current situation or context in which the agent finds itself. \n\n4. **Action**: Choices the agent can make to influence the state of the environment.\n\n5. **Reward**: A feedback signal from the environment that evaluates the action taken by the agent. The goal of the agent is to maximize the cumulative reward over time.\n\n6. **Policy**: A strategy or mapping from states to actions that defines the agent’s behavior. It can be deterministic or stochastic.\n\n7. **Value Function**: A function that estimates the expected cumulative reward an agent can achieve from a given state (state-value function) or state-action pair (action-value function). It helps the agent to evaluate which states or actions are preferable.\n\n8. **Q-Learning**: A popular RL algorithm that learns the value of actions in a given state to help the agent make decisions.\n\n9. **Temporal Difference Learning**: A method that combines ideas from Monte Carlo methods and dynamic programming, using estimates to update the value function incrementally.\n\n10. **Exploration vs. Exploitation**: The trade-off between exploring new actions to discover their rewards and exploiting known actions that already yield high rewards.\n\nThese elements work together in RL to enable an agent to learn from interactions with the environment and improve its decision-making over time.\n\n#AI \n#reinforcement-learning \n#agent\n#definition \n#article ",
    "tags": [
      "AI",
      "reinforcement",
      "agent",
      "definition",
      "article"
    ],
    "htmlContent": "<p>Reinforcement Learning (RL) is a type of machine learning where an agent learns to make decisions by taking actions in an environment to maximize a cumulative reward. Here’s a summary of the key building blocks:</p>\n<ol>\n<li><p><strong>Agent</strong>: The learner or decision-maker that interacts with the environment.</p>\n</li>\n<li><p><strong>Environment</strong>: Everything the agent interacts with and aims to control or influence. It provides feedback to the agent.</p>\n</li>\n<li><p><strong>State</strong>: A representation of the current situation or context in which the agent finds itself. </p>\n</li>\n<li><p><strong>Action</strong>: Choices the agent can make to influence the state of the environment.</p>\n</li>\n<li><p><strong>Reward</strong>: A feedback signal from the environment that evaluates the action taken by the agent. The goal of the agent is to maximize the cumulative reward over time.</p>\n</li>\n<li><p><strong>Policy</strong>: A strategy or mapping from states to actions that defines the agent’s behavior. It can be deterministic or stochastic.</p>\n</li>\n<li><p><strong>Value Function</strong>: A function that estimates the expected cumulative reward an agent can achieve from a given state (state-value function) or state-action pair (action-value function). It helps the agent to evaluate which states or actions are preferable.</p>\n</li>\n<li><p><strong>Q-Learning</strong>: A popular RL algorithm that learns the value of actions in a given state to help the agent make decisions.</p>\n</li>\n<li><p><strong>Temporal Difference Learning</strong>: A method that combines ideas from Monte Carlo methods and dynamic programming, using estimates to update the value function incrementally.</p>\n</li>\n<li><p><strong>Exploration vs. Exploitation</strong>: The trade-off between exploring new actions to discover their rewards and exploiting known actions that already yield high rewards.</p>\n</li>\n</ol>\n<p>These elements work together in RL to enable an agent to learn from interactions with the environment and improve its decision-making over time.</p>\n<p>#AI \n#reinforcement-learning \n#agent\n#definition \n#article </p>\n"
  },
  {
    "title": "Class imbalance",
    "body": "Class imbalance is a common issue where the distribution of examples within a dataset is skewed or biased.\n\nThe following table provides generally accepted names and ranges for different degrees of imbalance:\n\n| Percentage of data belonging to minority class | Degree of imbalance |\n| ---------------------------------------------- | ------------------- |\n| 20-40% of the dataset                          | Mild                |\n| 1-20% of the dataset                           | Moderate            |\n| <1% of the dataset                             | Extreme             |\nWhen estimating machine learning models, the problem of class imbalance often occurs. This means that the target variable is not equally distributed, but unevenly distributed. Usually the positive class is very small, while the negative class is very large, assuming a binary target class.\n\nMore: \n* https://marini.systems/en/glossary/unbalanced-classes-machine-learning/\n* https://wandb.ai/authors/class-imbalance/reports/Simple-Ways-to-Tackle-Class-Imbalance--VmlldzoxODA3NTk\n\n#ML \n#class-embalance\n#estimate\n#definition ",
    "tags": [
      "ML",
      "class",
      "estimate",
      "definition"
    ],
    "htmlContent": "<p>Class imbalance is a common issue where the distribution of examples within a dataset is skewed or biased.</p>\n<p>The following table provides generally accepted names and ranges for different degrees of imbalance:</p>\n<table>\n<thead>\n<tr>\n<th>Percentage of data belonging to minority class</th>\n<th>Degree of imbalance</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>20-40% of the dataset</td>\n<td>Mild</td>\n</tr>\n<tr>\n<td>1-20% of the dataset</td>\n<td>Moderate</td>\n</tr>\n<tr>\n<td>&lt;1% of the dataset</td>\n<td>Extreme</td>\n</tr>\n<tr>\n<td>When estimating machine learning models, the problem of class imbalance often occurs. This means that the target variable is not equally distributed, but unevenly distributed. Usually the positive class is very small, while the negative class is very large, assuming a binary target class.</td>\n<td></td>\n</tr>\n</tbody></table>\n<p>More: </p>\n<ul>\n<li><a href=\"https://marini.systems/en/glossary/unbalanced-classes-machine-learning/\">https://marini.systems/en/glossary/unbalanced-classes-machine-learning/</a></li>\n<li><a href=\"https://wandb.ai/authors/class-imbalance/reports/Simple-Ways-to-Tackle-Class-Imbalance--VmlldzoxODA3NTk\">https://wandb.ai/authors/class-imbalance/reports/Simple-Ways-to-Tackle-Class-Imbalance--VmlldzoxODA3NTk</a></li>\n</ul>\n<p>#ML \n#class-embalance\n#estimate\n#definition </p>\n"
  },
  {
    "title": "Classification",
    "body": "As the name suggests, Classification is the task of “classifying things” into sub-categories. Classification is part of supervised machine learning in which we put labeled data for training.\n\nThere are two main classification types in machine learning:\n\n#### Binary Classification\n\nIn binary classification, the goal is to classify the input into one of two classes or categories. Example – On the basis of the given health conditions of a person, we have to determine whether the person has a certain disease or not.\n\n#### Multiclass Classification\n\nIn multi-class classification, the goal is to classify the input into one of several classes or categories. For Example – On the basis of data about different species of flowers, we have to determine which specie our observation belongs to.\n\nSource: https://www.geeksforgeeks.org/getting-started-with-classification/\n\n#ML\n#definition \n#supervised-ml \n#classification \n#binary-classification\n#multiclass-classification\n",
    "tags": [
      "ML",
      "definition",
      "supervised",
      "classification",
      "binary",
      "multiclass"
    ],
    "htmlContent": "<p>As the name suggests, Classification is the task of “classifying things” into sub-categories. Classification is part of supervised machine learning in which we put labeled data for training.</p>\n<p>There are two main classification types in machine learning:</p>\n<h4>Binary Classification</h4>\n<p>In binary classification, the goal is to classify the input into one of two classes or categories. Example – On the basis of the given health conditions of a person, we have to determine whether the person has a certain disease or not.</p>\n<h4>Multiclass Classification</h4>\n<p>In multi-class classification, the goal is to classify the input into one of several classes or categories. For Example – On the basis of data about different species of flowers, we have to determine which specie our observation belongs to.</p>\n<p>Source: <a href=\"https://www.geeksforgeeks.org/getting-started-with-classification/\">https://www.geeksforgeeks.org/getting-started-with-classification/</a></p>\n<p>#ML\n#definition \n#supervised-ml \n#classification \n#binary-classification\n#multiclass-classification</p>\n"
  },
  {
    "title": "Classifying income data using Support Vector Machines",
    "body": "In machine learning, support vector machines (SVMs, also support vector networks) are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis. A Support Vector Machine (SVM) is a discriminative classifier formally defined by a separating hyperplane. In other words, given labeled training data (supervised learning), the algorithm outputs an optimal hyperplane which categorizes new examples.\n\nThe goal of the SVM algorithm is to create the best line or decision boundary that can segregate n-dimensional space into classes so that we can easily put the new data point in the correct category in the future. This best decision boundary is called a hyperplane.\n\nSVM chooses the extreme points/vectors that help in creating the hyperplane. These extreme cases are called as support vectors, and hence algorithm is termed as Support Vector Machine.\n\nThere are two different types of SVMs, each used for different things :\n\n• Simple SVM : Typically used for linear regression and classification problems.\n\n• Kernel SVM : Has more flexibility for non-linear data because you can add more features to fit a hyperplane instead of a two-dimensional space.\n\nMore: https://annettechiu.medium.com/using-support-vector-machine-to-classify-income-levels-50k-or-50k-part-1-3-bb9f3de1f645\n\n#ML \n#definition \n#supervised-ml \n#svm\n#support-vector-machines\n",
    "tags": [
      "ML",
      "definition",
      "supervised",
      "svm",
      "support"
    ],
    "htmlContent": "<p>In machine learning, support vector machines (SVMs, also support vector networks) are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis. A Support Vector Machine (SVM) is a discriminative classifier formally defined by a separating hyperplane. In other words, given labeled training data (supervised learning), the algorithm outputs an optimal hyperplane which categorizes new examples.</p>\n<p>The goal of the SVM algorithm is to create the best line or decision boundary that can segregate n-dimensional space into classes so that we can easily put the new data point in the correct category in the future. This best decision boundary is called a hyperplane.</p>\n<p>SVM chooses the extreme points/vectors that help in creating the hyperplane. These extreme cases are called as support vectors, and hence algorithm is termed as Support Vector Machine.</p>\n<p>There are two different types of SVMs, each used for different things :</p>\n<p>• Simple SVM : Typically used for linear regression and classification problems.</p>\n<p>• Kernel SVM : Has more flexibility for non-linear data because you can add more features to fit a hyperplane instead of a two-dimensional space.</p>\n<p>More: <a href=\"https://annettechiu.medium.com/using-support-vector-machine-to-classify-income-levels-50k-or-50k-part-1-3-bb9f3de1f645\">https://annettechiu.medium.com/using-support-vector-machine-to-classify-income-levels-50k-or-50k-part-1-3-bb9f3de1f645</a></p>\n<p>#ML \n#definition \n#supervised-ml \n#svm\n#support-vector-machines</p>\n"
  },
  {
    "title": "Clustering data with K-Means algorithm",
    "body": "K-Means Clustering is an Unsupervised Learning algorithm, which groups the unlabeled dataset into different clusters. Here K defines the number of pre-defined clusters that need to be created in the process, as if K=2, there will be two clusters, and for K=3, there will be three clusters, and so on.\n\nK-means clustering, originating from signal processing and utilizing the k-means algorithm, is a technique in vector quantization. Its objective is to divide a set of n observations into k clusters, with each observation assigned to the cluster whose mean (cluster center or centroid) is closest, thereby acting as a representative of that cluster.\n\nMore:\n* https://www.javatpoint.com/k-means-clustering-algorithm-in-machine-learning\n* https://www.geeksforgeeks.org/k-means-clustering-introduction/\n\n#ML \n#clustering\n#unsupervised-ml \n#definition \n#k-means\n#algorithm ",
    "tags": [
      "ML",
      "clustering",
      "unsupervised",
      "definition",
      "k",
      "algorithm"
    ],
    "htmlContent": "<p>K-Means Clustering is an Unsupervised Learning algorithm, which groups the unlabeled dataset into different clusters. Here K defines the number of pre-defined clusters that need to be created in the process, as if K=2, there will be two clusters, and for K=3, there will be three clusters, and so on.</p>\n<p>K-means clustering, originating from signal processing and utilizing the k-means algorithm, is a technique in vector quantization. Its objective is to divide a set of n observations into k clusters, with each observation assigned to the cluster whose mean (cluster center or centroid) is closest, thereby acting as a representative of that cluster.</p>\n<p>More:</p>\n<ul>\n<li><a href=\"https://www.javatpoint.com/k-means-clustering-algorithm-in-machine-learning\">https://www.javatpoint.com/k-means-clustering-algorithm-in-machine-learning</a></li>\n<li><a href=\"https://www.geeksforgeeks.org/k-means-clustering-introduction/\">https://www.geeksforgeeks.org/k-means-clustering-introduction/</a></li>\n</ul>\n<p>#ML \n#clustering\n#unsupervised-ml \n#definition \n#k-means\n#algorithm </p>\n"
  },
  {
    "title": "Confidence measure of predictions",
    "body": "A confidence measure in computer science refers to the likelihood of a certain outcome occurring, given a set of conditions or antecedents. It is used to provide a reliability measure for rules or predictions.\n\nA Confidence Score is a number between 0 and 1 that represents the likelihood that the output of a Machine Learning model is correct and will satisfy a request. The output of all Machine Learning (ML) systems is composed of one or multiple predictions.\n![[Pasted image 20240916170409.png]]\nMore: https://medium.com/voice-tech-global/machine-learning-confidence-scores-all-you-need-to-know-as-a-conversation-designer-8babd39caae7\n\n#ML \n#definition \n#confidence-score\n#confidence-measure",
    "tags": [
      "ML",
      "definition",
      "confidence"
    ],
    "htmlContent": "<p>A confidence measure in computer science refers to the likelihood of a certain outcome occurring, given a set of conditions or antecedents. It is used to provide a reliability measure for rules or predictions.</p>\n<p>A Confidence Score is a number between 0 and 1 that represents the likelihood that the output of a Machine Learning model is correct and will satisfy a request. The output of all Machine Learning (ML) systems is composed of one or multiple predictions.\n![[Pasted image 20240916170409.png]]\nMore: <a href=\"https://medium.com/voice-tech-global/machine-learning-confidence-scores-all-you-need-to-know-as-a-conversation-designer-8babd39caae7\">https://medium.com/voice-tech-global/machine-learning-confidence-scores-all-you-need-to-know-as-a-conversation-designer-8babd39caae7</a></p>\n<p>#ML \n#definition \n#confidence-score\n#confidence-measure</p>\n"
  },
  {
    "title": "Confusion matrix",
    "body": "A confusion matrix is a table that summarizes the performance of a classification model by comparing its predicted labels to the true labels. It displays the number of true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN) of the model's predictions.\n\n![[Pasted image 20240915134226.png]]\n\nMore: https://www.evidentlyai.com/classification-metrics/confusion-matrix#what-is-a-confusion-matrix\n\n#ML \n#definition \n#article \n#supervised-ml \n#confusion-matrix\n#classification-model\n#model-prediction",
    "tags": [
      "what",
      "ML",
      "definition",
      "article",
      "supervised",
      "confusion",
      "classification",
      "model"
    ],
    "htmlContent": "<p>A confusion matrix is a table that summarizes the performance of a classification model by comparing its predicted labels to the true labels. It displays the number of true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN) of the model&#39;s predictions.</p>\n<p>![[Pasted image 20240915134226.png]]</p>\n<p>More: <a href=\"https://www.evidentlyai.com/classification-metrics/confusion-matrix#what-is-a-confusion-matrix\">https://www.evidentlyai.com/classification-metrics/confusion-matrix#what-is-a-confusion-matrix</a></p>\n<p>#ML \n#definition \n#article \n#supervised-ml \n#confusion-matrix\n#classification-model\n#model-prediction</p>\n"
  },
  {
    "title": "Constraint Satisfaction Problems",
    "body": "Constraint Satisfaction Problem (CSP) is a fundamental topic in artificial intelligence (AI) that deals with solving problems by identifying constraints and finding solutions that satisfy those constraints.\n\nFinding a solution that meets a set of constraints is the goal of constraint satisfaction problems (CSPs), a type of AI issue. Finding values for a group of variables that fulfill a set of restrictions or rules is the aim of constraint satisfaction problems. For tasks including resource allocation, planning, scheduling, and decision-making, CSPs are frequently employed in AI.\n\nCSP has a wide range of applications, including scheduling, resource allocation, and automated reasoning.\n\nMore: \n* https://www.geeksforgeeks.org/constraint-satisfaction-problems-csp-in-artificial-intelligence/\n\n#AI \n#constrain-satisfaction-problems\n#definition \n#article \n#planning\n#scheduling\n#decision-making\n",
    "tags": [
      "AI",
      "constrain",
      "definition",
      "article",
      "planning",
      "scheduling",
      "decision"
    ],
    "htmlContent": "<p>Constraint Satisfaction Problem (CSP) is a fundamental topic in artificial intelligence (AI) that deals with solving problems by identifying constraints and finding solutions that satisfy those constraints.</p>\n<p>Finding a solution that meets a set of constraints is the goal of constraint satisfaction problems (CSPs), a type of AI issue. Finding values for a group of variables that fulfill a set of restrictions or rules is the aim of constraint satisfaction problems. For tasks including resource allocation, planning, scheduling, and decision-making, CSPs are frequently employed in AI.</p>\n<p>CSP has a wide range of applications, including scheduling, resource allocation, and automated reasoning.</p>\n<p>More: </p>\n<ul>\n<li><a href=\"https://www.geeksforgeeks.org/constraint-satisfaction-problems-csp-in-artificial-intelligence/\">https://www.geeksforgeeks.org/constraint-satisfaction-problems-csp-in-artificial-intelligence/</a></li>\n</ul>\n<p>#AI \n#constrain-satisfaction-problems\n#definition \n#article \n#planning\n#scheduling\n#decision-making</p>\n"
  },
  {
    "title": "Convolutional Neural Networks",
    "body": "Convolutional Neural Networks (CNNs) are a specialized type of neural network designed to process and analyze visual data. They are particularly effective for tasks involving image recognition, classification, and other forms of visual pattern recognition. Here's a detailed definition:\n\n### Convolutional Neural Networks (CNNs)\n\n**Definition:**\nA Convolutional Neural Network (CNN) is a class of deep neural networks that is designed to automatically and adaptively learn spatial hierarchies of features from data, especially images. CNNs utilize convolutional layers to process and extract features from input data, followed by pooling layers to reduce dimensionality and computational complexity. The final layers are often fully connected layers that perform classification or regression based on the features learned by the network.\n\n**Key Components of CNNs:**\n\n1. **Convolutional Layers:**\n   - **Purpose:** To detect and learn local features from the input data using filters (or kernels).\n   - **Operation:** Convolutional layers apply filters to the input image (or previous layer's output) to produce feature maps. Each filter detects specific features like edges, textures, or patterns.\n   - **Result:** The result of a convolution operation is a set of feature maps that highlight different aspects of the input data.\n\n2. **Activation Functions:**\n   - **Purpose:** To introduce non-linearity into the network, allowing it to learn more complex patterns.\n   - **Common Activation Function:** Rectified Linear Unit (ReLU), which replaces negative values with zero and keeps positive values unchanged.\n\n3. **Pooling Layers:**\n   - **Purpose:** To reduce the spatial dimensions of the feature maps, thereby decreasing the number of parameters and computation, and to make the network more robust to variations in the input.\n   - **Operation:** Pooling operations like max pooling (taking the maximum value in a region) or average pooling (taking the average value) are applied to reduce the size of feature maps.\n\n4. **Fully Connected Layers:**\n   - **Purpose:** To combine the features extracted by convolutional and pooling layers to make predictions.\n   - **Operation:** After flattening the output from the convolutional and pooling layers, the data is passed through one or more fully connected layers (dense layers) where each neuron is connected to every neuron in the previous layer.\n\n5. **Output Layer:**\n   - **Purpose:** To produce the final prediction or classification.\n   - **Operation:** Typically, a softmax layer is used for classification tasks to output probabilities for each class.\n\n**Advantages of CNNs:**\n- **Automatic Feature Extraction:** CNNs automatically learn hierarchical feature representations from raw data, reducing the need for manual feature engineering.\n- **Parameter Sharing:** Filters are applied across the entire input, reducing the number of parameters compared to fully connected networks.\n- **Spatial Hierarchies:** CNNs effectively capture spatial hierarchies in data, which is crucial for image and pattern recognition.\n\n**Applications:**\n- **Image Classification:** Identifying objects or categories in images.\n- **Object Detection:** Locating and classifying objects within images.\n- **Segmentation:** Dividing an image into regions based on different features.\n- **Video Analysis:** Analyzing sequences of images to detect patterns or actions.\n\nCNNs are a foundational technology in modern computer vision and have been widely adopted for tasks involving image and video data.\n\n#AI \n#CNN\n#computer-vision\n#definition \n#article \n#NN \n#DNN\n",
    "tags": [
      "**Automatic Feature Extraction:** CNNs automatically learn hierarchical feature representations from raw data, reducing the need for manual feature engineering.",
      "**Parameter Sharing:** Filters are applied across the entire input, reducing the number of parameters compared to fully connected networks.",
      "**Spatial Hierarchies:** CNNs effectively capture spatial hierarchies in data, which is crucial for image and pattern recognition.",
      "**Image Classification:** Identifying objects or categories in images.",
      "**Object Detection:** Locating and classifying objects within images.",
      "**Segmentation:** Dividing an image into regions based on different features.",
      "**Video Analysis:** Analyzing sequences of images to detect patterns or actions.",
      "AI",
      "CNN",
      "computer",
      "definition",
      "article",
      "NN",
      "DNN"
    ],
    "htmlContent": "<p>Convolutional Neural Networks (CNNs) are a specialized type of neural network designed to process and analyze visual data. They are particularly effective for tasks involving image recognition, classification, and other forms of visual pattern recognition. Here&#39;s a detailed definition:</p>\n<h3>Convolutional Neural Networks (CNNs)</h3>\n<p><strong>Definition:</strong>\nA Convolutional Neural Network (CNN) is a class of deep neural networks that is designed to automatically and adaptively learn spatial hierarchies of features from data, especially images. CNNs utilize convolutional layers to process and extract features from input data, followed by pooling layers to reduce dimensionality and computational complexity. The final layers are often fully connected layers that perform classification or regression based on the features learned by the network.</p>\n<p><strong>Key Components of CNNs:</strong></p>\n<ol>\n<li><p><strong>Convolutional Layers:</strong></p>\n<ul>\n<li><strong>Purpose:</strong> To detect and learn local features from the input data using filters (or kernels).</li>\n<li><strong>Operation:</strong> Convolutional layers apply filters to the input image (or previous layer&#39;s output) to produce feature maps. Each filter detects specific features like edges, textures, or patterns.</li>\n<li><strong>Result:</strong> The result of a convolution operation is a set of feature maps that highlight different aspects of the input data.</li>\n</ul>\n</li>\n<li><p><strong>Activation Functions:</strong></p>\n<ul>\n<li><strong>Purpose:</strong> To introduce non-linearity into the network, allowing it to learn more complex patterns.</li>\n<li><strong>Common Activation Function:</strong> Rectified Linear Unit (ReLU), which replaces negative values with zero and keeps positive values unchanged.</li>\n</ul>\n</li>\n<li><p><strong>Pooling Layers:</strong></p>\n<ul>\n<li><strong>Purpose:</strong> To reduce the spatial dimensions of the feature maps, thereby decreasing the number of parameters and computation, and to make the network more robust to variations in the input.</li>\n<li><strong>Operation:</strong> Pooling operations like max pooling (taking the maximum value in a region) or average pooling (taking the average value) are applied to reduce the size of feature maps.</li>\n</ul>\n</li>\n<li><p><strong>Fully Connected Layers:</strong></p>\n<ul>\n<li><strong>Purpose:</strong> To combine the features extracted by convolutional and pooling layers to make predictions.</li>\n<li><strong>Operation:</strong> After flattening the output from the convolutional and pooling layers, the data is passed through one or more fully connected layers (dense layers) where each neuron is connected to every neuron in the previous layer.</li>\n</ul>\n</li>\n<li><p><strong>Output Layer:</strong></p>\n<ul>\n<li><strong>Purpose:</strong> To produce the final prediction or classification.</li>\n<li><strong>Operation:</strong> Typically, a softmax layer is used for classification tasks to output probabilities for each class.</li>\n</ul>\n</li>\n</ol>\n<p><strong>Advantages of CNNs:</strong></p>\n<ul>\n<li><strong>Automatic Feature Extraction:</strong> CNNs automatically learn hierarchical feature representations from raw data, reducing the need for manual feature engineering.</li>\n<li><strong>Parameter Sharing:</strong> Filters are applied across the entire input, reducing the number of parameters compared to fully connected networks.</li>\n<li><strong>Spatial Hierarchies:</strong> CNNs effectively capture spatial hierarchies in data, which is crucial for image and pattern recognition.</li>\n</ul>\n<p><strong>Applications:</strong></p>\n<ul>\n<li><strong>Image Classification:</strong> Identifying objects or categories in images.</li>\n<li><strong>Object Detection:</strong> Locating and classifying objects within images.</li>\n<li><strong>Segmentation:</strong> Dividing an image into regions based on different features.</li>\n<li><strong>Video Analysis:</strong> Analyzing sequences of images to detect patterns or actions.</li>\n</ul>\n<p>CNNs are a foundational technology in modern computer vision and have been widely adopted for tasks involving image and video data.</p>\n<p>#AI \n#CNN\n#computer-vision\n#definition \n#article \n#NN \n#DNN</p>\n"
  },
  {
    "title": "Creating a training pipeline",
    "body": "A training pipeline is a series of steps or processes that takes input features and labels (for supervised ML algorithms), and produces a model as output. A training pipeline typically reads training data from a feature store, performs model-dependent transformations, trains the model, and evaluates the model before the model is saved to a model registry. If model evaluation is complex, it can also be performed after the model has been saved in a model registry. \n\nMore:\n* https://www.hopsworks.ai/dictionary/training-pipeline\n* https://mlmax.readthedocs.io/en/latest/INFERENCE.html\n* https://hectormrejia.medium.com/save-time-by-building-a-continuous-training-pipeline-for-ml-part-1-799e95d7c0ec\n\n#ML \n#training-pipeline\n#supervised-ml \n#article \n#definition ",
    "tags": [
      "ML",
      "training",
      "supervised",
      "article",
      "definition"
    ],
    "htmlContent": "<p>A training pipeline is a series of steps or processes that takes input features and labels (for supervised ML algorithms), and produces a model as output. A training pipeline typically reads training data from a feature store, performs model-dependent transformations, trains the model, and evaluates the model before the model is saved to a model registry. If model evaluation is complex, it can also be performed after the model has been saved in a model registry. </p>\n<p>More:</p>\n<ul>\n<li><a href=\"https://www.hopsworks.ai/dictionary/training-pipeline\">https://www.hopsworks.ai/dictionary/training-pipeline</a></li>\n<li><a href=\"https://mlmax.readthedocs.io/en/latest/INFERENCE.html\">https://mlmax.readthedocs.io/en/latest/INFERENCE.html</a></li>\n<li><a href=\"https://hectormrejia.medium.com/save-time-by-building-a-continuous-training-pipeline-for-ml-part-1-799e95d7c0ec\">https://hectormrejia.medium.com/save-time-by-building-a-continuous-training-pipeline-for-ml-part-1-799e95d7c0ec</a></li>\n</ul>\n<p>#ML \n#training-pipeline\n#supervised-ml \n#article \n#definition </p>\n"
  },
  {
    "title": "Decision Tree Classifier",
    "body": "A decision tree classifier is a well-liked and adaptable machine learning approach for classification applications. It creates a model in the shape of a tree structure, with each internal node standing in for a “decision” based on a feature, each branch for the decision’s result, and each leaf node for a regression value or class label. Decision trees are the fundamental components of random forests.\n\nThe Decision Tree Classifier algorithm can be broken down into three main steps:\n\n1. Root Node Selection: The algorithm starts by selecting the root node, which represents the entire dataset.\n2. Feature Selection: At each internal node, the algorithm selects the most informative feature to split the data. This is typically done using a metric such as information gain or Gini impurity.\n3. Splitting: The algorithm splits the data into two subsets based on the selected feature and a threshold value.\n4. Recursion: Steps 2 and 3 are repeated recursively until a stopping criterion is reached, such as a maximum depth or a minimum number of samples.\n\nNB: *Gini impurity* **measures how often a randomly chosen element of a set would be incorrectly labeled if it were labeled randomly and independently according to the distribution of labels in the set**. It reaches its minimum (zero) when all cases in the node fall into a single target category.\n\nMore: https://www.learndatasci.com/glossary/gini-impurity/\n\n#ML \n#decision-tree\n#algorithm \n#article \n#gini-impurity\n#classifier ",
    "tags": [
      "ML",
      "decision",
      "algorithm",
      "article",
      "gini",
      "classifier"
    ],
    "htmlContent": "<p>A decision tree classifier is a well-liked and adaptable machine learning approach for classification applications. It creates a model in the shape of a tree structure, with each internal node standing in for a “decision” based on a feature, each branch for the decision’s result, and each leaf node for a regression value or class label. Decision trees are the fundamental components of random forests.</p>\n<p>The Decision Tree Classifier algorithm can be broken down into three main steps:</p>\n<ol>\n<li>Root Node Selection: The algorithm starts by selecting the root node, which represents the entire dataset.</li>\n<li>Feature Selection: At each internal node, the algorithm selects the most informative feature to split the data. This is typically done using a metric such as information gain or Gini impurity.</li>\n<li>Splitting: The algorithm splits the data into two subsets based on the selected feature and a threshold value.</li>\n<li>Recursion: Steps 2 and 3 are repeated recursively until a stopping criterion is reached, such as a maximum depth or a minimum number of samples.</li>\n</ol>\n<p>NB: <em>Gini impurity</em> <strong>measures how often a randomly chosen element of a set would be incorrectly labeled if it were labeled randomly and independently according to the distribution of labels in the set</strong>. It reaches its minimum (zero) when all cases in the node fall into a single target category.</p>\n<p>More: <a href=\"https://www.learndatasci.com/glossary/gini-impurity/\">https://www.learndatasci.com/glossary/gini-impurity/</a></p>\n<p>#ML \n#decision-tree\n#algorithm \n#article \n#gini-impurity\n#classifier </p>\n"
  },
  {
    "title": "Decision Trees",
    "body": "A decision tree is a non-parametric supervised learning algorithm, which is utilized for both classification and regression tasks. It has a hierarchical, tree structure, which consists of a root node, branches, internal nodes and leaf nodes.\n\n![[Pasted image 20240915205737.png]]\n\n#ML \n#algorithm \n#definition \n#supervised-ml ",
    "tags": [
      "ML",
      "algorithm",
      "definition",
      "supervised"
    ],
    "htmlContent": "<p>A decision tree is a non-parametric supervised learning algorithm, which is utilized for both classification and regression tasks. It has a hierarchical, tree structure, which consists of a root node, branches, internal nodes and leaf nodes.</p>\n<p>![[Pasted image 20240915205737.png]]</p>\n<p>#ML \n#algorithm \n#definition \n#supervised-ml </p>\n"
  },
  {
    "title": "Ensemble Learning",
    "body": "Ensemble learning (techniques) combines multiple learners to improve predictive performance. It has been adopted in response to issues resulting from limited datasets.\n\nEnsemble means ‘a collection of things’ and in Machine Learning terminology, Ensemble learning refers to the approach of combining multiple ML models to produce a more accurate and robust prediction compared to any individual model. It implements an ensemble of fast algorithms (classifiers) such as decision trees for learning and allows them to vote.\n\nSupervised learning algorithms perform the task of searching through a hypothesis space to find a suitable hypothesis that will make good predictions with a particular problem. Even if the hypothesis space contains hypotheses that are very well-suited for a particular problem, it may be very difficult to find a good one. Ensembles combine multiple hypotheses to form a (hopefully) better hypothesis.\n\nEnsemble learning trains two or more Machine Learning algorithms to a specific classification or regression task.\n\nMore: \n* https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-for-ensemble-models/\n* https://www.ibm.com/topics/ensemble-learning\n\n#ML \n#definition \n#supervised-ml \n#ensemble-learning\n#ml-technique",
    "tags": [
      "ML",
      "definition",
      "supervised",
      "ensemble",
      "ml"
    ],
    "htmlContent": "<p>Ensemble learning (techniques) combines multiple learners to improve predictive performance. It has been adopted in response to issues resulting from limited datasets.</p>\n<p>Ensemble means ‘a collection of things’ and in Machine Learning terminology, Ensemble learning refers to the approach of combining multiple ML models to produce a more accurate and robust prediction compared to any individual model. It implements an ensemble of fast algorithms (classifiers) such as decision trees for learning and allows them to vote.</p>\n<p>Supervised learning algorithms perform the task of searching through a hypothesis space to find a suitable hypothesis that will make good predictions with a particular problem. Even if the hypothesis space contains hypotheses that are very well-suited for a particular problem, it may be very difficult to find a good one. Ensembles combine multiple hypotheses to form a (hopefully) better hypothesis.</p>\n<p>Ensemble learning trains two or more Machine Learning algorithms to a specific classification or regression task.</p>\n<p>More: </p>\n<ul>\n<li><a href=\"https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-for-ensemble-models/\">https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-for-ensemble-models/</a></li>\n<li><a href=\"https://www.ibm.com/topics/ensemble-learning\">https://www.ibm.com/topics/ensemble-learning</a></li>\n</ul>\n<p>#ML \n#definition \n#supervised-ml \n#ensemble-learning\n#ml-technique</p>\n"
  },
  {
    "title": "Evolutionary and genetic algorithms",
    "body": " An Evolutionary Algorithm is a collection of techniques inspired by the way biological life evolves through the process of reproduction, mutation, recombination (crossover), natural selection, and survival of the fittest. Evolutionary Algorithms consist of a variety of techniques but the principle behind them is the same. Evolutionary Algorithm techniques are often useful for search and optimisation. The general sub-areas of Evolutionary Algorithms include:\n\n    Genetic Algorithm\n    Genetic Programming\n    Evolutionary Programming\n    Evolutionary Strategies\n    Learning Classifier Systems\n    Neuro-Evolution Algorithms\n\nMore:\n* https://www.linkedin.com/pulse/introduction-evolutionary-algorithms-genetic-algorithm-khazab/\n* https://alexandremundim.medium.com/how-do-evolutionary-algorithms-differ-from-each-other-4af8f8f5a682\n\n#AI \n#definition \n#article \n#evolutionary-algorithm\n#genetic-algorithm\n#learning-classifier-systems\n#neuro-evolution-algorithm\n",
    "tags": [
      "AI",
      "definition",
      "article",
      "evolutionary",
      "genetic",
      "learning",
      "neuro"
    ],
    "htmlContent": "<p> An Evolutionary Algorithm is a collection of techniques inspired by the way biological life evolves through the process of reproduction, mutation, recombination (crossover), natural selection, and survival of the fittest. Evolutionary Algorithms consist of a variety of techniques but the principle behind them is the same. Evolutionary Algorithm techniques are often useful for search and optimisation. The general sub-areas of Evolutionary Algorithms include:</p>\n<pre><code>Genetic Algorithm\nGenetic Programming\nEvolutionary Programming\nEvolutionary Strategies\nLearning Classifier Systems\nNeuro-Evolution Algorithms\n</code></pre>\n<p>More:</p>\n<ul>\n<li><a href=\"https://www.linkedin.com/pulse/introduction-evolutionary-algorithms-genetic-algorithm-khazab/\">https://www.linkedin.com/pulse/introduction-evolutionary-algorithms-genetic-algorithm-khazab/</a></li>\n<li><a href=\"https://alexandremundim.medium.com/how-do-evolutionary-algorithms-differ-from-each-other-4af8f8f5a682\">https://alexandremundim.medium.com/how-do-evolutionary-algorithms-differ-from-each-other-4af8f8f5a682</a></li>\n</ul>\n<p>#AI \n#definition \n#article \n#evolutionary-algorithm\n#genetic-algorithm\n#learning-classifier-systems\n#neuro-evolution-algorithm</p>\n"
  },
  {
    "title": "Extremely Random Forests",
    "body": "Random forests or random decision forests is an ensemble learning method for classification, regression and other tasks that operates by constructing a multitude of decision trees at training time. For classification tasks, the output of the random forest is the class selected by most trees. For regression tasks, the mean or average prediction of the individual trees is returned. Random decision forests correct for decision trees' habit of overfitting to their training set.\n\nThe main difference between random forests and extra trees (usually called extreme random forests) lies in the fact that, instead of computing the locally optimal feature/split combination (for the random forest), for each feature under consideration, a random value is selected for the split (for the extra trees).\n\n**Extra Trees** and **Random Forest** are two very similar ensemble methods and often a doubt arises as to whether to use one or the other.\n\n![[Pasted image 20240916163640.png]]\n\n\nMore: \n* https://www.kaggle.com/code/hkapoor/random-forest-vs-extra-trees\n* https://www.linkedin.com/pulse/extremely-randomized-trees-leonardo-anello/\n* https://quantdare.com/what-is-the-difference-between-extra-trees-and-random-forest/\n\n#ML \n#random-forest\n#extreme-random-forest\n#definition \n#decision-tree \n#definition ",
    "tags": [
      "ML",
      "random",
      "extreme",
      "definition",
      "decision"
    ],
    "htmlContent": "<p>Random forests or random decision forests is an ensemble learning method for classification, regression and other tasks that operates by constructing a multitude of decision trees at training time. For classification tasks, the output of the random forest is the class selected by most trees. For regression tasks, the mean or average prediction of the individual trees is returned. Random decision forests correct for decision trees&#39; habit of overfitting to their training set.</p>\n<p>The main difference between random forests and extra trees (usually called extreme random forests) lies in the fact that, instead of computing the locally optimal feature/split combination (for the random forest), for each feature under consideration, a random value is selected for the split (for the extra trees).</p>\n<p><strong>Extra Trees</strong> and <strong>Random Forest</strong> are two very similar ensemble methods and often a doubt arises as to whether to use one or the other.</p>\n<p>![[Pasted image 20240916163640.png]]</p>\n<p>More: </p>\n<ul>\n<li><a href=\"https://www.kaggle.com/code/hkapoor/random-forest-vs-extra-trees\">https://www.kaggle.com/code/hkapoor/random-forest-vs-extra-trees</a></li>\n<li><a href=\"https://www.linkedin.com/pulse/extremely-randomized-trees-leonardo-anello/\">https://www.linkedin.com/pulse/extremely-randomized-trees-leonardo-anello/</a></li>\n<li><a href=\"https://quantdare.com/what-is-the-difference-between-extra-trees-and-random-forest/\">https://quantdare.com/what-is-the-difference-between-extra-trees-and-random-forest/</a></li>\n</ul>\n<p>#ML \n#random-forest\n#extreme-random-forest\n#definition \n#decision-tree \n#definition </p>\n"
  },
  {
    "title": "Finding similar users using collaborative filtering",
    "body": "\nCollaborative Filtering is the most common technique used when it comes to building intelligent recommender systems that can learn to give better recommendations as more information about users is collected.\n\nCollaborative filtering is a technique that can filter out items that a user might like on the basis of reactions by similar users.\n\n![[Pasted image 20240916184254.png]]\n\nMore:\n* https://medium.com/@kunalmahadik27/collaborative-filtering-for-recommender-systems-34b9135ce07b\n* https://medium.com/@deepapandithu/recommender-system-user-collaborative-filtering-37613f0c6a9\n* https://www.geeksforgeeks.org/user-based-collaborative-filtering/\n\n\n#ML \n#recommender-system\n#collaborative-filtering\n#article \n#definition ",
    "tags": [
      "ML",
      "recommender",
      "collaborative",
      "article",
      "definition"
    ],
    "htmlContent": "<p>Collaborative Filtering is the most common technique used when it comes to building intelligent recommender systems that can learn to give better recommendations as more information about users is collected.</p>\n<p>Collaborative filtering is a technique that can filter out items that a user might like on the basis of reactions by similar users.</p>\n<p>![[Pasted image 20240916184254.png]]</p>\n<p>More:</p>\n<ul>\n<li><a href=\"https://medium.com/@kunalmahadik27/collaborative-filtering-for-recommender-systems-34b9135ce07b\">https://medium.com/@kunalmahadik27/collaborative-filtering-for-recommender-systems-34b9135ce07b</a></li>\n<li><a href=\"https://medium.com/@deepapandithu/recommender-system-user-collaborative-filtering-37613f0c6a9\">https://medium.com/@deepapandithu/recommender-system-user-collaborative-filtering-37613f0c6a9</a></li>\n<li><a href=\"https://www.geeksforgeeks.org/user-based-collaborative-filtering/\">https://www.geeksforgeeks.org/user-based-collaborative-filtering/</a></li>\n</ul>\n<p>#ML \n#recommender-system\n#collaborative-filtering\n#article \n#definition </p>\n"
  },
  {
    "title": "Fundamental concepts in genetic algorithms",
    "body": "\nGenetic Algorithms (GAs) are adaptive methods which may be used to solve search and optimisation problems. They are based on the genetic processes of biological organisms. Over many generations, natural populations evolve according to the principles of natural selection and survival of the fittest\", first clearly stated by Charles Darwin in The Origin of Species . By  mimicking this process, genetic algorithms are able to \"evolve\" solutions to real world problems, if they have been suitably encoded. \n\nOptimization algorithms execute iterative operations to come up with numerous solutions and then compare those to reach the optimum solution. While there are many sub-types of optimization algorithms, one of the most valuable, useful, and exciting types is Genetic Algorithm.\n\nMore:\n* https://www.tutorialspoint.com/genetic_algorithms/genetic_algorithms_fundamentals.htm\n* https://medium.com/@byanalytixlabs/a-complete-guide-to-genetic-algorithm-advantages-limitations-more-738e87427dbb\n\n#AI \n#algorithm \n#article \n#definition \n#genetic-algorithm ",
    "tags": [
      "AI",
      "algorithm",
      "article",
      "definition",
      "genetic"
    ],
    "htmlContent": "<p>Genetic Algorithms (GAs) are adaptive methods which may be used to solve search and optimisation problems. They are based on the genetic processes of biological organisms. Over many generations, natural populations evolve according to the principles of natural selection and survival of the fittest&quot;, first clearly stated by Charles Darwin in The Origin of Species . By  mimicking this process, genetic algorithms are able to &quot;evolve&quot; solutions to real world problems, if they have been suitably encoded. </p>\n<p>Optimization algorithms execute iterative operations to come up with numerous solutions and then compare those to reach the optimum solution. While there are many sub-types of optimization algorithms, one of the most valuable, useful, and exciting types is Genetic Algorithm.</p>\n<p>More:</p>\n<ul>\n<li><a href=\"https://www.tutorialspoint.com/genetic_algorithms/genetic_algorithms_fundamentals.htm\">https://www.tutorialspoint.com/genetic_algorithms/genetic_algorithms_fundamentals.htm</a></li>\n<li><a href=\"https://medium.com/@byanalytixlabs/a-complete-guide-to-genetic-algorithm-advantages-limitations-more-738e87427dbb\">https://medium.com/@byanalytixlabs/a-complete-guide-to-genetic-algorithm-advantages-limitations-more-738e87427dbb</a></li>\n</ul>\n<p>#AI \n#algorithm \n#article \n#definition \n#genetic-algorithm </p>\n"
  },
  {
    "title": "Gaussian Mixture Models",
    "body": "At its heart, Gaussian Mixture Models (GMM) operates on the principle that a complex, multi-modal distribution can be approximated by a combination of simpler Gaussian distributions, each representing a different cluster within the data.\n\nMore: \n* https://medium.com/@juanc.olamendy/understanding-gaussian-mixture-models-a-comprehensive-guide-df30af59ced7\n* https://builtin.com/articles/gaussian-mixture-model\n* https://deepchecks.com/glossary/gaussian-mixture-model/\n\n\n#ML \n#definition \n#gaussian-mixture\n#gmm \n#algorithm \n#unsupervised-ml ",
    "tags": [
      "ML",
      "definition",
      "gaussian",
      "gmm",
      "algorithm",
      "unsupervised"
    ],
    "htmlContent": "<p>At its heart, Gaussian Mixture Models (GMM) operates on the principle that a complex, multi-modal distribution can be approximated by a combination of simpler Gaussian distributions, each representing a different cluster within the data.</p>\n<p>More: </p>\n<ul>\n<li><a href=\"https://medium.com/@juanc.olamendy/understanding-gaussian-mixture-models-a-comprehensive-guide-df30af59ced7\">https://medium.com/@juanc.olamendy/understanding-gaussian-mixture-models-a-comprehensive-guide-df30af59ced7</a></li>\n<li><a href=\"https://builtin.com/articles/gaussian-mixture-model\">https://builtin.com/articles/gaussian-mixture-model</a></li>\n<li><a href=\"https://deepchecks.com/glossary/gaussian-mixture-model/\">https://deepchecks.com/glossary/gaussian-mixture-model/</a></li>\n</ul>\n<p>#ML \n#definition \n#gaussian-mixture\n#gmm \n#algorithm \n#unsupervised-ml </p>\n"
  },
  {
    "title": "General Problem Solver",
    "body": "Early AI program designed to simulate human problem-solving processes through a heuristic-based approach.\n\nDetailed Explanation: The General Problem Solver (GPS) was developed to demonstrate that a general-purpose problem-solving machine could tackle a wide variety of issues by using heuristics—rules of thumb that guide the search for solutions. GPS operates by representing problems in a formalized structure of goals and subgoals, transforming the initial state into the goal state through a sequence of operators. Its significance lies in pioneering the concept of problem-solving as a search process, influencing later AI research and development, particularly in areas like automated reasoning, planning, and cognitive simulation.\n\nSource: https://stacks.stanford.edu/file/druid:zk239tp3547/zk239tp3547.pdf\n\n#AI \n#article \n#definition \n#gps\n#general-problem-solver",
    "tags": [
      "AI",
      "article",
      "definition",
      "gps",
      "general"
    ],
    "htmlContent": "<p>Early AI program designed to simulate human problem-solving processes through a heuristic-based approach.</p>\n<p>Detailed Explanation: The General Problem Solver (GPS) was developed to demonstrate that a general-purpose problem-solving machine could tackle a wide variety of issues by using heuristics—rules of thumb that guide the search for solutions. GPS operates by representing problems in a formalized structure of goals and subgoals, transforming the initial state into the goal state through a sequence of operators. Its significance lies in pioneering the concept of problem-solving as a search process, influencing later AI research and development, particularly in areas like automated reasoning, planning, and cognitive simulation.</p>\n<p>Source: <a href=\"https://stacks.stanford.edu/file/druid:zk239tp3547/zk239tp3547.pdf\">https://stacks.stanford.edu/file/druid:zk239tp3547/zk239tp3547.pdf</a></p>\n<p>#AI \n#article \n#definition \n#gps\n#general-problem-solver</p>\n"
  },
  {
    "title": "Heuristic search",
    "body": "Heuristic search is a type of algorithm that is used to find the best solution to a problem by using a heuristic, or rule of thumb.\n\nIt is one of the core methods AI systems use to navigate problem-solving is through heuristic search techniques. These techniques are essential for tasks that involve finding the best path from a starting point to a goal state, such as in navigation systems, game playing, and optimization problems.\n\nHeuristics operates on the search space of a problem to find the best or closest-to-optimal solution via the use of systematic algorithms. In contrast to a brute-force approach, which checks all possible solutions exhaustively, a heuristic search method uses heuristic information to define a route that seems more plausible than the rest. Heuristics, in this case, refer to a set of criteria or rules of thumb that offer an estimate of a firm’s profitability. Utilizing heuristic guiding, the algorithms determine the balance between exploration and exploitation, and thus they can successfully tackle demanding issues. Therefore, they enable an efficient solution finding process.\n\nMore:\n* https://www.geeksforgeeks.org/heuristic-search-techniques-in-ai/\n* https://www.simplilearn.com/tutorials/artificial-intelligence-tutorial/heuristic-function-in-ai\n\n#AI \n#ML \n#definition \n#article \n#heuristic-search\n",
    "tags": [
      "AI",
      "ML",
      "definition",
      "article",
      "heuristic"
    ],
    "htmlContent": "<p>Heuristic search is a type of algorithm that is used to find the best solution to a problem by using a heuristic, or rule of thumb.</p>\n<p>It is one of the core methods AI systems use to navigate problem-solving is through heuristic search techniques. These techniques are essential for tasks that involve finding the best path from a starting point to a goal state, such as in navigation systems, game playing, and optimization problems.</p>\n<p>Heuristics operates on the search space of a problem to find the best or closest-to-optimal solution via the use of systematic algorithms. In contrast to a brute-force approach, which checks all possible solutions exhaustively, a heuristic search method uses heuristic information to define a route that seems more plausible than the rest. Heuristics, in this case, refer to a set of criteria or rules of thumb that offer an estimate of a firm’s profitability. Utilizing heuristic guiding, the algorithms determine the balance between exploration and exploitation, and thus they can successfully tackle demanding issues. Therefore, they enable an efficient solution finding process.</p>\n<p>More:</p>\n<ul>\n<li><a href=\"https://www.geeksforgeeks.org/heuristic-search-techniques-in-ai/\">https://www.geeksforgeeks.org/heuristic-search-techniques-in-ai/</a></li>\n<li><a href=\"https://www.simplilearn.com/tutorials/artificial-intelligence-tutorial/heuristic-function-in-ai\">https://www.simplilearn.com/tutorials/artificial-intelligence-tutorial/heuristic-function-in-ai</a></li>\n</ul>\n<p>#AI \n#ML \n#definition \n#article \n#heuristic-search</p>\n"
  },
  {
    "title": "Intelligent Agent",
    "body": "An intelligent agent is an autonomous entity which act upon an environment using sensors and actuators for achieving goals. An intelligent agent may learn from the environment to achieve their goals. A thermostat is an example of an intelligent agent.\n\nFollowing are the main four rules for an AI agent:\n\n- **Rule 1:** An AI agent must have the ability to perceive the environment.\n- **Rule 2:** The observation must be used to make decisions.\n- **Rule 3:** Decision should result in an action.\n- **Rule 4:** The action taken by an AI agent must be a rational action.\n\nIn terms of structure, an intelligent agent consists of architecture and an agent program, which implements the agent function—the mapping from percept histories to actions. The rationality of an agent is not about being omniscient or perfect but about making the best possible decisions given the available information and its understanding of the environment.\n\n#AI\n#definition\n#article\n#intelligent-agent\n\n",
    "tags": [
      "**Rule 1:** An AI agent must have the ability to perceive the environment.",
      "**Rule 2:** The observation must be used to make decisions.",
      "**Rule 3:** Decision should result in an action.",
      "**Rule 4:** The action taken by an AI agent must be a rational action.",
      "AI",
      "definition",
      "article",
      "intelligent"
    ],
    "htmlContent": "<p>An intelligent agent is an autonomous entity which act upon an environment using sensors and actuators for achieving goals. An intelligent agent may learn from the environment to achieve their goals. A thermostat is an example of an intelligent agent.</p>\n<p>Following are the main four rules for an AI agent:</p>\n<ul>\n<li><strong>Rule 1:</strong> An AI agent must have the ability to perceive the environment.</li>\n<li><strong>Rule 2:</strong> The observation must be used to make decisions.</li>\n<li><strong>Rule 3:</strong> Decision should result in an action.</li>\n<li><strong>Rule 4:</strong> The action taken by an AI agent must be a rational action.</li>\n</ul>\n<p>In terms of structure, an intelligent agent consists of architecture and an agent program, which implements the agent function—the mapping from percept histories to actions. The rationality of an agent is not about being omniscient or perfect but about making the best possible decisions given the available information and its understanding of the environment.</p>\n<p>#AI\n#definition\n#article\n#intelligent-agent</p>\n"
  },
  {
    "title": "Intro to artificial neural networks",
    "body": "In machine learning, a neural network (also artificial neural network or neural net, abbreviated ANN or NN) is a model inspired by the structure and function of biological neural networks in animal brains.\n\nA neural network is a machine learning program, or model, that makes decisions in a manner similar to the human brain, by using processes that mimic the way biological neurons work together to identify phenomena, weigh options and arrive at conclusions.\n\nMore:\n* https://www.ibm.com/topics/neural-networks\n* https://www.geeksforgeeks.org/artificial-neural-networks-and-its-applications/\n\n\n#AI \n#ML \n#neural-network\n#NN\n#ANN\n#definition \n#article ",
    "tags": [
      "AI",
      "ML",
      "neural",
      "NN",
      "ANN",
      "definition",
      "article"
    ],
    "htmlContent": "<p>In machine learning, a neural network (also artificial neural network or neural net, abbreviated ANN or NN) is a model inspired by the structure and function of biological neural networks in animal brains.</p>\n<p>A neural network is a machine learning program, or model, that makes decisions in a manner similar to the human brain, by using processes that mimic the way biological neurons work together to identify phenomena, weigh options and arrive at conclusions.</p>\n<p>More:</p>\n<ul>\n<li><a href=\"https://www.ibm.com/topics/neural-networks\">https://www.ibm.com/topics/neural-networks</a></li>\n<li><a href=\"https://www.geeksforgeeks.org/artificial-neural-networks-and-its-applications/\">https://www.geeksforgeeks.org/artificial-neural-networks-and-its-applications/</a></li>\n</ul>\n<p>#AI \n#ML \n#neural-network\n#NN\n#ANN\n#definition \n#article </p>\n"
  },
  {
    "title": "Label encoding",
    "body": "Label Encoding is a technique that is used to convert categorical columns into numerical ones so that they can be fitted by machine learning models which only take numerical data. It is an important pre-processing step in a machine-learning project.\n\nLabel encoding is suitable for categorical data where there is an inherent order or ranking among the categories. Specifically, it is appropriate for ordinal categorical data. Ordinal data is categorical data that has a clear order or ranking, meaning that one category is greater or smaller than another.\n\n| Height | Height |\n| ------ | ------ |\n| Tall   | 0      |\n| Medium | 1      |\n| Short  | 2      |\n\n#ML \n#supervised-ml \n#definition \n#label-encoding\n#categorical-data\n#ordinal-data\n",
    "tags": [
      "ML",
      "supervised",
      "definition",
      "label",
      "categorical",
      "ordinal"
    ],
    "htmlContent": "<p>Label Encoding is a technique that is used to convert categorical columns into numerical ones so that they can be fitted by machine learning models which only take numerical data. It is an important pre-processing step in a machine-learning project.</p>\n<p>Label encoding is suitable for categorical data where there is an inherent order or ranking among the categories. Specifically, it is appropriate for ordinal categorical data. Ordinal data is categorical data that has a clear order or ranking, meaning that one category is greater or smaller than another.</p>\n<table>\n<thead>\n<tr>\n<th>Height</th>\n<th>Height</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Tall</td>\n<td>0</td>\n</tr>\n<tr>\n<td>Medium</td>\n<td>1</td>\n</tr>\n<tr>\n<td>Short</td>\n<td>2</td>\n</tr>\n</tbody></table>\n<p>#ML \n#supervised-ml \n#definition \n#label-encoding\n#categorical-data\n#ordinal-data</p>\n"
  },
  {
    "title": "Learning models with Ensemble Learning",
    "body": "\nIn the realm of machine learning, we can categorize models into two fundamental groups: Base Models and Ensemble Models.\n\n- **Base Models:** These are individual machine learning models that are used independently to make predictions. For example, **decision trees, logistic regression, K-nearest neighbors (KNN), Support Vector Machines (SVM), linear regression,** and so on. Base models are often the building blocks of ensemble models.\n- **Ensemble Models:** The idea behind of ensemble models is to combine many **weak learners**( simple “building block” models) in order to obtain a **strong learner** (a single and potentially very powerful model).\n\nMore: https://www.geeksforgeeks.org/ensemble-classifier-data-mining/\n\n#ML \n#definition \n#supervised-ml \n#ensemble-learning\n#ml-technique\n#ml-model",
    "tags": [
      "**Base Models:** These are individual machine learning models that are used independently to make predictions. For example, **decision trees, logistic regression, K",
      "nearest neighbors (KNN), Support Vector Machines (SVM), linear regression,** and so on. Base models are often the building blocks of ensemble models.",
      "**Ensemble Models:** The idea behind of ensemble models is to combine many **weak learners**( simple “building block” models) in order to obtain a **strong learner** (a single and potentially very powerful model).",
      "ML",
      "definition",
      "supervised",
      "ensemble",
      "ml"
    ],
    "htmlContent": "<p>In the realm of machine learning, we can categorize models into two fundamental groups: Base Models and Ensemble Models.</p>\n<ul>\n<li><strong>Base Models:</strong> These are individual machine learning models that are used independently to make predictions. For example, <strong>decision trees, logistic regression, K-nearest neighbors (KNN), Support Vector Machines (SVM), linear regression,</strong> and so on. Base models are often the building blocks of ensemble models.</li>\n<li><strong>Ensemble Models:</strong> The idea behind of ensemble models is to combine many <strong>weak learners</strong>( simple “building block” models) in order to obtain a <strong>strong learner</strong> (a single and potentially very powerful model).</li>\n</ul>\n<p>More: <a href=\"https://www.geeksforgeeks.org/ensemble-classifier-data-mining/\">https://www.geeksforgeeks.org/ensemble-classifier-data-mining/</a></p>\n<p>#ML \n#definition \n#supervised-ml \n#ensemble-learning\n#ml-technique\n#ml-model</p>\n"
  },
  {
    "title": "Local search techniques",
    "body": "A local search algorithm in artificial intelligence is a type of optimization algorithm used to find the best solution to a problem by repeatedly making minor adjustments to an initial solution.\n\nA **local search algorithm** in artificial intelligence works by starting with an initial solution and then making minor adjustments to it in the hopes of discovering a better one. Every time the algorithm iterates, the current solution is assessed, and a small modification to the current solution creates a new solution. The current solution is then compared to the new one, and if the new one is superior, it replaces the old one. This process keeps going until a satisfactory answer is discovered or a predetermined stopping criterion is satisfied.\n\nMore:\n* https://www.scaler.com/topics/artificial-intelligence-tutorial/types-of-local-search-algorithm/\n* https://www.simplilearn.com/local-search-algorithms-in-ai-article\n* https://www.cs.cmu.edu/~./15281/coursenotes/localsearch/index.html\n\n#AI \n#local-search\n#definition \n#article \n#heuristic-search \n#optimization\n",
    "tags": [
      "AI",
      "local",
      "definition",
      "article",
      "heuristic",
      "optimization"
    ],
    "htmlContent": "<p>A local search algorithm in artificial intelligence is a type of optimization algorithm used to find the best solution to a problem by repeatedly making minor adjustments to an initial solution.</p>\n<p>A <strong>local search algorithm</strong> in artificial intelligence works by starting with an initial solution and then making minor adjustments to it in the hopes of discovering a better one. Every time the algorithm iterates, the current solution is assessed, and a small modification to the current solution creates a new solution. The current solution is then compared to the new one, and if the new one is superior, it replaces the old one. This process keeps going until a satisfactory answer is discovered or a predetermined stopping criterion is satisfied.</p>\n<p>More:</p>\n<ul>\n<li><a href=\"https://www.scaler.com/topics/artificial-intelligence-tutorial/types-of-local-search-algorithm/\">https://www.scaler.com/topics/artificial-intelligence-tutorial/types-of-local-search-algorithm/</a></li>\n<li><a href=\"https://www.simplilearn.com/local-search-algorithms-in-ai-article\">https://www.simplilearn.com/local-search-algorithms-in-ai-article</a></li>\n<li><a href=\"https://www.cs.cmu.edu/~./15281/coursenotes/localsearch/index.html\">https://www.cs.cmu.edu/~./15281/coursenotes/localsearch/index.html</a></li>\n</ul>\n<p>#AI \n#local-search\n#definition \n#article \n#heuristic-search \n#optimization</p>\n"
  },
  {
    "title": "Logic programming",
    "body": "Logic programming is a programming paradigm that is based on formal logic. In logic programming, programs are written in the form of logical statements or rules, which define relationships and constraints between different entities.\n\nUnlike other programming paradigms, such as functional programming and object-oriented programming, which focus on how to achieve a specific task, logic programming is concerned with representing and reasoning about knowledge.\n\nMore:\n* https://blogit.michelin.io/logic-programing-loves-data/\n* https://www.doc.ic.ac.uk/~cclw05/topics1/lp.html\n* https://www.linkedin.com/advice/0/how-can-you-solve-complex-problems-logic-programming\n\n#ML \n#logic-programming",
    "tags": [
      "ML",
      "logic"
    ],
    "htmlContent": "<p>Logic programming is a programming paradigm that is based on formal logic. In logic programming, programs are written in the form of logical statements or rules, which define relationships and constraints between different entities.</p>\n<p>Unlike other programming paradigms, such as functional programming and object-oriented programming, which focus on how to achieve a specific task, logic programming is concerned with representing and reasoning about knowledge.</p>\n<p>More:</p>\n<ul>\n<li><a href=\"https://blogit.michelin.io/logic-programing-loves-data/\">https://blogit.michelin.io/logic-programing-loves-data/</a></li>\n<li><a href=\"https://www.doc.ic.ac.uk/~cclw05/topics1/lp.html\">https://www.doc.ic.ac.uk/~cclw05/topics1/lp.html</a></li>\n<li><a href=\"https://www.linkedin.com/advice/0/how-can-you-solve-complex-problems-logic-programming\">https://www.linkedin.com/advice/0/how-can-you-solve-complex-problems-logic-programming</a></li>\n</ul>\n<p>#ML \n#logic-programming</p>\n"
  },
  {
    "title": "Logistic Regression classifier",
    "body": "Logistic regression is used for binary classification where we use sigmoid function (logistic function), that takes input as independent variables and produces a probability value between 0 and 1. \n\nIn machine learning, a classifier is an algorithm that automatically assigns data points to a range of categories or classes. Within the classifier category, there are two principal models: \n\n- Supervised: In the supervised model, classifiers train to make distinctions between labeled and unlabeled data. This training allows them to recognize patterns and ultimately operate autonomously without using labels.\n- Unsupervised: Unsupervised algorithms use pattern recognition to classify unlabeled datasets, progressively becoming more accurate.\n\nA logistic function (sometimes called the Verhulst model or logistic growth curve) is a mathematical function commonly used in Quality Assurance (QA) applications for nonlinear fitting. It is characterized by a sigmoidal (S-shaped) curve that can be adjusted with parameters to model various relationships between variables.\n![x(t)=1/(1+(1/(x_0)-1)e^(-rt)).](https://mathworld.wolfram.com/images/equations/LogisticEquation/NumberedEquation3.svg)\n\nThe function x(t) is sometimes known as the sigmoid function. \n\nThe logistic function is defined as:\n![[Pasted image 20240915125325.png]]\nThe logistic function maps the input _z_ to a value between 0 and 1, representing the estimated probability that the instance belongs to the positive class. For binary classification, if the estimated probability is greater than or equal to a chosen threshold (typically 0.5), the instance is predicted to belong to the positive class; otherwise, it is predicted to belong to the negative class.\n\nMore:\n* https://activewizards.com/blog/5-real-world-examples-of-logistic-regression-application\n* https://medium.com/@avicsebooks/ml-part-4-linear-classification-1d182c0b1eb3\n* https://www.geeksforgeeks.org/understanding-logistic-regression/\n* https://www.indeed.com/career-advice/career-development/classifiers-in-machine-learning\n\n#ML \n#definition \n#article \n#logistic-regression\n#sigmoid-function\n#logistic-function\n#supervised-ml \n#classifier\n#algorithm\n#supervised-ml ",
    "tags": [
      "Supervised: In the supervised model, classifiers train to make distinctions between labeled and unlabeled data. This training allows them to recognize patterns and ultimately operate autonomously without using labels.",
      "Unsupervised: Unsupervised algorithms use pattern recognition to classify unlabeled datasets, progressively becoming more accurate.",
      "ML",
      "definition",
      "article",
      "logistic",
      "sigmoid",
      "supervised",
      "classifier",
      "algorithm"
    ],
    "htmlContent": "<p>Logistic regression is used for binary classification where we use sigmoid function (logistic function), that takes input as independent variables and produces a probability value between 0 and 1. </p>\n<p>In machine learning, a classifier is an algorithm that automatically assigns data points to a range of categories or classes. Within the classifier category, there are two principal models: </p>\n<ul>\n<li>Supervised: In the supervised model, classifiers train to make distinctions between labeled and unlabeled data. This training allows them to recognize patterns and ultimately operate autonomously without using labels.</li>\n<li>Unsupervised: Unsupervised algorithms use pattern recognition to classify unlabeled datasets, progressively becoming more accurate.</li>\n</ul>\n<p>A logistic function (sometimes called the Verhulst model or logistic growth curve) is a mathematical function commonly used in Quality Assurance (QA) applications for nonlinear fitting. It is characterized by a sigmoidal (S-shaped) curve that can be adjusted with parameters to model various relationships between variables.\n<img src=\"https://mathworld.wolfram.com/images/equations/LogisticEquation/NumberedEquation3.svg\" alt=\"x(t)=1/(1+(1/(x_0)-1)e^(-rt)).\"></p>\n<p>The function x(t) is sometimes known as the sigmoid function. </p>\n<p>The logistic function is defined as:\n![[Pasted image 20240915125325.png]]\nThe logistic function maps the input <em>z</em> to a value between 0 and 1, representing the estimated probability that the instance belongs to the positive class. For binary classification, if the estimated probability is greater than or equal to a chosen threshold (typically 0.5), the instance is predicted to belong to the positive class; otherwise, it is predicted to belong to the negative class.</p>\n<p>More:</p>\n<ul>\n<li><a href=\"https://activewizards.com/blog/5-real-world-examples-of-logistic-regression-application\">https://activewizards.com/blog/5-real-world-examples-of-logistic-regression-application</a></li>\n<li><a href=\"https://medium.com/@avicsebooks/ml-part-4-linear-classification-1d182c0b1eb3\">https://medium.com/@avicsebooks/ml-part-4-linear-classification-1d182c0b1eb3</a></li>\n<li><a href=\"https://www.geeksforgeeks.org/understanding-logistic-regression/\">https://www.geeksforgeeks.org/understanding-logistic-regression/</a></li>\n<li><a href=\"https://www.indeed.com/career-advice/career-development/classifiers-in-machine-learning\">https://www.indeed.com/career-advice/career-development/classifiers-in-machine-learning</a></li>\n</ul>\n<p>#ML \n#definition \n#article \n#logistic-regression\n#sigmoid-function\n#logistic-function\n#supervised-ml \n#classifier\n#algorithm\n#supervised-ml </p>\n"
  },
  {
    "title": "ML Expert System",
    "body": "\n|                                                                         |     |\n| ----------------------------------------------------------------------- | --- |\n| **Chapter: 01 Introduction to Artificial Intelligence**                 |     |\n|                                                                         |     |\n| [[What is AI?]]                                                         |     |\n| [[Turing Test]]                                                         |     |\n| [[Rational Agent]]                                                      |     |\n| [[General Problem Solver]]                                              |     |\n| [[Intelligent Agent]]                                                   |     |\n|                                                                         |     |\n| [[AI and ML packages to use]]                                           |     |\n| [[A List of AI and ML Terms]]                                           |     |\n| [[AI Terms Dictionary URLs]]                                            |     |\n|                                                                         |     |\n| **Chapter: 02 Classification and Regression Using Supervised Learning** |     |\n| [[Supervised vs Unsupervised learning]]                                 |     |\n| [[Classification]]                                                      |     |\n| [[Processing Data]]                                                     |     |\n| [[Binarization]]                                                        |     |\n| [[Mean removal]]                                                        |     |\n| [[Scaling]]                                                             |     |\n| [[Normalization]]                                                       |     |\n| [[Label encoding]]                                                      |     |\n| [[Logistic Regression classifier]]                                      |     |\n| [[Naïve Bayes classifier]]                                              |     |\n| [[Confusion matrix]]                                                    |     |\n| [[Support Vector Machines]]                                             |     |\n| [[Classifying income data using Support Vector Machines]]               |     |\n| [[Regression]]                                                          |     |\n| [[Single Variable Regressor]]                                           |     |\n| [[Multivariable Regressor]]                                             |     |\n| [[Estimating housing prices using Support Vector Regressor]]            |     |\n|                                                                         |     |\n| Summary                                                                 |     |\n|                                                                         |     |\n|                                                                         |     |\n| **Chapter03: Predictive Analytics with Ensemble Learning**              |     |\n| [[Ensemble Learning]]                                                   |     |\n| [[Learning models with Ensemble Learning]]                              |     |\n| [[Decision Trees]]                                                      |     |\n| [[Decision Tree Classifier]]                                            |     |\n| [[Random Forests]]                                                      |     |\n| [[Extremely Random Forests]]                                            |     |\n| [[Confidence measure of predictions]]                                   |     |\n| [[Class imbalance]]                                                     |     |\n| [[Relative Feature Importance]]                                         |     |\n| [[Predicting traffic using Extremely Random Forest regressor]]          |     |\n|                                                                         |     |\n| Summary                                                                 |     |\n|                                                                         |     |\n|                                                                         |     |\n| **Chapter: 04 Detecting Patterns with Unsupervised Learning**           |     |\n| [[Unsupervised Learning]]                                               |     |\n| [[Clustering data with K-Means algorithm]]                              |     |\n| [[Number of clusters with Mean Shift algorithm]]                        |     |\n| [[Quality of clustering with silhouette scores]]                        |     |\n| [[Gaussian Mixture Models]]                                             |     |\n| [[Building a classifier based on Gaussian Mixture Models]]              |     |\n| [[Finding subgroups in stock market using Affinity Propagation model]]  |     |\n| [[Segmenting the market based on shopping patterns]]                    |     |\n|                                                                         |     |\n| Summary                                                                 |     |\n|                                                                         |     |\n|                                                                         |     |\n| **Chapter 05: Building Recommender Systems**                            |     |\n| [[Creating a training pipeline]]                                        |     |\n| [[Extracting the nearest neighbors]]                                    |     |\n| [[Building a K-Nearest Neighbors classifier]]                           |     |\n| [[Computing similarity scores]]                                         |     |\n| [[Finding similar users using collaborative filtering]]                 |     |\n| [[Building a movie recommendation system]]                              |     |\n|                                                                         |     |\n| Summary                                                                 |     |\n|                                                                         |     |\n|                                                                         |     |\n| **Chapter 06: Logic Programming**                                       |     |\n| [[Logic programming]]                                                   |     |\n| [[Understanding building blocks of logic programming]]                  |     |\n| [[Solving problems using logic programming]]                            |     |\n| Packages                                                                |     |\n| [[Matching math expression]]                                            |     |\n| [[Validating primes]]                                                   |     |\n| [[Parsing a family tree]]                                               |     |\n| [[Building a puzzle solver]]                                            |     |\n|                                                                         |     |\n| Summary                                                                 |     |\n|                                                                         |     |\n|                                                                         |     |\n| **Chapter 07: Heuristic Search Techniques**                             |     |\n| [[Heuristic search]]                                                    |     |\n| [[Uninformed vs Informed search]]                                       |     |\n| [[Constraint Satisfaction Problems]]                                    |     |\n| [[Local search techniques]]                                             |     |\n| [[Simulated Annealing]]                                                 |     |\n| [[Constructing a string using greedy search]]                           |     |\n| [[Solving the region-coloring problem]]                                 |     |\n| [[Building an 8-puzzle solver]]                                         |     |\n| [[Building a maze solver]]                                              |     |\n|                                                                         |     |\n| Summary                                                                 |     |\n|                                                                         |     |\n|                                                                         |     |\n| **Chapter 08: Generic Algorithms**                                      |     |\n| [[Evolutionary and genetic algorithms]]                                 |     |\n| [[Fundamental concepts in genetic algorithms]]                          |     |\n| [[Generating a bit pattern with predefined parameters]]                 |     |\n| [[Visualizing the evolution]]                                           |     |\n| [[Solving the symbol regression problem]]                               |     |\n| [[Building an intelligent robot controller]]                            |     |\n|                                                                         |     |\n| Summary                                                                 |     |\n|                                                                         |     |\n| **Chapter 09: Building Games With Artificial Intelligence**             |     |\n| [[Using search algorithms in games]]                                    |     |\n| [[Combinatorial search]]                                                |     |\n| [[Minimal algorithm]]                                                   |     |\n| [[Alpha-Beta pruning]]                                                  |     |\n| [[Negamax algorithm]]                                                   |     |\n| [[Installing easy AI library]]                                          |     |\n| [[Building a bot to play Last Coin Standing]]                           |     |\n| [[Building a bot to play Tic-Tac-Toe]]                                  |     |\n| [[Building two bots to play Connect Four against each other]]           |     |\n| [[Building two bots to play Hexapawn against each other]]               |     |\n|                                                                         |     |\n| Summary                                                                 |     |\n|                                                                         |     |\n| **Chapter 10: Natural Language Processing**                             |     |\n| Packages                                                                |     |\n| [[Tokenizing text data]]                                                |     |\n| [[Converting words to their base forms using stemming]]                 |     |\n| [[Converting words to their base forms using lemmatization]]            |     |\n| [[Dividing text data into chunks]]                                      |     |\n| [[Extracting the frequency of terms using a Bag of Words model]]        |     |\n| [[Building a category predictor]]                                       |     |\n| [[Constructing a gender identifier]]                                    |     |\n| [[Building a sentiment analyzer]]                                       |     |\n| [[Topic modeling using Latent Dirichlet Allocation]]                    |     |\n|                                                                         |     |\n| Summary                                                                 |     |\n|                                                                         |     |\n| **Chapter 11: Probabilistic Reasoning for Sequential Data**             |     |\n| [[Sequential data]]                                                     |     |\n| ==Handling time-series data with Pandas==                               |     |\n| [[Slicing time-series data]]                                            |     |\n| [[Operating on time-series data]]                                       |     |\n| [[Extracting statistics from time-series data]]                         |     |\n| [[Generating data using Hidden Markov Models]]                          |     |\n| [[Identifying alphabet sequences with Conditional Random Fields]]       |     |\n| [[Stock market analysis]]                                               |     |\n|                                                                         |     |\n| Summary                                                                 |     |\n|                                                                         |     |\n| **Chapter 12: Building A Speech Recognizer**                            |     |\n| [[Speech signals]]                                                      |     |\n| [[Visualizing audio signals]]                                           |     |\n| [[Transforming audio signals to the frequency domain]]                  |     |\n| [[Generating audio signals]]                                            |     |\n| [[Synthesizing tones to generate music]]                                |     |\n| [[Extracting speech features]]                                          |     |\n| [[Recognizing spoken words]]                                            |     |\n|                                                                         |     |\n| Summary                                                                 |     |\n|                                                                         |     |\n|                                                                         |     |\n| **Chapter 13: Object Detection and Tracking**                           |     |\n| Installing OpenCV                                                       |     |\n| [[Frame differencing]]                                                  |     |\n| [[Tracking objects using color spaces]]                                 |     |\n| [[Object tracking using background subtraction]]                        |     |\n| [[Building an interactive object tracker using the CAMShift algorithm]] |     |\n| [[Optical flow based tracking]]                                         |     |\n| [[Face detection and tracking]]                                         |     |\n| [[Using Haar cascades for object detection]]                            |     |\n| [[Using integral images for feature extraction]]                        |     |\n| [[Eye detection and tracking]]                                          |     |\n|                                                                         |     |\n| Summary                                                                 |     |\n|                                                                         |     |\n| **Chapter 14: Artificial Neural Networks**                              |     |\n| [[Intro to artificial neural networks]]                                 |     |\n| [[Building a neural network]]                                           |     |\n| [[Training a neural network]]                                           |     |\n| [[Building a Perception based classifier]]                              |     |\n| [[Constructing a single layer neural network]]                          |     |\n| [[Constructing a multilayer neural network]]                            |     |\n| [[Building a vector quantizer]]                                         |     |\n| [[Analyzing sequential data using recurrent neural networks]]           |     |\n| [[Visualizing characters in an Optical Character Recognition database]] |     |\n| [[Building an Optical Character Recognition engine]]                    |     |\n|                                                                         |     |\n| Summary                                                                 |     |\n|                                                                         |     |\n| **Chapter 15: Reinforcement Learning**                                  |     |\n| [[Understanding the premise]]                                           |     |\n| [[Reinforcement learning vs supervised learning]]                       |     |\n| [[Real world examples of reinforcement learning]]                       |     |\n| [[Building blocks of reinforcement learning]]                           |     |\n| [[Creating an environment]]                                             |     |\n| [[Building a learning agent]]                                           |     |\n|                                                                         |     |\n| Summary                                                                 |     |\n|                                                                         |     |\n| **Chapter 16: Deep Learning with Convolutional Neural Networks**        |     |\n| [[Convolutional Neural Networks]]                                       |     |\n| [[Architecture of CNN]]                                                 |     |\n| [[Types of layers in a CNN]]                                            |     |\n| [[Building a perceptron-based linear regressor]]                        |     |\n| [[Building an image classfier using a single layer neural network]]     |     |\n| [[Building an image classifier using a CNN]]                            |     |\n|                                                                         |     |\n| Summary                                                                 |     |\n",
    "tags": [],
    "htmlContent": "<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Chapter: 01 Introduction to Artificial Intelligence</strong></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>[[What is AI?]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Turing Test]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Rational Agent]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[General Problem Solver]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Intelligent Agent]]</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>[[AI and ML packages to use]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[A List of AI and ML Terms]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[AI Terms Dictionary URLs]]</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td><strong>Chapter: 02 Classification and Regression Using Supervised Learning</strong></td>\n<td></td>\n</tr>\n<tr>\n<td>[[Supervised vs Unsupervised learning]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Classification]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Processing Data]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Binarization]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Mean removal]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Scaling]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Normalization]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Label encoding]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Logistic Regression classifier]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Naïve Bayes classifier]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Confusion matrix]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Support Vector Machines]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Classifying income data using Support Vector Machines]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Regression]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Single Variable Regressor]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Multivariable Regressor]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Estimating housing prices using Support Vector Regressor]]</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Summary</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td><strong>Chapter03: Predictive Analytics with Ensemble Learning</strong></td>\n<td></td>\n</tr>\n<tr>\n<td>[[Ensemble Learning]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Learning models with Ensemble Learning]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Decision Trees]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Decision Tree Classifier]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Random Forests]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Extremely Random Forests]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Confidence measure of predictions]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Class imbalance]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Relative Feature Importance]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Predicting traffic using Extremely Random Forest regressor]]</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Summary</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td><strong>Chapter: 04 Detecting Patterns with Unsupervised Learning</strong></td>\n<td></td>\n</tr>\n<tr>\n<td>[[Unsupervised Learning]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Clustering data with K-Means algorithm]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Number of clusters with Mean Shift algorithm]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Quality of clustering with silhouette scores]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Gaussian Mixture Models]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Building a classifier based on Gaussian Mixture Models]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Finding subgroups in stock market using Affinity Propagation model]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Segmenting the market based on shopping patterns]]</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Summary</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td><strong>Chapter 05: Building Recommender Systems</strong></td>\n<td></td>\n</tr>\n<tr>\n<td>[[Creating a training pipeline]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Extracting the nearest neighbors]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Building a K-Nearest Neighbors classifier]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Computing similarity scores]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Finding similar users using collaborative filtering]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Building a movie recommendation system]]</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Summary</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td><strong>Chapter 06: Logic Programming</strong></td>\n<td></td>\n</tr>\n<tr>\n<td>[[Logic programming]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Understanding building blocks of logic programming]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Solving problems using logic programming]]</td>\n<td></td>\n</tr>\n<tr>\n<td>Packages</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Matching math expression]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Validating primes]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Parsing a family tree]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Building a puzzle solver]]</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Summary</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td><strong>Chapter 07: Heuristic Search Techniques</strong></td>\n<td></td>\n</tr>\n<tr>\n<td>[[Heuristic search]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Uninformed vs Informed search]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Constraint Satisfaction Problems]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Local search techniques]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Simulated Annealing]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Constructing a string using greedy search]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Solving the region-coloring problem]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Building an 8-puzzle solver]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Building a maze solver]]</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Summary</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td><strong>Chapter 08: Generic Algorithms</strong></td>\n<td></td>\n</tr>\n<tr>\n<td>[[Evolutionary and genetic algorithms]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Fundamental concepts in genetic algorithms]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Generating a bit pattern with predefined parameters]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Visualizing the evolution]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Solving the symbol regression problem]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Building an intelligent robot controller]]</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Summary</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td><strong>Chapter 09: Building Games With Artificial Intelligence</strong></td>\n<td></td>\n</tr>\n<tr>\n<td>[[Using search algorithms in games]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Combinatorial search]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Minimal algorithm]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Alpha-Beta pruning]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Negamax algorithm]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Installing easy AI library]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Building a bot to play Last Coin Standing]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Building a bot to play Tic-Tac-Toe]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Building two bots to play Connect Four against each other]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Building two bots to play Hexapawn against each other]]</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Summary</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td><strong>Chapter 10: Natural Language Processing</strong></td>\n<td></td>\n</tr>\n<tr>\n<td>Packages</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Tokenizing text data]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Converting words to their base forms using stemming]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Converting words to their base forms using lemmatization]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Dividing text data into chunks]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Extracting the frequency of terms using a Bag of Words model]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Building a category predictor]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Constructing a gender identifier]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Building a sentiment analyzer]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Topic modeling using Latent Dirichlet Allocation]]</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Summary</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td><strong>Chapter 11: Probabilistic Reasoning for Sequential Data</strong></td>\n<td></td>\n</tr>\n<tr>\n<td>[[Sequential data]]</td>\n<td></td>\n</tr>\n<tr>\n<td>==Handling time-series data with Pandas==</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Slicing time-series data]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Operating on time-series data]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Extracting statistics from time-series data]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Generating data using Hidden Markov Models]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Identifying alphabet sequences with Conditional Random Fields]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Stock market analysis]]</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Summary</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td><strong>Chapter 12: Building A Speech Recognizer</strong></td>\n<td></td>\n</tr>\n<tr>\n<td>[[Speech signals]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Visualizing audio signals]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Transforming audio signals to the frequency domain]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Generating audio signals]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Synthesizing tones to generate music]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Extracting speech features]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Recognizing spoken words]]</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Summary</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td><strong>Chapter 13: Object Detection and Tracking</strong></td>\n<td></td>\n</tr>\n<tr>\n<td>Installing OpenCV</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Frame differencing]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Tracking objects using color spaces]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Object tracking using background subtraction]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Building an interactive object tracker using the CAMShift algorithm]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Optical flow based tracking]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Face detection and tracking]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Using Haar cascades for object detection]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Using integral images for feature extraction]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Eye detection and tracking]]</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Summary</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td><strong>Chapter 14: Artificial Neural Networks</strong></td>\n<td></td>\n</tr>\n<tr>\n<td>[[Intro to artificial neural networks]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Building a neural network]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Training a neural network]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Building a Perception based classifier]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Constructing a single layer neural network]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Constructing a multilayer neural network]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Building a vector quantizer]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Analyzing sequential data using recurrent neural networks]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Visualizing characters in an Optical Character Recognition database]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Building an Optical Character Recognition engine]]</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Summary</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td><strong>Chapter 15: Reinforcement Learning</strong></td>\n<td></td>\n</tr>\n<tr>\n<td>[[Understanding the premise]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Reinforcement learning vs supervised learning]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Real world examples of reinforcement learning]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Building blocks of reinforcement learning]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Creating an environment]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Building a learning agent]]</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Summary</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td><strong>Chapter 16: Deep Learning with Convolutional Neural Networks</strong></td>\n<td></td>\n</tr>\n<tr>\n<td>[[Convolutional Neural Networks]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Architecture of CNN]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Types of layers in a CNN]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Building a perceptron-based linear regressor]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Building an image classfier using a single layer neural network]]</td>\n<td></td>\n</tr>\n<tr>\n<td>[[Building an image classifier using a CNN]]</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Summary</td>\n<td></td>\n</tr>\n</tbody></table>\n"
  },
  {
    "title": "Matching math expression",
    "body": "Logic Programming is often said to be declarative or descriptive and contrasts with the imperative or prescriptive approach to programming associated with traditional programming languages.\n\nIn imperative/prescriptive programming, the programmer provides a detailed operational\nprogram for a system in terms of internal processing details (such as data types and variable\nassignments). In writing such programs, programmers typically take into account information\nabout the intended application areas and goals of their programs, but that information is rarely\nrecorded in the resulting programs, except in the form of non-executable comments.\n\nIn declarative/descriptive programming, programmers explicitly encode information about the application area and the goals of the program, but they do not specify internal processing details, leaving it to the systems that execute those programs to decide on those details on their own.\n\nA logic program is a type of declarative program in that it describes the application area\nof the program and the goals the programmer would like to achieve. It focusses on what is true\nand what is wanted rather than how to achieve the desired goals. In this respect, a logic program\nis more of a specification than an implementation.\n\n**Matching Logic** allows us to regard a programming language through both operational and axiomatic lenses at the same time, making no distinction between the two. The semantics of a programming language is given in **Matching Logic** as a set of rewrite rules. Both operational behaviors and formal properties of a program are derived using the _language-independent_ proof system of **Matching Logic**.\n\nMore:\n* http://www.matching-logic.org/\n* https://www.numbas.org.uk/behind-the-design/pattern-matching.html\n\n#AI \n#definition \n#article \n#logic-programming ",
    "tags": [
      "AI",
      "definition",
      "article",
      "logic"
    ],
    "htmlContent": "<p>Logic Programming is often said to be declarative or descriptive and contrasts with the imperative or prescriptive approach to programming associated with traditional programming languages.</p>\n<p>In imperative/prescriptive programming, the programmer provides a detailed operational\nprogram for a system in terms of internal processing details (such as data types and variable\nassignments). In writing such programs, programmers typically take into account information\nabout the intended application areas and goals of their programs, but that information is rarely\nrecorded in the resulting programs, except in the form of non-executable comments.</p>\n<p>In declarative/descriptive programming, programmers explicitly encode information about the application area and the goals of the program, but they do not specify internal processing details, leaving it to the systems that execute those programs to decide on those details on their own.</p>\n<p>A logic program is a type of declarative program in that it describes the application area\nof the program and the goals the programmer would like to achieve. It focusses on what is true\nand what is wanted rather than how to achieve the desired goals. In this respect, a logic program\nis more of a specification than an implementation.</p>\n<p><strong>Matching Logic</strong> allows us to regard a programming language through both operational and axiomatic lenses at the same time, making no distinction between the two. The semantics of a programming language is given in <strong>Matching Logic</strong> as a set of rewrite rules. Both operational behaviors and formal properties of a program are derived using the <em>language-independent</em> proof system of <strong>Matching Logic</strong>.</p>\n<p>More:</p>\n<ul>\n<li><a href=\"http://www.matching-logic.org/\">http://www.matching-logic.org/</a></li>\n<li><a href=\"https://www.numbas.org.uk/behind-the-design/pattern-matching.html\">https://www.numbas.org.uk/behind-the-design/pattern-matching.html</a></li>\n</ul>\n<p>#AI \n#definition \n#article \n#logic-programming </p>\n"
  },
  {
    "title": "Mean removal",
    "body": "It involves removing the mean from each feature so that it is centered on zero. Mean removal helps in removing any bias from the features.\n\n#ML \n#definition \n#preprocessing\n#data-preprocessing\n#data-processing \n#mean-removal\n#feature-mean-removal\n#supervised-ml ",
    "tags": [
      "ML",
      "definition",
      "preprocessing",
      "data",
      "mean",
      "feature",
      "supervised"
    ],
    "htmlContent": "<p>It involves removing the mean from each feature so that it is centered on zero. Mean removal helps in removing any bias from the features.</p>\n<p>#ML \n#definition \n#preprocessing\n#data-preprocessing\n#data-processing \n#mean-removal\n#feature-mean-removal\n#supervised-ml </p>\n"
  },
  {
    "title": "Multivariable Regressor",
    "body": "Simple linear regression is a function that allows an analyst or statistician to make predictions about one variable based on the information that is known about another variable. Linear regression can only be used when one has two continuous variables—an independent variable and a dependent variable. The independent variable is the parameter that is used to calculate the dependent variable or outcome. A multiple regression model extends to several explanatory variables.\n\nIn _statistics_ - as in mathematics - 'variate' and 'variable' mean the same thing.\n\nMultiple regression is when you have multiple IVs, multivariate regression is when you have multiple DVs.\n\nMore: https://www.theanalysisfactor.com/multiple-regression-model-univariate-or-multivariate-glm/\n\n#ML \n#definition \n#regressor\n#regression \n#multivariable\n#multivariable-regression\n#multivariate-regression",
    "tags": [
      "ML",
      "definition",
      "regressor",
      "regression",
      "multivariable",
      "multivariate"
    ],
    "htmlContent": "<p>Simple linear regression is a function that allows an analyst or statistician to make predictions about one variable based on the information that is known about another variable. Linear regression can only be used when one has two continuous variables—an independent variable and a dependent variable. The independent variable is the parameter that is used to calculate the dependent variable or outcome. A multiple regression model extends to several explanatory variables.</p>\n<p>In <em>statistics</em> - as in mathematics - &#39;variate&#39; and &#39;variable&#39; mean the same thing.</p>\n<p>Multiple regression is when you have multiple IVs, multivariate regression is when you have multiple DVs.</p>\n<p>More: <a href=\"https://www.theanalysisfactor.com/multiple-regression-model-univariate-or-multivariate-glm/\">https://www.theanalysisfactor.com/multiple-regression-model-univariate-or-multivariate-glm/</a></p>\n<p>#ML \n#definition \n#regressor\n#regression \n#multivariable\n#multivariable-regression\n#multivariate-regression</p>\n"
  },
  {
    "title": "Naïve Bayes classifier",
    "body": "\nA family of algorithms based on Bayes’ theorem. Bayes theorem (also known as the Bayes Rule or Bayes Law) is used to determine the conditional probability of event A when event B has already occurred.\n\nP(A|B) = P(B|A)P(A) / P(B)\n\nwhere,\n\n- P(A) and P(B) are the probabilities of events A and B\n- P(A|B) is the probability of event A when event B happens\n- P(B|A) is the probability of event B when A happens\n\nThe “Naive” part of the name indicates the simplifying assumption made by the Naïve Bayes classifier. The classifier assumes that the features used to describe an observation are conditionally independent, given the class label. The “Bayes” part of the name refers to Reverend Thomas Bayes, an 18th-century statistician and theologian who formulated Bayes’ theorem.\n\nMore: https://www.javatpoint.com/machine-learning-naive-bayes-classifier\n\n#ML \n#definition \n#article \n#bayes-theorem\n#naïve-bayes-classifier\n#supervised-ml \n#classifier\n#algorithm",
    "tags": [
      "P(A) and P(B) are the probabilities of events A and B",
      "P(A|B) is the probability of event A when event B happens",
      "P(B|A) is the probability of event B when A happens",
      "ML",
      "definition",
      "article",
      "bayes",
      "na",
      "supervised",
      "classifier",
      "algorithm"
    ],
    "htmlContent": "<p>A family of algorithms based on Bayes’ theorem. Bayes theorem (also known as the Bayes Rule or Bayes Law) is used to determine the conditional probability of event A when event B has already occurred.</p>\n<p>P(A|B) = P(B|A)P(A) / P(B)</p>\n<p>where,</p>\n<ul>\n<li>P(A) and P(B) are the probabilities of events A and B</li>\n<li>P(A|B) is the probability of event A when event B happens</li>\n<li>P(B|A) is the probability of event B when A happens</li>\n</ul>\n<p>The “Naive” part of the name indicates the simplifying assumption made by the Naïve Bayes classifier. The classifier assumes that the features used to describe an observation are conditionally independent, given the class label. The “Bayes” part of the name refers to Reverend Thomas Bayes, an 18th-century statistician and theologian who formulated Bayes’ theorem.</p>\n<p>More: <a href=\"https://www.javatpoint.com/machine-learning-naive-bayes-classifier\">https://www.javatpoint.com/machine-learning-naive-bayes-classifier</a></p>\n<p>#ML \n#definition \n#article \n#bayes-theorem\n#naïve-bayes-classifier\n#supervised-ml \n#classifier\n#algorithm</p>\n"
  },
  {
    "title": "Normalization",
    "body": "Normalization is a specific form of feature scaling that transforms the range of features to a standard scale. Normalization and, for that matter, any data scaling technique is required only when your dataset has features of varying ranges. Normalization encompasses diverse techniques tailored to different data distributions and model requirements.\n\nThe most widely used types of normalization in machine learning are:\n\n- **Min-Max Scaling –** Subtract the minimum value from each column’s highest value and divide by the range. Each new column has a minimum value of 0 and a maximum value of 1.\n\n- **Standardization Scaling –**  The term “standardization” refers to the process of centering a variable at zero and standardizing the variance at one. Subtracting the mean of each observation and then dividing by the standard deviation is the procedure:\n\nThe features will be rescaled so that they have the attributes of a typical normal distribution with standard deviations.\n\n| Normalization                                                                                                                    | Standardization                                                                                                                 |\n| -------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------- |\n| Objective is to bring the values of a feature within a specific range, often between 0 and 1                                     | Objective is to transform the values of a feature to have a mean of 0 and a standard deviation of 1                             |\n| Sensitive to outliers and the range of the data                                                                                  | Less sensitive to outliers due to the use of the mean and standard deviation                                                    |\n| Useful when maintaining the original range is essential                                                                          | Effective when algorithms assume a standard normal distribution                                                                 |\n| No assumption about the distribution of data is made                                                                             | Assumes a normal distribution or close approximation                                                                            |\n| Suitable for algorithms where the absolute values and their relations are important (e.g., k-nearest neighbors, neural networks) | Particularly useful for algorithms that assume normally distributed data, such as linear regression and support vector machines |\n| Maintains the interpretability of the original values within the specified range                                                 | Alters the original values, making interpretation more challenging due to the shift in scale and units                          |\n| Can lead to faster convergence, especially in algorithms that rely on gradient descent                                           | Also contributes to faster convergence, particularly in algorithms sensitive to the scale of input features                     |\n| Use cases: Image processing, neural networks, algorithms sensitive to feature scales                                             | Use cases: Linear regression, support vector machines, algorithms assuming normal distribution                                  |\n\nMore: https://www.datacamp.com/tutorial/normalization-in-machine-learning\n\n#ML \n#article \n#normalization\n#standardization\n#definition \n#supervised-ml ",
    "tags": [
      "**Min",
      "Max Scaling –** Subtract the minimum value from each column’s highest value and divide by the range. Each new column has a minimum value of 0 and a maximum value of 1.",
      "**Standardization Scaling –**  The term “standardization” refers to the process of centering a variable at zero and standardizing the variance at one. Subtracting the mean of each observation and then dividing by the standard deviation is the procedure:",
      "ML",
      "article",
      "normalization",
      "standardization",
      "definition",
      "supervised"
    ],
    "htmlContent": "<p>Normalization is a specific form of feature scaling that transforms the range of features to a standard scale. Normalization and, for that matter, any data scaling technique is required only when your dataset has features of varying ranges. Normalization encompasses diverse techniques tailored to different data distributions and model requirements.</p>\n<p>The most widely used types of normalization in machine learning are:</p>\n<ul>\n<li><p><strong>Min-Max Scaling –</strong> Subtract the minimum value from each column’s highest value and divide by the range. Each new column has a minimum value of 0 and a maximum value of 1.</p>\n</li>\n<li><p><strong>Standardization Scaling –</strong>  The term “standardization” refers to the process of centering a variable at zero and standardizing the variance at one. Subtracting the mean of each observation and then dividing by the standard deviation is the procedure:</p>\n</li>\n</ul>\n<p>The features will be rescaled so that they have the attributes of a typical normal distribution with standard deviations.</p>\n<table>\n<thead>\n<tr>\n<th>Normalization</th>\n<th>Standardization</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Objective is to bring the values of a feature within a specific range, often between 0 and 1</td>\n<td>Objective is to transform the values of a feature to have a mean of 0 and a standard deviation of 1</td>\n</tr>\n<tr>\n<td>Sensitive to outliers and the range of the data</td>\n<td>Less sensitive to outliers due to the use of the mean and standard deviation</td>\n</tr>\n<tr>\n<td>Useful when maintaining the original range is essential</td>\n<td>Effective when algorithms assume a standard normal distribution</td>\n</tr>\n<tr>\n<td>No assumption about the distribution of data is made</td>\n<td>Assumes a normal distribution or close approximation</td>\n</tr>\n<tr>\n<td>Suitable for algorithms where the absolute values and their relations are important (e.g., k-nearest neighbors, neural networks)</td>\n<td>Particularly useful for algorithms that assume normally distributed data, such as linear regression and support vector machines</td>\n</tr>\n<tr>\n<td>Maintains the interpretability of the original values within the specified range</td>\n<td>Alters the original values, making interpretation more challenging due to the shift in scale and units</td>\n</tr>\n<tr>\n<td>Can lead to faster convergence, especially in algorithms that rely on gradient descent</td>\n<td>Also contributes to faster convergence, particularly in algorithms sensitive to the scale of input features</td>\n</tr>\n<tr>\n<td>Use cases: Image processing, neural networks, algorithms sensitive to feature scales</td>\n<td>Use cases: Linear regression, support vector machines, algorithms assuming normal distribution</td>\n</tr>\n</tbody></table>\n<p>More: <a href=\"https://www.datacamp.com/tutorial/normalization-in-machine-learning\">https://www.datacamp.com/tutorial/normalization-in-machine-learning</a></p>\n<p>#ML \n#article \n#normalization\n#standardization\n#definition \n#supervised-ml </p>\n"
  },
  {
    "title": "Number of clusters with Mean Shift algorithm",
    "body": "**Meanshift** is falling under the category of a clustering algorithm in contrast of Unsupervised learning that assigns the data points to the clusters iteratively by shifting points towards the mode (mode is the highest density of data points in the region, in the context of the Meanshift). As such, it is also known as the **Mode-seeking algorithm**. Mean-shift algorithm has applications in the field of image processing and computer vision.\n\n\nMore: \n* https://www.geeksforgeeks.org/ml-mean-shift-clustering/\n* https://datascientest.com/en/meanshift-everything-you-need-to-know-about-the-data-clustering-algorithm\n\n#ML \n#clustering\n#unsupervised-ml \n#definition \n#mean-shift\n#mode-seeking\n#algorithm ",
    "tags": [
      "ML",
      "clustering",
      "unsupervised",
      "definition",
      "mean",
      "mode",
      "algorithm"
    ],
    "htmlContent": "<p><strong>Meanshift</strong> is falling under the category of a clustering algorithm in contrast of Unsupervised learning that assigns the data points to the clusters iteratively by shifting points towards the mode (mode is the highest density of data points in the region, in the context of the Meanshift). As such, it is also known as the <strong>Mode-seeking algorithm</strong>. Mean-shift algorithm has applications in the field of image processing and computer vision.</p>\n<p>More: </p>\n<ul>\n<li><a href=\"https://www.geeksforgeeks.org/ml-mean-shift-clustering/\">https://www.geeksforgeeks.org/ml-mean-shift-clustering/</a></li>\n<li><a href=\"https://datascientest.com/en/meanshift-everything-you-need-to-know-about-the-data-clustering-algorithm\">https://datascientest.com/en/meanshift-everything-you-need-to-know-about-the-data-clustering-algorithm</a></li>\n</ul>\n<p>#ML \n#clustering\n#unsupervised-ml \n#definition \n#mean-shift\n#mode-seeking\n#algorithm </p>\n"
  },
  {
    "title": "Processing Data",
    "body": "![[Pasted image 20240915095220.png]]\nData science professionals design systems in which raw data is the input, and the output is data that can produce actionable insights.\n\nMore: https://lakefs.io/blog/data-preprocessing-in-machine-learning/\n\n#ML\n#definition \n#article \n#data-processing",
    "tags": [
      "ML",
      "definition",
      "article",
      "data"
    ],
    "htmlContent": "<p>![[Pasted image 20240915095220.png]]\nData science professionals design systems in which raw data is the input, and the output is data that can produce actionable insights.</p>\n<p>More: <a href=\"https://lakefs.io/blog/data-preprocessing-in-machine-learning/\">https://lakefs.io/blog/data-preprocessing-in-machine-learning/</a></p>\n<p>#ML\n#definition \n#article \n#data-processing</p>\n"
  },
  {
    "title": "Quality of clustering with silhouette scores",
    "body": "Silhouette refers to a method of interpretation and validation of consistency within clusters of data. The technique provides a succinct graphical representation of how well each object has been classified. It was proposed by Belgian statistician Peter Rousseeuw in 1987. \n\nMore:\n* https://medium.com/@MrBam44/how-to-evaluate-the-performance-of-clustering-algorithms-3ba29cad8c03\n* https://www.linkedin.com/advice/0/how-can-you-calculate-silhouette-score-clustering-algorithm-w9bcc\n\n\n#ML \n#clustering\n#unsupervised-ml \n#definition \n#silhouette\n#algorithm ",
    "tags": [
      "ML",
      "clustering",
      "unsupervised",
      "definition",
      "silhouette",
      "algorithm"
    ],
    "htmlContent": "<p>Silhouette refers to a method of interpretation and validation of consistency within clusters of data. The technique provides a succinct graphical representation of how well each object has been classified. It was proposed by Belgian statistician Peter Rousseeuw in 1987. </p>\n<p>More:</p>\n<ul>\n<li><a href=\"https://medium.com/@MrBam44/how-to-evaluate-the-performance-of-clustering-algorithms-3ba29cad8c03\">https://medium.com/@MrBam44/how-to-evaluate-the-performance-of-clustering-algorithms-3ba29cad8c03</a></li>\n<li><a href=\"https://www.linkedin.com/advice/0/how-can-you-calculate-silhouette-score-clustering-algorithm-w9bcc\">https://www.linkedin.com/advice/0/how-can-you-calculate-silhouette-score-clustering-algorithm-w9bcc</a></li>\n</ul>\n<p>#ML \n#clustering\n#unsupervised-ml \n#definition \n#silhouette\n#algorithm </p>\n"
  },
  {
    "title": "Random Forests",
    "body": "Random forest is a commonly-used machine learning algorithm, trademarked by Leo Breiman and Adele Cutler, that combines the output of multiple decision trees to reach a single result. Its ease of use and flexibility have fuelled its adoption, as it handles both classification and regression problems.\n\nThe random forest algorithm is an extension of the bagging method as it utilizes both bagging and feature randomness to create an uncorrelated forest of decision trees.\n\nMore: \n* https://www.ibm.com/topics/random-forest\n* https://developers.google.com/machine-learning/decision-forests/random-forests\n\n#ML \n#definition \n#decision-tree \n#bagging",
    "tags": [
      "ML",
      "definition",
      "decision",
      "bagging"
    ],
    "htmlContent": "<p>Random forest is a commonly-used machine learning algorithm, trademarked by Leo Breiman and Adele Cutler, that combines the output of multiple decision trees to reach a single result. Its ease of use and flexibility have fuelled its adoption, as it handles both classification and regression problems.</p>\n<p>The random forest algorithm is an extension of the bagging method as it utilizes both bagging and feature randomness to create an uncorrelated forest of decision trees.</p>\n<p>More: </p>\n<ul>\n<li><a href=\"https://www.ibm.com/topics/random-forest\">https://www.ibm.com/topics/random-forest</a></li>\n<li><a href=\"https://developers.google.com/machine-learning/decision-forests/random-forests\">https://developers.google.com/machine-learning/decision-forests/random-forests</a></li>\n</ul>\n<p>#ML \n#definition \n#decision-tree \n#bagging</p>\n"
  },
  {
    "title": "Rational Agent",
    "body": "A rational agent in AI is an agent that performs actions to achieve the best possible outcome based on its perceptions and knowledge. It operates under the premise of rationality, where it consistently makes decisions that maximize its expected utility or performance measure. Rational agents can be found in various AI applications, including robotics, automated trading systems, and decision support systems.\n\n## Components of a Rational Agent\n\nA rational agent comprises several key components:\n\n1. ****Perception****: The ability to perceive the environment through sensors.\n2. ****Knowledge Base****: Information the agent has about the environment and itself.\n3. ****Decision-Making Process****: Algorithms and rules that guide the agent’s actions.\n4. ****Action****: The ability to perform actions that affect the environment through actuators.\n\n### Types of Rational Agents\n\n1. ****Simple Reflex Agents****: These agents select actions based on the current perception, ignoring the rest of the percept history. They follow condition-action rules but can be limited in complex environments.\n2. ****Model-Based Reflex Agents****: These agents maintain an internal model of the world, allowing them to handle partially observable environments. They use the model to keep track of the unobserved aspects of the environment.\n3. ****Goal-Based Agents****: These agents take actions to achieve specific goals. They use planning and search algorithms to find sequences of actions that lead to the desired outcomes.\n4. ****Utility-Based Agents****: These agents aim to maximize a utility function that represents the agent’s preferences. They are designed to handle trade-offs and uncertainties by selecting actions that maximize expected utility.\n5. ****Learning Agents****:  These agents improve their performance over time by learning from their experiences. They adapt their behavior based on feedback from the environment.\n\n### **Different Types of Agents in AI**\n\n### **1. Software Agents:**\n\n- **Search Agents:** Search engines like Google use software agents to retrieve and rank web pages based on user queries.\n- **Recommender Systems:** Recommendation algorithms in e-commerce websites and streaming platforms use software agents to suggest products or content based on user preferences.\n- **Chatbots:** Chatbots and virtual assistants like Siri or Alexa are software agents designed to understand and respond to natural language input.\n\n### **2. Robotic Agents:**\n\n- **Autonomous Robots:** Autonomous drones and self-driving cars are examples of robotic agents that use sensors, actuators, and AI to navigate and interact with their physical environments.\n- **Industrial Robots:** In manufacturing, industrial robots are used as agents to perform tasks like welding, assembling, and packaging.\n\n### **3. Intelligent Virtual Agents:**\n\n- **Virtual Avatars:** In video games, intelligent virtual agents, such as non-player characters (NPCs), interact with players and respond to game events.\n- **Virtual Assistants:** Intelligent virtual agents like Apple's Siri, Amazon's Alexa, and Microsoft's Cortana provide voice-activated assistance and perform tasks such as setting reminders, answering questions, and controlling smart devices.\n\nThese examples showcase the diversity of agent types in AI, with each designed to address specific tasks or applications using various combinations of sensors, actuators, and internal functions. Whether in software, physical robotics, or virtual environments, agents play a crucial role in AI to automate, assist, and optimize a wide range of functions and activities.\n\nMore: \n* https://www.almabetter.com/bytes/tutorials/artificial-intelligence/agents-in-ai\n* https://aitech.studio/aie/components-of-ai-agents/\n\n#AI\n#definition\n#article\n#rational-agent\n#software-agent\n#robotic-agent\n#virtual-agent\n\n",
    "tags": [
      "**Search Agents:** Search engines like Google use software agents to retrieve and rank web pages based on user queries.",
      "**Recommender Systems:** Recommendation algorithms in e",
      "commerce websites and streaming platforms use software agents to suggest products or content based on user preferences.",
      "**Chatbots:** Chatbots and virtual assistants like Siri or Alexa are software agents designed to understand and respond to natural language input.",
      "**Autonomous Robots:** Autonomous drones and self",
      "driving cars are examples of robotic agents that use sensors, actuators, and AI to navigate and interact with their physical environments.",
      "**Industrial Robots:** In manufacturing, industrial robots are used as agents to perform tasks like welding, assembling, and packaging.",
      "**Virtual Avatars:** In video games, intelligent virtual agents, such as non",
      "player characters (NPCs), interact with players and respond to game events.",
      "**Virtual Assistants:** Intelligent virtual agents like Apple's Siri, Amazon's Alexa, and Microsoft's Cortana provide voice",
      "activated assistance and perform tasks such as setting reminders, answering questions, and controlling smart devices.",
      "AI",
      "definition",
      "article",
      "rational",
      "software",
      "robotic",
      "virtual"
    ],
    "htmlContent": "<p>A rational agent in AI is an agent that performs actions to achieve the best possible outcome based on its perceptions and knowledge. It operates under the premise of rationality, where it consistently makes decisions that maximize its expected utility or performance measure. Rational agents can be found in various AI applications, including robotics, automated trading systems, and decision support systems.</p>\n<h2>Components of a Rational Agent</h2>\n<p>A rational agent comprises several key components:</p>\n<ol>\n<li><strong><strong>Perception</strong></strong>: The ability to perceive the environment through sensors.</li>\n<li><strong><strong>Knowledge Base</strong></strong>: Information the agent has about the environment and itself.</li>\n<li><strong><strong>Decision-Making Process</strong></strong>: Algorithms and rules that guide the agent’s actions.</li>\n<li><strong><strong>Action</strong></strong>: The ability to perform actions that affect the environment through actuators.</li>\n</ol>\n<h3>Types of Rational Agents</h3>\n<ol>\n<li><strong><strong>Simple Reflex Agents</strong></strong>: These agents select actions based on the current perception, ignoring the rest of the percept history. They follow condition-action rules but can be limited in complex environments.</li>\n<li><strong><strong>Model-Based Reflex Agents</strong></strong>: These agents maintain an internal model of the world, allowing them to handle partially observable environments. They use the model to keep track of the unobserved aspects of the environment.</li>\n<li><strong><strong>Goal-Based Agents</strong></strong>: These agents take actions to achieve specific goals. They use planning and search algorithms to find sequences of actions that lead to the desired outcomes.</li>\n<li><strong><strong>Utility-Based Agents</strong></strong>: These agents aim to maximize a utility function that represents the agent’s preferences. They are designed to handle trade-offs and uncertainties by selecting actions that maximize expected utility.</li>\n<li><strong><strong>Learning Agents</strong></strong>:  These agents improve their performance over time by learning from their experiences. They adapt their behavior based on feedback from the environment.</li>\n</ol>\n<h3><strong>Different Types of Agents in AI</strong></h3>\n<h3><strong>1. Software Agents:</strong></h3>\n<ul>\n<li><strong>Search Agents:</strong> Search engines like Google use software agents to retrieve and rank web pages based on user queries.</li>\n<li><strong>Recommender Systems:</strong> Recommendation algorithms in e-commerce websites and streaming platforms use software agents to suggest products or content based on user preferences.</li>\n<li><strong>Chatbots:</strong> Chatbots and virtual assistants like Siri or Alexa are software agents designed to understand and respond to natural language input.</li>\n</ul>\n<h3><strong>2. Robotic Agents:</strong></h3>\n<ul>\n<li><strong>Autonomous Robots:</strong> Autonomous drones and self-driving cars are examples of robotic agents that use sensors, actuators, and AI to navigate and interact with their physical environments.</li>\n<li><strong>Industrial Robots:</strong> In manufacturing, industrial robots are used as agents to perform tasks like welding, assembling, and packaging.</li>\n</ul>\n<h3><strong>3. Intelligent Virtual Agents:</strong></h3>\n<ul>\n<li><strong>Virtual Avatars:</strong> In video games, intelligent virtual agents, such as non-player characters (NPCs), interact with players and respond to game events.</li>\n<li><strong>Virtual Assistants:</strong> Intelligent virtual agents like Apple&#39;s Siri, Amazon&#39;s Alexa, and Microsoft&#39;s Cortana provide voice-activated assistance and perform tasks such as setting reminders, answering questions, and controlling smart devices.</li>\n</ul>\n<p>These examples showcase the diversity of agent types in AI, with each designed to address specific tasks or applications using various combinations of sensors, actuators, and internal functions. Whether in software, physical robotics, or virtual environments, agents play a crucial role in AI to automate, assist, and optimize a wide range of functions and activities.</p>\n<p>More: </p>\n<ul>\n<li><a href=\"https://www.almabetter.com/bytes/tutorials/artificial-intelligence/agents-in-ai\">https://www.almabetter.com/bytes/tutorials/artificial-intelligence/agents-in-ai</a></li>\n<li><a href=\"https://aitech.studio/aie/components-of-ai-agents/\">https://aitech.studio/aie/components-of-ai-agents/</a></li>\n</ul>\n<p>#AI\n#definition\n#article\n#rational-agent\n#software-agent\n#robotic-agent\n#virtual-agent</p>\n"
  },
  {
    "title": "Real world examples of reinforcement learning",
    "body": "Certainly! Here’s a table summarizing real-world examples of reinforcement learning (RL) and their applications:\n\n| **Application**             | **Description**                                                                                                  | **Real-World Examples**                               |\n|-----------------------------|------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------|\n| **Game Playing**            | RL algorithms learn to play and master games by interacting with the environment and receiving feedback.         | AlphaGo, AlphaZero (DeepMind)                         |\n| **Robotics**                | RL is used to train robots for tasks such as manipulation, locomotion, and interaction with their environment.    | Warehouse robots (Amazon), robotic arms (Boston Dynamics) |\n| **Autonomous Vehicles**     | Self-driving cars use RL to navigate, make decisions, and adapt to dynamic road conditions and traffic scenarios. | Waymo, Tesla Autopilot                                |\n| **Finance**                 | RL optimizes trading strategies, portfolio management, and risk assessment by learning from market data.         | Algorithmic trading systems (various financial institutions) |\n| **Healthcare**              | RL personalizes treatment plans, manages chronic conditions, and optimizes drug dosages based on patient data.    | Personalized medicine (e.g., insulin dosing)         |\n| **Energy Management**       | RL optimizes energy distribution, consumption, and grid management in smart grids and buildings.                  | Smart grids, energy-efficient buildings               |\n| **Manufacturing**           | RL improves production processes, machine settings, and supply chain management for increased efficiency.         | Automated factories (e.g., Tesla Gigafactory)        |\n| **Advertising**             | RL optimizes ad placement, bidding strategies, and content recommendations based on user interactions.           | Google Ads, Facebook Ads                              |\n| **Recommendation Systems**  | RL personalizes content recommendations by learning from user interactions and preferences.                     | Netflix, YouTube                                     |\n| **Customer Service**        | RL enhances the performance of chatbots and virtual assistants by learning to respond more accurately to user needs. | Virtual assistants (e.g., Siri, Alexa)               |\n\n### Additional Details\n\n- **AlphaGo and AlphaZero**: These systems use RL to master board games like Go and Chess, achieving superhuman performance through self-play and strategic learning.\n- **Warehouse Robots**: Amazon's robots use RL to efficiently navigate and manage inventory in warehouses, optimizing picking and packing processes.\n- **Waymo and Tesla Autopilot**: These self-driving technologies use RL to improve navigation, decision-making, and safety features in autonomous vehicles.\n- **Algorithmic Trading**: RL algorithms adjust trading strategies in real-time to maximize returns and manage risks based on market conditions.\n- **Personalized Medicine**: RL helps in customizing treatment regimens for individual patients, such as adjusting insulin levels for diabetics.\n- **Smart Grids**: RL manages energy distribution and consumption, balancing supply and demand in real-time to optimize grid performance.\n- **Automated Factories**: RL is used to fine-tune manufacturing processes and manage supply chains for improved efficiency and reduced downtime.\n- **Google Ads and Facebook Ads**: RL optimizes ad placements and bidding strategies, enhancing targeting and ad revenue.\n- **Netflix and YouTube**: RL personalizes content recommendations by learning user preferences and viewing habits.\n- **Virtual Assistants**: RL improves the accuracy and relevance of responses from AI-driven assistants by learning from user interactions.\n\n#AI \n#reinforcement-learning \n#definition \n#article ",
    "tags": [
      "**AlphaGo and AlphaZero**: These systems use RL to master board games like Go and Chess, achieving superhuman performance through self",
      "play and strategic learning.",
      "**Warehouse Robots**: Amazon's robots use RL to efficiently navigate and manage inventory in warehouses, optimizing picking and packing processes.",
      "**Waymo and Tesla Autopilot**: These self",
      "driving technologies use RL to improve navigation, decision",
      "making, and safety features in autonomous vehicles.",
      "**Algorithmic Trading**: RL algorithms adjust trading strategies in real",
      "time to maximize returns and manage risks based on market conditions.",
      "**Personalized Medicine**: RL helps in customizing treatment regimens for individual patients, such as adjusting insulin levels for diabetics.",
      "**Smart Grids**: RL manages energy distribution and consumption, balancing supply and demand in real",
      "time to optimize grid performance.",
      "**Automated Factories**: RL is used to fine",
      "tune manufacturing processes and manage supply chains for improved efficiency and reduced downtime.",
      "**Google Ads and Facebook Ads**: RL optimizes ad placements and bidding strategies, enhancing targeting and ad revenue.",
      "**Netflix and YouTube**: RL personalizes content recommendations by learning user preferences and viewing habits.",
      "**Virtual Assistants**: RL improves the accuracy and relevance of responses from AI",
      "driven assistants by learning from user interactions.",
      "AI",
      "reinforcement",
      "definition",
      "article"
    ],
    "htmlContent": "<p>Certainly! Here’s a table summarizing real-world examples of reinforcement learning (RL) and their applications:</p>\n<table>\n<thead>\n<tr>\n<th><strong>Application</strong></th>\n<th><strong>Description</strong></th>\n<th><strong>Real-World Examples</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Game Playing</strong></td>\n<td>RL algorithms learn to play and master games by interacting with the environment and receiving feedback.</td>\n<td>AlphaGo, AlphaZero (DeepMind)</td>\n</tr>\n<tr>\n<td><strong>Robotics</strong></td>\n<td>RL is used to train robots for tasks such as manipulation, locomotion, and interaction with their environment.</td>\n<td>Warehouse robots (Amazon), robotic arms (Boston Dynamics)</td>\n</tr>\n<tr>\n<td><strong>Autonomous Vehicles</strong></td>\n<td>Self-driving cars use RL to navigate, make decisions, and adapt to dynamic road conditions and traffic scenarios.</td>\n<td>Waymo, Tesla Autopilot</td>\n</tr>\n<tr>\n<td><strong>Finance</strong></td>\n<td>RL optimizes trading strategies, portfolio management, and risk assessment by learning from market data.</td>\n<td>Algorithmic trading systems (various financial institutions)</td>\n</tr>\n<tr>\n<td><strong>Healthcare</strong></td>\n<td>RL personalizes treatment plans, manages chronic conditions, and optimizes drug dosages based on patient data.</td>\n<td>Personalized medicine (e.g., insulin dosing)</td>\n</tr>\n<tr>\n<td><strong>Energy Management</strong></td>\n<td>RL optimizes energy distribution, consumption, and grid management in smart grids and buildings.</td>\n<td>Smart grids, energy-efficient buildings</td>\n</tr>\n<tr>\n<td><strong>Manufacturing</strong></td>\n<td>RL improves production processes, machine settings, and supply chain management for increased efficiency.</td>\n<td>Automated factories (e.g., Tesla Gigafactory)</td>\n</tr>\n<tr>\n<td><strong>Advertising</strong></td>\n<td>RL optimizes ad placement, bidding strategies, and content recommendations based on user interactions.</td>\n<td>Google Ads, Facebook Ads</td>\n</tr>\n<tr>\n<td><strong>Recommendation Systems</strong></td>\n<td>RL personalizes content recommendations by learning from user interactions and preferences.</td>\n<td>Netflix, YouTube</td>\n</tr>\n<tr>\n<td><strong>Customer Service</strong></td>\n<td>RL enhances the performance of chatbots and virtual assistants by learning to respond more accurately to user needs.</td>\n<td>Virtual assistants (e.g., Siri, Alexa)</td>\n</tr>\n</tbody></table>\n<h3>Additional Details</h3>\n<ul>\n<li><strong>AlphaGo and AlphaZero</strong>: These systems use RL to master board games like Go and Chess, achieving superhuman performance through self-play and strategic learning.</li>\n<li><strong>Warehouse Robots</strong>: Amazon&#39;s robots use RL to efficiently navigate and manage inventory in warehouses, optimizing picking and packing processes.</li>\n<li><strong>Waymo and Tesla Autopilot</strong>: These self-driving technologies use RL to improve navigation, decision-making, and safety features in autonomous vehicles.</li>\n<li><strong>Algorithmic Trading</strong>: RL algorithms adjust trading strategies in real-time to maximize returns and manage risks based on market conditions.</li>\n<li><strong>Personalized Medicine</strong>: RL helps in customizing treatment regimens for individual patients, such as adjusting insulin levels for diabetics.</li>\n<li><strong>Smart Grids</strong>: RL manages energy distribution and consumption, balancing supply and demand in real-time to optimize grid performance.</li>\n<li><strong>Automated Factories</strong>: RL is used to fine-tune manufacturing processes and manage supply chains for improved efficiency and reduced downtime.</li>\n<li><strong>Google Ads and Facebook Ads</strong>: RL optimizes ad placements and bidding strategies, enhancing targeting and ad revenue.</li>\n<li><strong>Netflix and YouTube</strong>: RL personalizes content recommendations by learning user preferences and viewing habits.</li>\n<li><strong>Virtual Assistants</strong>: RL improves the accuracy and relevance of responses from AI-driven assistants by learning from user interactions.</li>\n</ul>\n<p>#AI \n#reinforcement-learning \n#definition \n#article </p>\n"
  },
  {
    "title": "Regression",
    "body": "Regression, a statistical approach, dissects the relationship between dependent and independent variables, enabling predictions through various regression models.\n\nIt is a supervised machine learning technique, used to predict the value of the dependent variable for new, unseen data. It models the relationship between the input features and the target variable, allowing for the estimation or prediction of numerical values.\n\n**Regression Types**\n\nThere are such main types of regression:\n\n- Simple Regression\n    - Used to predict a continuous dependent variable based on a single independent variable.\n    - Simple linear regression should be used when there is only a single independent variable.\n- Multiple Regression\n    - Used to predict a continuous dependent variable based on multiple independent variables.\n    - Multiple linear regression should be used when there are multiple independent variables.\n- NonLinear Regression\n    - Relationship between the dependent variable and independent variable(s) follows a nonlinear pattern.\n    - Provides flexibility in modeling a wide range of functional forms.\n\nMore: https://www.geeksforgeeks.org/regression-in-machine-learning/\n\n#ML \n#definition \n#supervised-ml \n#regression\n#prediction\n#ml-model ",
    "tags": [
      "Simple Regression",
      "Multiple Regression",
      "NonLinear Regression",
      "ML",
      "definition",
      "supervised",
      "regression",
      "prediction",
      "ml"
    ],
    "htmlContent": "<p>Regression, a statistical approach, dissects the relationship between dependent and independent variables, enabling predictions through various regression models.</p>\n<p>It is a supervised machine learning technique, used to predict the value of the dependent variable for new, unseen data. It models the relationship between the input features and the target variable, allowing for the estimation or prediction of numerical values.</p>\n<p><strong>Regression Types</strong></p>\n<p>There are such main types of regression:</p>\n<ul>\n<li>Simple Regression<ul>\n<li>Used to predict a continuous dependent variable based on a single independent variable.</li>\n<li>Simple linear regression should be used when there is only a single independent variable.</li>\n</ul>\n</li>\n<li>Multiple Regression<ul>\n<li>Used to predict a continuous dependent variable based on multiple independent variables.</li>\n<li>Multiple linear regression should be used when there are multiple independent variables.</li>\n</ul>\n</li>\n<li>NonLinear Regression<ul>\n<li>Relationship between the dependent variable and independent variable(s) follows a nonlinear pattern.</li>\n<li>Provides flexibility in modeling a wide range of functional forms.</li>\n</ul>\n</li>\n</ul>\n<p>More: <a href=\"https://www.geeksforgeeks.org/regression-in-machine-learning/\">https://www.geeksforgeeks.org/regression-in-machine-learning/</a></p>\n<p>#ML \n#definition \n#supervised-ml \n#regression\n#prediction\n#ml-model </p>\n"
  },
  {
    "title": "Reinforcement learning vs supervised learning",
    "body": "Supervised Learning: A Predictive Approach\n\nReinforcement Learning: Learning through Trial and Error\n\n| Aspect                   | Supervised Learning                               | Reinforcement Learning                              |\n|--------------------------|---------------------------------------------------|-----------------------------------------------------|\n| **Definition**           | A type of machine learning where the model is trained on labeled data, with the goal of predicting the correct label for new, unseen data. | A type of machine learning where the model learns to make decisions by receiving rewards or penalties for actions taken in an environment. |\n| **Data**                 | Requires a dataset with input-output pairs (labeled data). | Operates in an environment where the agent interacts and learns from its actions (feedback in the form of rewards). |\n| **Objective**            | Minimize prediction error on the labeled dataset. | Maximize cumulative reward over time. |\n| **Training Feedback**    | Supervised learning uses explicit feedback in the form of labels for training data. | Reinforcement learning uses feedback in the form of rewards or penalties, which is often sparse and delayed. |\n| **Model Output**         | The model produces a prediction or classification for given inputs. | The model produces a policy or sequence of actions to maximize rewards. |\n| **Learning Process**     | Learning is guided by the error between the predicted output and the actual output (ground truth). | Learning is guided by the reward signal received after performing actions in an environment. |\n| **Example Algorithms**   | Linear Regression, Logistic Regression, Decision Trees, Support Vector Machines, Neural Networks. | Q-Learning, Deep Q-Networks (DQN), Policy Gradients, Actor-Critic Methods. |\n| **Training Data**        | Static and fixed dataset used for training and testing. | Dynamic environment with potentially continuous interaction and exploration. |\n| **Evaluation**           | Evaluated using metrics such as accuracy, precision, recall, F1-score, etc., on a validation set. | Evaluated based on the total accumulated reward or performance metrics over time in the environment. |\n| **Applications**         | Image classification, spam detection, sentiment analysis, medical diagnosis. | Game playing (e.g., AlphaGo), robotics, autonomous vehicles, financial trading. |\n| **Exploration vs. Exploitation** | Not directly applicable; focuses on fitting a model to known data. | Critical concept; balance between exploring new actions and exploiting known rewarding actions. |\n| **Scalability**          | Generally scales well with large datasets, provided enough labeled data is available. | Scalability can be challenging due to the complexity of environments and the need for exploration. |\n| **Complexity**           | Typically less complex as it deals with a static dataset and explicit labels. | Can be more complex due to the need to learn from interaction with a dynamic environment and handle delayed rewards. |\n\nThis table provides a high-level comparison between Supervised Learning and Reinforcement Learning, highlighting their key differences and characteristics.\n\n#AI \n#ML \n#supervised-ml \n#reinforcement-learning \n#definition \n#article ",
    "tags": [
      "AI",
      "ML",
      "supervised",
      "reinforcement",
      "definition",
      "article"
    ],
    "htmlContent": "<p>Supervised Learning: A Predictive Approach</p>\n<p>Reinforcement Learning: Learning through Trial and Error</p>\n<table>\n<thead>\n<tr>\n<th>Aspect</th>\n<th>Supervised Learning</th>\n<th>Reinforcement Learning</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Definition</strong></td>\n<td>A type of machine learning where the model is trained on labeled data, with the goal of predicting the correct label for new, unseen data.</td>\n<td>A type of machine learning where the model learns to make decisions by receiving rewards or penalties for actions taken in an environment.</td>\n</tr>\n<tr>\n<td><strong>Data</strong></td>\n<td>Requires a dataset with input-output pairs (labeled data).</td>\n<td>Operates in an environment where the agent interacts and learns from its actions (feedback in the form of rewards).</td>\n</tr>\n<tr>\n<td><strong>Objective</strong></td>\n<td>Minimize prediction error on the labeled dataset.</td>\n<td>Maximize cumulative reward over time.</td>\n</tr>\n<tr>\n<td><strong>Training Feedback</strong></td>\n<td>Supervised learning uses explicit feedback in the form of labels for training data.</td>\n<td>Reinforcement learning uses feedback in the form of rewards or penalties, which is often sparse and delayed.</td>\n</tr>\n<tr>\n<td><strong>Model Output</strong></td>\n<td>The model produces a prediction or classification for given inputs.</td>\n<td>The model produces a policy or sequence of actions to maximize rewards.</td>\n</tr>\n<tr>\n<td><strong>Learning Process</strong></td>\n<td>Learning is guided by the error between the predicted output and the actual output (ground truth).</td>\n<td>Learning is guided by the reward signal received after performing actions in an environment.</td>\n</tr>\n<tr>\n<td><strong>Example Algorithms</strong></td>\n<td>Linear Regression, Logistic Regression, Decision Trees, Support Vector Machines, Neural Networks.</td>\n<td>Q-Learning, Deep Q-Networks (DQN), Policy Gradients, Actor-Critic Methods.</td>\n</tr>\n<tr>\n<td><strong>Training Data</strong></td>\n<td>Static and fixed dataset used for training and testing.</td>\n<td>Dynamic environment with potentially continuous interaction and exploration.</td>\n</tr>\n<tr>\n<td><strong>Evaluation</strong></td>\n<td>Evaluated using metrics such as accuracy, precision, recall, F1-score, etc., on a validation set.</td>\n<td>Evaluated based on the total accumulated reward or performance metrics over time in the environment.</td>\n</tr>\n<tr>\n<td><strong>Applications</strong></td>\n<td>Image classification, spam detection, sentiment analysis, medical diagnosis.</td>\n<td>Game playing (e.g., AlphaGo), robotics, autonomous vehicles, financial trading.</td>\n</tr>\n<tr>\n<td><strong>Exploration vs. Exploitation</strong></td>\n<td>Not directly applicable; focuses on fitting a model to known data.</td>\n<td>Critical concept; balance between exploring new actions and exploiting known rewarding actions.</td>\n</tr>\n<tr>\n<td><strong>Scalability</strong></td>\n<td>Generally scales well with large datasets, provided enough labeled data is available.</td>\n<td>Scalability can be challenging due to the complexity of environments and the need for exploration.</td>\n</tr>\n<tr>\n<td><strong>Complexity</strong></td>\n<td>Typically less complex as it deals with a static dataset and explicit labels.</td>\n<td>Can be more complex due to the need to learn from interaction with a dynamic environment and handle delayed rewards.</td>\n</tr>\n</tbody></table>\n<p>This table provides a high-level comparison between Supervised Learning and Reinforcement Learning, highlighting their key differences and characteristics.</p>\n<p>#AI \n#ML \n#supervised-ml \n#reinforcement-learning \n#definition \n#article </p>\n"
  },
  {
    "title": "Relative Feature Importance",
    "body": "The feature importance (variable importance) describes which features are relevant.\n\nWhen we fit a supervised machine learning (ML) model, we often want to understand which features are most associated with our outcome of interest. Features that are highly associated with the outcome are considered more “important.”\n\nFeature Importance is good to understand the relationships between the features, it may help to improve the model, and, finally, it facilitates model interpretability.\n\nMore: \n* https://www.codecademy.com/article/fe-feature-importance-final\n* https://mljar.com/blog/feature-importance-in-random-forest/\n\n#ML\n#definition \n#feature-importance",
    "tags": [
      "ML",
      "definition",
      "feature"
    ],
    "htmlContent": "<p>The feature importance (variable importance) describes which features are relevant.</p>\n<p>When we fit a supervised machine learning (ML) model, we often want to understand which features are most associated with our outcome of interest. Features that are highly associated with the outcome are considered more “important.”</p>\n<p>Feature Importance is good to understand the relationships between the features, it may help to improve the model, and, finally, it facilitates model interpretability.</p>\n<p>More: </p>\n<ul>\n<li><a href=\"https://www.codecademy.com/article/fe-feature-importance-final\">https://www.codecademy.com/article/fe-feature-importance-final</a></li>\n<li><a href=\"https://mljar.com/blog/feature-importance-in-random-forest/\">https://mljar.com/blog/feature-importance-in-random-forest/</a></li>\n</ul>\n<p>#ML\n#definition \n#feature-importance</p>\n"
  },
  {
    "title": "Scaling",
    "body": "Feature Scaling is a technique to standardize the independent features present in the data in a fixed range. It is performed during the data pre-processing to handle highly varying magnitudes or values or units. If feature scaling is not done, then a ML algorithm tends to weigh greater values, higher and consider smaller values as the lower values, regardless of the unit of the values.\n\nFeature scaling can significantly enhance the performance of machine learning models. Scaling the features makes it easier for algorithms to find the optimal solution, as the different scales of the features do not influence them.\n\nIt can lead to faster convergence and more accurate predictions, especially when using algorithms like k-nearest neighbors, support vector machines, and neural networks.\n\nMore: \n* https://www.geeksforgeeks.org/ml-feature-scaling-part-2/\n* https://medium.com/@shivanipickl/what-is-feature-scaling-and-why-does-machine-learning-need-it-104eedebb1c9\n\n#ML \n#article \n#feature-scaling\n#definition \n#supervised-ml ",
    "tags": [
      "ML",
      "article",
      "feature",
      "definition",
      "supervised"
    ],
    "htmlContent": "<p>Feature Scaling is a technique to standardize the independent features present in the data in a fixed range. It is performed during the data pre-processing to handle highly varying magnitudes or values or units. If feature scaling is not done, then a ML algorithm tends to weigh greater values, higher and consider smaller values as the lower values, regardless of the unit of the values.</p>\n<p>Feature scaling can significantly enhance the performance of machine learning models. Scaling the features makes it easier for algorithms to find the optimal solution, as the different scales of the features do not influence them.</p>\n<p>It can lead to faster convergence and more accurate predictions, especially when using algorithms like k-nearest neighbors, support vector machines, and neural networks.</p>\n<p>More: </p>\n<ul>\n<li><a href=\"https://www.geeksforgeeks.org/ml-feature-scaling-part-2/\">https://www.geeksforgeeks.org/ml-feature-scaling-part-2/</a></li>\n<li><a href=\"https://medium.com/@shivanipickl/what-is-feature-scaling-and-why-does-machine-learning-need-it-104eedebb1c9\">https://medium.com/@shivanipickl/what-is-feature-scaling-and-why-does-machine-learning-need-it-104eedebb1c9</a></li>\n</ul>\n<p>#ML \n#article \n#feature-scaling\n#definition \n#supervised-ml </p>\n"
  },
  {
    "title": "Sequential data",
    "body": "Sequential data refers to data where the ordering is important.\n\nWhenever the points in the dataset are dependent on the other points in the dataset the data is said to be Sequential data. A common example of this is a Timeseries such as a stock price or a sensor data where each point represents an observation at a certain point in time.  There are other examples of sequential data like sequences, gene sequences, and weather data.\n\nMore:\n* https://medium.com/analytics-vidhya/sequential-data-and-the-neural-network-conundrum-b2c005f8f865\n* https://aiml.com/what-does-sequential-data-mean-which-models-are-best-suited-for-handling-sequential-data/\n* https://analyticsindiamag.com/ai-mysteries/a-tutorial-on-sequential-machine-learning/\n\n#AI \n#RNN\n#definition \n#article \n#sequential-data\n#deep-learning\n#autoencoder",
    "tags": [
      "AI",
      "RNN",
      "definition",
      "article",
      "sequential",
      "deep",
      "autoencoder"
    ],
    "htmlContent": "<p>Sequential data refers to data where the ordering is important.</p>\n<p>Whenever the points in the dataset are dependent on the other points in the dataset the data is said to be Sequential data. A common example of this is a Timeseries such as a stock price or a sensor data where each point represents an observation at a certain point in time.  There are other examples of sequential data like sequences, gene sequences, and weather data.</p>\n<p>More:</p>\n<ul>\n<li><a href=\"https://medium.com/analytics-vidhya/sequential-data-and-the-neural-network-conundrum-b2c005f8f865\">https://medium.com/analytics-vidhya/sequential-data-and-the-neural-network-conundrum-b2c005f8f865</a></li>\n<li><a href=\"https://aiml.com/what-does-sequential-data-mean-which-models-are-best-suited-for-handling-sequential-data/\">https://aiml.com/what-does-sequential-data-mean-which-models-are-best-suited-for-handling-sequential-data/</a></li>\n<li><a href=\"https://analyticsindiamag.com/ai-mysteries/a-tutorial-on-sequential-machine-learning/\">https://analyticsindiamag.com/ai-mysteries/a-tutorial-on-sequential-machine-learning/</a></li>\n</ul>\n<p>#AI \n#RNN\n#definition \n#article \n#sequential-data\n#deep-learning\n#autoencoder</p>\n"
  },
  {
    "title": "Simulated Annealing",
    "body": "Simulated Annealing (SA) is one of the simplest and best-known metaheuristic method for addressing the difficult - unconstrained and bound-constrained - black box global optimization problems (those whose objective function is not explicitly given and can only be evaluated via some costly computer simulation). It is massively used on real-life applications. The main ad- vantage of SA is its simplicity.\n\nThe simulated annealing process starts with an initial solution and then iteratively improves the current solution by randomly perturbing it and accepting the perturbation with a certain probability. The probability of accepting a worse solution is initially high and gradually decreases as the number of iterations increases.\n\nMore:\n* https://www.baeldung.com/cs/simulated-annealing\n\n#AI \n#optimization \n#algorithm \n#definition \n#article \n#simulated-annealing",
    "tags": [
      "AI",
      "optimization",
      "algorithm",
      "definition",
      "article",
      "simulated"
    ],
    "htmlContent": "<p>Simulated Annealing (SA) is one of the simplest and best-known metaheuristic method for addressing the difficult - unconstrained and bound-constrained - black box global optimization problems (those whose objective function is not explicitly given and can only be evaluated via some costly computer simulation). It is massively used on real-life applications. The main ad- vantage of SA is its simplicity.</p>\n<p>The simulated annealing process starts with an initial solution and then iteratively improves the current solution by randomly perturbing it and accepting the perturbation with a certain probability. The probability of accepting a worse solution is initially high and gradually decreases as the number of iterations increases.</p>\n<p>More:</p>\n<ul>\n<li><a href=\"https://www.baeldung.com/cs/simulated-annealing\">https://www.baeldung.com/cs/simulated-annealing</a></li>\n</ul>\n<p>#AI \n#optimization \n#algorithm \n#definition \n#article \n#simulated-annealing</p>\n"
  },
  {
    "title": "Single Variable Regressor",
    "body": "Regressor - this is an independent variable, predictor. \nRegressand - dependant variable, measured variable, output variable.\n\nSingle Variable Regressor assumes or expects that the predictors are independent of each other (i.e. weakly dependent) and are not multi-collinear.\n\nMore: https://medium.com/@ranaprathap/learning-ml-with-andrew-part-1-linear-regression-with-a-single-variable-615f2d163b88\n\n#ML \n#definition \n#regressor\n#regressand \n#independent-variable\n#dependant-variable\n#measured-variable\n#regression ",
    "tags": [
      "ML",
      "definition",
      "regressor",
      "regressand",
      "independent",
      "dependant",
      "measured",
      "regression"
    ],
    "htmlContent": "<p>Regressor - this is an independent variable, predictor. \nRegressand - dependant variable, measured variable, output variable.</p>\n<p>Single Variable Regressor assumes or expects that the predictors are independent of each other (i.e. weakly dependent) and are not multi-collinear.</p>\n<p>More: <a href=\"https://medium.com/@ranaprathap/learning-ml-with-andrew-part-1-linear-regression-with-a-single-variable-615f2d163b88\">https://medium.com/@ranaprathap/learning-ml-with-andrew-part-1-linear-regression-with-a-single-variable-615f2d163b88</a></p>\n<p>#ML \n#definition \n#regressor\n#regressand \n#independent-variable\n#dependant-variable\n#measured-variable\n#regression </p>\n"
  },
  {
    "title": "Solving problems using logic programming",
    "body": "**Logic programming** has many applications in AI, such as **expert systems**, **knowledge bases**, **natural language processing**, **computer vision**, and machine learning. For example, an expert system is a program that uses logic programming to encode the knowledge and rules of a domain expert, and to provide advice or solutions to users. A knowledge base is a collection of facts and rules that represent the knowledge of a domain, and that can be queried and updated using logic programming. Natural language processing is a field of AI that uses logic programming to analyze and generate natural language, such as parsing sentences, translating texts, or answering questions. Computer vision is a field of AI that uses logic programming to process and understand images, such as recognizing faces, detecting objects, or describing scenes. Machine learning is a field of AI that uses logic programming to learn from data, such as inducing rules, clustering data, or classifying data.\n\nLogic Programming uses facts and rules for solving the problem. That is why they are called the building blocks of Logic Programming. A goal needs to be specified for every program in logic programming. To understand how a problem can be solved in logic programming, we need to know about the building blocks − Facts and Rules.\n\nMore:\n* https://www.tutorialspoint.com/artificial_intelligence_with_python/artificial_intelligence_with_python_logic_programming.htm\n\n#AI \n#ML \n#knowledge-base\n#expert-system\n#logic-programming \n#nlp\n#definition \n#article ",
    "tags": [
      "AI",
      "ML",
      "knowledge",
      "expert",
      "logic",
      "nlp",
      "definition",
      "article"
    ],
    "htmlContent": "<p><strong>Logic programming</strong> has many applications in AI, such as <strong>expert systems</strong>, <strong>knowledge bases</strong>, <strong>natural language processing</strong>, <strong>computer vision</strong>, and machine learning. For example, an expert system is a program that uses logic programming to encode the knowledge and rules of a domain expert, and to provide advice or solutions to users. A knowledge base is a collection of facts and rules that represent the knowledge of a domain, and that can be queried and updated using logic programming. Natural language processing is a field of AI that uses logic programming to analyze and generate natural language, such as parsing sentences, translating texts, or answering questions. Computer vision is a field of AI that uses logic programming to process and understand images, such as recognizing faces, detecting objects, or describing scenes. Machine learning is a field of AI that uses logic programming to learn from data, such as inducing rules, clustering data, or classifying data.</p>\n<p>Logic Programming uses facts and rules for solving the problem. That is why they are called the building blocks of Logic Programming. A goal needs to be specified for every program in logic programming. To understand how a problem can be solved in logic programming, we need to know about the building blocks − Facts and Rules.</p>\n<p>More:</p>\n<ul>\n<li><a href=\"https://www.tutorialspoint.com/artificial_intelligence_with_python/artificial_intelligence_with_python_logic_programming.htm\">https://www.tutorialspoint.com/artificial_intelligence_with_python/artificial_intelligence_with_python_logic_programming.htm</a></li>\n</ul>\n<p>#AI \n#ML \n#knowledge-base\n#expert-system\n#logic-programming \n#nlp\n#definition \n#article </p>\n"
  },
  {
    "title": "Supervised vs Unsupervised learning",
    "body": "| Parameters               | Supervised machine learning                                                                                                                | Unsupervised machine learning                                                      |\n| ------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------- |\n| Input Data               | Algorithms are trained using labeled data.                                                                                                 | Algorithms are used against data that is not labeled                               |\n| Computational Complexity | Simpler method                                                                                                                             | Computationally complex                                                            |\n| Accuracy                 | Highly accurate                                                                                                                            | Less accurate                                                                      |\n| No. of classes           | No. of classes is known                                                                                                                    | No. of classes is not known                                                        |\n| Data Analysis            | Uses offline analysis                                                                                                                      | Uses real-time analysis of data                                                    |\n| Algorithms used          | Linear and Logistics regression,KNN Random forest, multi-class classification, decision tree, Support Vector Machine, Neural Network, etc. | K-Means clustering, Hierarchical clustering, Apriori algorithm, etc.               |\n| Output                   | Desired output is given.                                                                                                                   | Desired output is not given.                                                       |\n| Training data            | Use training data to infer model.                                                                                                          | No training data is used.                                                          |\n| Complex model            | It is not possible to learn larger and more complex models than with supervised learning.                                                  | It is possible to learn larger and more complex models with unsupervised learning. |\n| Model                    | We can test our model.                                                                                                                     | We can not test our model.                                                         |\n| Called as                | Supervised learning is also called classification.                                                                                         | Unsupervised learning is also called clustering.                                   |\n| Example                  | Example: Optical character recognition.                                                                                                    | Example: Find a face in an image.                                                  |\n| Supervision              | supervised learning needs supervision to train the model.                                                                                  | Unsupervised learning does not need any supervision to train the model.            |\nMore: https://www.geeksforgeeks.org/supervised-unsupervised-learning/\n\n#ML\n#article\n#supervised-ml\n#unsupervised-ml\n#ml-model \n",
    "tags": [
      "ML",
      "article",
      "supervised",
      "unsupervised",
      "ml"
    ],
    "htmlContent": "<table>\n<thead>\n<tr>\n<th>Parameters</th>\n<th>Supervised machine learning</th>\n<th>Unsupervised machine learning</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Input Data</td>\n<td>Algorithms are trained using labeled data.</td>\n<td>Algorithms are used against data that is not labeled</td>\n</tr>\n<tr>\n<td>Computational Complexity</td>\n<td>Simpler method</td>\n<td>Computationally complex</td>\n</tr>\n<tr>\n<td>Accuracy</td>\n<td>Highly accurate</td>\n<td>Less accurate</td>\n</tr>\n<tr>\n<td>No. of classes</td>\n<td>No. of classes is known</td>\n<td>No. of classes is not known</td>\n</tr>\n<tr>\n<td>Data Analysis</td>\n<td>Uses offline analysis</td>\n<td>Uses real-time analysis of data</td>\n</tr>\n<tr>\n<td>Algorithms used</td>\n<td>Linear and Logistics regression,KNN Random forest, multi-class classification, decision tree, Support Vector Machine, Neural Network, etc.</td>\n<td>K-Means clustering, Hierarchical clustering, Apriori algorithm, etc.</td>\n</tr>\n<tr>\n<td>Output</td>\n<td>Desired output is given.</td>\n<td>Desired output is not given.</td>\n</tr>\n<tr>\n<td>Training data</td>\n<td>Use training data to infer model.</td>\n<td>No training data is used.</td>\n</tr>\n<tr>\n<td>Complex model</td>\n<td>It is not possible to learn larger and more complex models than with supervised learning.</td>\n<td>It is possible to learn larger and more complex models with unsupervised learning.</td>\n</tr>\n<tr>\n<td>Model</td>\n<td>We can test our model.</td>\n<td>We can not test our model.</td>\n</tr>\n<tr>\n<td>Called as</td>\n<td>Supervised learning is also called classification.</td>\n<td>Unsupervised learning is also called clustering.</td>\n</tr>\n<tr>\n<td>Example</td>\n<td>Example: Optical character recognition.</td>\n<td>Example: Find a face in an image.</td>\n</tr>\n<tr>\n<td>Supervision</td>\n<td>supervised learning needs supervision to train the model.</td>\n<td>Unsupervised learning does not need any supervision to train the model.</td>\n</tr>\n<tr>\n<td>More: <a href=\"https://www.geeksforgeeks.org/supervised-unsupervised-learning/\">https://www.geeksforgeeks.org/supervised-unsupervised-learning/</a></td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<p>#ML\n#article\n#supervised-ml\n#unsupervised-ml\n#ml-model </p>\n"
  },
  {
    "title": "Support Vector Machines",
    "body": "A support vector machine (SVM) is a supervised machine learning algorithm that classifies data by finding an optimal line or hyperplane that maximizes the distance between each class in an N-dimensional space.\n\n![[Pasted image 20240915135426.png]]\n\nSupport vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection.\n\nBased on the training sets, SVM are basically of two types-\n\n1. Linear SVM – _Data points can be easily separated with a linear line._\n2. Non-Linear SVM – _Data points cannot be easily separated with a linear line_.\n\nMore: https://www.geeksforgeeks.org/support-vector-machine-algorithm/\n\n#ML \n#definition \n#supervised-ml \n#svm\n#support-vector-machines\n#ml-model ",
    "tags": [
      "ML",
      "definition",
      "supervised",
      "svm",
      "support",
      "ml"
    ],
    "htmlContent": "<p>A support vector machine (SVM) is a supervised machine learning algorithm that classifies data by finding an optimal line or hyperplane that maximizes the distance between each class in an N-dimensional space.</p>\n<p>![[Pasted image 20240915135426.png]]</p>\n<p>Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection.</p>\n<p>Based on the training sets, SVM are basically of two types-</p>\n<ol>\n<li>Linear SVM – <em>Data points can be easily separated with a linear line.</em></li>\n<li>Non-Linear SVM – <em>Data points cannot be easily separated with a linear line</em>.</li>\n</ol>\n<p>More: <a href=\"https://www.geeksforgeeks.org/support-vector-machine-algorithm/\">https://www.geeksforgeeks.org/support-vector-machine-algorithm/</a></p>\n<p>#ML \n#definition \n#supervised-ml \n#svm\n#support-vector-machines\n#ml-model </p>\n"
  },
  {
    "title": "Turing Test",
    "body": "The Turing Test is a deceptively simple method of determining whether a machine can demonstrate human intelligence: If a machine can engage in a conversation with a human without being detected as a machine, it has demonstrated human intelligence.\n\n#AI \n#definition \n#turing-test\n\n",
    "tags": [
      "AI",
      "definition",
      "turing"
    ],
    "htmlContent": "<p>The Turing Test is a deceptively simple method of determining whether a machine can demonstrate human intelligence: If a machine can engage in a conversation with a human without being detected as a machine, it has demonstrated human intelligence.</p>\n<p>#AI \n#definition \n#turing-test</p>\n"
  },
  {
    "title": "Types of layers in a CNN",
    "body": "### Example CNN Architecture\n\nHere’s an example of a simple CNN architecture:\n\n1. **Input Layer**: 32x32x3 (RGB image)\n2. **Convolutional Layer 1**: 32 filters of size 3x3, stride 1, padding 1\n   - Output: 32x32x32\n3. **Activation Layer 1**: ReLU\n   - Output: 32x32x32\n4. **Pooling Layer 1**: Max pooling with 2x2 window, stride 2\n   - Output: 16x16x32\n5. **Convolutional Layer 2**: 64 filters of size 3x3, stride 1, padding 1\n   - Output: 16x16x64\n6. **Activation Layer 2**: ReLU\n   - Output: 16x16x64\n7. **Pooling Layer 2**: Max pooling with 2x2 window, stride 2\n   - Output: 8x8x64\n8. **Fully Connected Layer**: 128 neurons\n   - Output: 128-dimensional vector\n9. **Output Layer**: Softmax activation for classification\n   - Output: Vector of class probabilities (e.g., 10 for a 10-class problem)\n\n### Key Considerations\n\n- **Convolutional Filters**: Learn spatial hierarchies and detect patterns from the data.\n- **Activation Functions**: Introduce non-linearity, allowing the network to learn complex patterns.\n- **Pooling Layers**: Reduce computational complexity and enhance the network’s ability to generalize by reducing spatial dimensions.\n- **Fully Connected Layers**: Integrate features learned by convolutional layers for final predictions.\n\nThe architecture of CNNs can vary greatly depending on the complexity of the task and the dataset, with deeper networks having more convolutional and pooling layers, and sometimes additional components like normalization layers or dropout layers to improve performance.\n\n#AI \n#CNN\n#CNN-layers\n#definition \n#article ",
    "tags": [
      "**Convolutional Filters**: Learn spatial hierarchies and detect patterns from the data.",
      "**Activation Functions**: Introduce non",
      "linearity, allowing the network to learn complex patterns.",
      "**Pooling Layers**: Reduce computational complexity and enhance the network’s ability to generalize by reducing spatial dimensions.",
      "**Fully Connected Layers**: Integrate features learned by convolutional layers for final predictions.",
      "AI",
      "CNN",
      "definition",
      "article"
    ],
    "htmlContent": "<h3>Example CNN Architecture</h3>\n<p>Here’s an example of a simple CNN architecture:</p>\n<ol>\n<li><strong>Input Layer</strong>: 32x32x3 (RGB image)</li>\n<li><strong>Convolutional Layer 1</strong>: 32 filters of size 3x3, stride 1, padding 1<ul>\n<li>Output: 32x32x32</li>\n</ul>\n</li>\n<li><strong>Activation Layer 1</strong>: ReLU<ul>\n<li>Output: 32x32x32</li>\n</ul>\n</li>\n<li><strong>Pooling Layer 1</strong>: Max pooling with 2x2 window, stride 2<ul>\n<li>Output: 16x16x32</li>\n</ul>\n</li>\n<li><strong>Convolutional Layer 2</strong>: 64 filters of size 3x3, stride 1, padding 1<ul>\n<li>Output: 16x16x64</li>\n</ul>\n</li>\n<li><strong>Activation Layer 2</strong>: ReLU<ul>\n<li>Output: 16x16x64</li>\n</ul>\n</li>\n<li><strong>Pooling Layer 2</strong>: Max pooling with 2x2 window, stride 2<ul>\n<li>Output: 8x8x64</li>\n</ul>\n</li>\n<li><strong>Fully Connected Layer</strong>: 128 neurons<ul>\n<li>Output: 128-dimensional vector</li>\n</ul>\n</li>\n<li><strong>Output Layer</strong>: Softmax activation for classification<ul>\n<li>Output: Vector of class probabilities (e.g., 10 for a 10-class problem)</li>\n</ul>\n</li>\n</ol>\n<h3>Key Considerations</h3>\n<ul>\n<li><strong>Convolutional Filters</strong>: Learn spatial hierarchies and detect patterns from the data.</li>\n<li><strong>Activation Functions</strong>: Introduce non-linearity, allowing the network to learn complex patterns.</li>\n<li><strong>Pooling Layers</strong>: Reduce computational complexity and enhance the network’s ability to generalize by reducing spatial dimensions.</li>\n<li><strong>Fully Connected Layers</strong>: Integrate features learned by convolutional layers for final predictions.</li>\n</ul>\n<p>The architecture of CNNs can vary greatly depending on the complexity of the task and the dataset, with deeper networks having more convolutional and pooling layers, and sometimes additional components like normalization layers or dropout layers to improve performance.</p>\n<p>#AI \n#CNN\n#CNN-layers\n#definition \n#article </p>\n"
  },
  {
    "title": "Understanding building blocks of logic programming",
    "body": "Logic Programming is the combination of two words, logic and programming. Logic Programming is a programming paradigm in which the problems are expressed as facts and rules by program statements but within a system of formal logic. Just like other programming paradigms like object oriented, functional, declarative, and procedural, etc., it is also a particular way to approach programming.\n\nLogic Learning Machines (LLMs) are machine learning models that use logic-based representations and reasoning to learn from data.\n\nLLMs are often used in applications where the data is naturally represented in a symbolic or logical form, such as natural language processing, knowledge representation, and expert systems. They are also useful in domains where the data is noisy or incomplete, as they can reason with uncertain or incomplete information and generate more robust models.\n\nMore:\n* https://induraj2020.medium.com/logic-learning-machine-ai-gets-a-step-closer-to-the-human-brain-5454b3026900\n* https://induraj2020.medium.com/what-are-large-language-models-llms-and-their-uses-ccfdee4ce386\n#ML \n#LLM\n#logic-programming \n#definition \n#article ",
    "tags": [
      "ML",
      "LLM",
      "logic",
      "definition",
      "article"
    ],
    "htmlContent": "<p>Logic Programming is the combination of two words, logic and programming. Logic Programming is a programming paradigm in which the problems are expressed as facts and rules by program statements but within a system of formal logic. Just like other programming paradigms like object oriented, functional, declarative, and procedural, etc., it is also a particular way to approach programming.</p>\n<p>Logic Learning Machines (LLMs) are machine learning models that use logic-based representations and reasoning to learn from data.</p>\n<p>LLMs are often used in applications where the data is naturally represented in a symbolic or logical form, such as natural language processing, knowledge representation, and expert systems. They are also useful in domains where the data is noisy or incomplete, as they can reason with uncertain or incomplete information and generate more robust models.</p>\n<p>More:</p>\n<ul>\n<li><a href=\"https://induraj2020.medium.com/logic-learning-machine-ai-gets-a-step-closer-to-the-human-brain-5454b3026900\">https://induraj2020.medium.com/logic-learning-machine-ai-gets-a-step-closer-to-the-human-brain-5454b3026900</a></li>\n<li><a href=\"https://induraj2020.medium.com/what-are-large-language-models-llms-and-their-uses-ccfdee4ce386\">https://induraj2020.medium.com/what-are-large-language-models-llms-and-their-uses-ccfdee4ce386</a></li>\n</ul>\n<p>#ML \n#LLM\n#logic-programming \n#definition \n#article </p>\n"
  },
  {
    "title": "Understanding the premise",
    "body": "\nReinforcement learning (RL) is an interdisciplinary area of machine learning and optimal control concerned with how an intelligent agent ought to take actions in a dynamic environment in order to maximize the cumulative reward. Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning.\n\nReinforcement learning (RL) is a machine learning (ML) technique that trains software to make decisions to achieve the most optimal results. It mimics the trial-and-error learning process that humans use to achieve their goals. Software actions that work towards your goal are reinforced, while actions that detract from the goal are ignored. \n\nRL algorithms use a reward-and-punishment paradigm as they process data. They learn from the feedback of each action and self-discover the best processing paths to achieve final outcomes. The algorithms are also capable of delayed gratification. The best overall strategy may require short-term sacrifices, so the best approach they discover may include some punishments or backtracking along the way. RL is a powerful method to help artificial intelligence (AI) systems achieve optimal outcomes in unseen environments.\n\n#AI \n#ML \n#ml-paradigm\n#reinforcement-learning\n#definition \n#article ",
    "tags": [
      "AI",
      "ML",
      "ml",
      "reinforcement",
      "definition",
      "article"
    ],
    "htmlContent": "<p>Reinforcement learning (RL) is an interdisciplinary area of machine learning and optimal control concerned with how an intelligent agent ought to take actions in a dynamic environment in order to maximize the cumulative reward. Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning.</p>\n<p>Reinforcement learning (RL) is a machine learning (ML) technique that trains software to make decisions to achieve the most optimal results. It mimics the trial-and-error learning process that humans use to achieve their goals. Software actions that work towards your goal are reinforced, while actions that detract from the goal are ignored. </p>\n<p>RL algorithms use a reward-and-punishment paradigm as they process data. They learn from the feedback of each action and self-discover the best processing paths to achieve final outcomes. The algorithms are also capable of delayed gratification. The best overall strategy may require short-term sacrifices, so the best approach they discover may include some punishments or backtracking along the way. RL is a powerful method to help artificial intelligence (AI) systems achieve optimal outcomes in unseen environments.</p>\n<p>#AI \n#ML \n#ml-paradigm\n#reinforcement-learning\n#definition \n#article </p>\n"
  },
  {
    "title": "Uninformed vs Informed search",
    "body": "The process of searching in Artificial Intelligence (AI) is a sequence of steps that the AI uses to identify the solution to a given problem. There are two primary types of searches: informed and uninformed. The main difference between the two lies in the amount of information each one utilizes. An informed search provides the AI with guidance on how and where to look for the solution to the problem. On the other hand, an uninformed search only provides the AI with the problem’s specifications and no additional information about the potential solution. Between the two, an informed search is generally more efficient and cost-effective.\n\n| Parameters                 | Informed Search                                                                                                                                | Uninformed Search                                                                                                       |\n| -------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------- |\n| Known as                   | It is also known as Heuristic Search.                                                                                                          | It is also known as Blind Search.                                                                                       |\n| Using Knowledge            | It uses knowledge for the searching process.                                                                                                   | It doesn’t use knowledge for the searching process.                                                                     |\n| Performance                | It finds a solution more quickly.                                                                                                              | It finds solution slow as compared to an informed search.                                                               |\n| Completion                 | It may or may not be complete.                                                                                                                 | It is always complete.                                                                                                  |\n| Cost Factor                | Cost is low.                                                                                                                                   | Cost is high.                                                                                                           |\n| Time                       | It consumes less time because of quick searching.                                                                                              | It consumes moderate time because of slow searching.                                                                    |\n| Direction                  | There is a direction given about the solution.                                                                                                 | No suggestion is given regarding the solution in it.                                                                    |\n| Implementation             | It is less lengthy while implemented.                                                                                                          | It is more lengthy while implemented.                                                                                   |\n| Efficiency                 | It is more efficient as efficiency takes into account cost and performance. The incurred cost is less and speed of finding solutions is quick. | It is comparatively less efficient as incurred cost is more and the speed of finding the Breadth-Firstsolution is slow. |\n| Computational requirements | Computational requirements are lessened.                                                                                                       | Comparatively higher computational requirements.                                                                        |\n| Size of search problems    | Having a wide scope in terms of handling large search problems.                                                                                | Solving a massive search task is challenging.                                                                           |\n| Examples of Algorithms     | - Greedy Search<br>- A* Search<br>- AO* Search<br>- Hill Climbing Algorithm                                                                    | - Depth First Search (DFS)<br>- Breadth First Search (BFS)<br>- Branch and Bound                                        |\n\n\nMore:\n* https://www.baeldung.com/cs/informed-vs-uninformed-search\n\n#AI \n#ML \n#uninformed-search\n#informed-search\n#definition \n#article \n",
    "tags": [
      "AI",
      "ML",
      "uninformed",
      "informed",
      "definition",
      "article"
    ],
    "htmlContent": "<p>The process of searching in Artificial Intelligence (AI) is a sequence of steps that the AI uses to identify the solution to a given problem. There are two primary types of searches: informed and uninformed. The main difference between the two lies in the amount of information each one utilizes. An informed search provides the AI with guidance on how and where to look for the solution to the problem. On the other hand, an uninformed search only provides the AI with the problem’s specifications and no additional information about the potential solution. Between the two, an informed search is generally more efficient and cost-effective.</p>\n<table>\n<thead>\n<tr>\n<th>Parameters</th>\n<th>Informed Search</th>\n<th>Uninformed Search</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Known as</td>\n<td>It is also known as Heuristic Search.</td>\n<td>It is also known as Blind Search.</td>\n</tr>\n<tr>\n<td>Using Knowledge</td>\n<td>It uses knowledge for the searching process.</td>\n<td>It doesn’t use knowledge for the searching process.</td>\n</tr>\n<tr>\n<td>Performance</td>\n<td>It finds a solution more quickly.</td>\n<td>It finds solution slow as compared to an informed search.</td>\n</tr>\n<tr>\n<td>Completion</td>\n<td>It may or may not be complete.</td>\n<td>It is always complete.</td>\n</tr>\n<tr>\n<td>Cost Factor</td>\n<td>Cost is low.</td>\n<td>Cost is high.</td>\n</tr>\n<tr>\n<td>Time</td>\n<td>It consumes less time because of quick searching.</td>\n<td>It consumes moderate time because of slow searching.</td>\n</tr>\n<tr>\n<td>Direction</td>\n<td>There is a direction given about the solution.</td>\n<td>No suggestion is given regarding the solution in it.</td>\n</tr>\n<tr>\n<td>Implementation</td>\n<td>It is less lengthy while implemented.</td>\n<td>It is more lengthy while implemented.</td>\n</tr>\n<tr>\n<td>Efficiency</td>\n<td>It is more efficient as efficiency takes into account cost and performance. The incurred cost is less and speed of finding solutions is quick.</td>\n<td>It is comparatively less efficient as incurred cost is more and the speed of finding the Breadth-Firstsolution is slow.</td>\n</tr>\n<tr>\n<td>Computational requirements</td>\n<td>Computational requirements are lessened.</td>\n<td>Comparatively higher computational requirements.</td>\n</tr>\n<tr>\n<td>Size of search problems</td>\n<td>Having a wide scope in terms of handling large search problems.</td>\n<td>Solving a massive search task is challenging.</td>\n</tr>\n<tr>\n<td>Examples of Algorithms</td>\n<td>- Greedy Search<br>- A* Search<br>- AO* Search<br>- Hill Climbing Algorithm</td>\n<td>- Depth First Search (DFS)<br>- Breadth First Search (BFS)<br>- Branch and Bound</td>\n</tr>\n</tbody></table>\n<p>More:</p>\n<ul>\n<li><a href=\"https://www.baeldung.com/cs/informed-vs-uninformed-search\">https://www.baeldung.com/cs/informed-vs-uninformed-search</a></li>\n</ul>\n<p>#AI \n#ML \n#uninformed-search\n#informed-search\n#definition \n#article </p>\n"
  },
  {
    "title": "Unsupervised Learning",
    "body": "Unsupervised learning, also known as unsupervised machine learning, uses machine learning (ML) algorithms to analyze and cluster unlabeled data sets. These algorithms discover hidden patterns or data groupings without the need for human intervention.\n\nUnsupervised learning's ability to discover similarities and differences in information make it the ideal solution for exploratory data analysis, cross-selling strategies, customer segmentation and image recognition.\n\nMore: \n* https://cloud.google.com/discover/what-is-unsupervised-learning?hl=en\n* https://www.ibm.com/topics/unsupervised-learning \n\n#ML \n#definition \n#unsupervised-ml ",
    "tags": [
      "ML",
      "definition",
      "unsupervised"
    ],
    "htmlContent": "<p>Unsupervised learning, also known as unsupervised machine learning, uses machine learning (ML) algorithms to analyze and cluster unlabeled data sets. These algorithms discover hidden patterns or data groupings without the need for human intervention.</p>\n<p>Unsupervised learning&#39;s ability to discover similarities and differences in information make it the ideal solution for exploratory data analysis, cross-selling strategies, customer segmentation and image recognition.</p>\n<p>More: </p>\n<ul>\n<li><a href=\"https://cloud.google.com/discover/what-is-unsupervised-learning?hl=en\">https://cloud.google.com/discover/what-is-unsupervised-learning?hl=en</a></li>\n<li><a href=\"https://www.ibm.com/topics/unsupervised-learning\">https://www.ibm.com/topics/unsupervised-learning</a></li>\n</ul>\n<p>#ML \n#definition \n#unsupervised-ml </p>\n"
  },
  {
    "title": "Validating primes",
    "body": "A prime number is a whole number greater than 1 that is divisible only by 1 and itself.\n\nMore:\n* https://www.geeksforgeeks.org/prime-numbers/\n* https://www.programminglogic.com/testing-if-a-number-is-prime-efficiently/\n* https://s-arash.github.io/ascent/\n\n#AI \n#definition \n#prime-number",
    "tags": [
      "AI",
      "definition",
      "prime"
    ],
    "htmlContent": "<p>A prime number is a whole number greater than 1 that is divisible only by 1 and itself.</p>\n<p>More:</p>\n<ul>\n<li><a href=\"https://www.geeksforgeeks.org/prime-numbers/\">https://www.geeksforgeeks.org/prime-numbers/</a></li>\n<li><a href=\"https://www.programminglogic.com/testing-if-a-number-is-prime-efficiently/\">https://www.programminglogic.com/testing-if-a-number-is-prime-efficiently/</a></li>\n<li><a href=\"https://s-arash.github.io/ascent/\">https://s-arash.github.io/ascent/</a></li>\n</ul>\n<p>#AI \n#definition \n#prime-number</p>\n"
  },
  {
    "title": "What is AI?",
    "body": "![[Pasted image 20240914214657.png]]\nArtificial intelligence is a field of science concerned with building computers and machines that can reason, learn, and act in such a way that would normally require human intelligence or that involves data whose scale exceeds what humans can analyze. \n\nAI is a broad field that encompasses many different disciplines, including computer science, data analytics and statistics, hardware and software engineering, linguistics, neuroscience, and even philosophy and psychology. \n\nOn an operational level for business use, AI is a set of technologies that are based primarily on machine learning and deep learning, used for data analytics, predictions and forecasting, object categorization, natural language processing, recommendations, intelligent data retrieval, and more.\n\nFour stages of AI development are commonly recognized:\n\n1. **Reactive machines:** Limited AI that only reacts to different kinds of stimuli based on preprogrammed rules. Does not use memory and thus cannot learn with new data. IBM’s Deep Blue that beat chess champion Garry Kasparov in 1997 was an example of a reactive machine.\n2. **Limited memory:** Most modern AI is considered to be limited memory. It can use memory to improve over time by being trained with new data, typically through an artificial neural network or other training model. Deep learning, a subset of machine learning, is considered limited memory artificial intelligence.\n3. **Theory of mind:** Theory of mind AI does not currently exist, but research is ongoing into its possibilities. It describes AI that can emulate the human mind and has decision-making capabilities equal to that of a human, including recognizing and remembering emotions and reacting in social situations as a human would. \n4. **Self aware:** A step above theory of mind AI, self-aware AI describes a mythical machine that is aware of its own existence and has the intellectual and emotional capabilities of a human. Like theory of mind AI, self-aware AI does not currently exist.\n\n## Goals of Artificial Intelligence\n\nFollowing are the main goals of Artificial Intelligence:\n\n1. Replicate human intelligence\n2. Solve Knowledge-intensive tasks\n3. An intelligent connection of perception and action\n4. Building a machine which can perform tasks that requires human intelligence such as:\n    - Proving a theorem\n    - Playing chess\n    - Plan some surgical operation\n    - Driving a car in traffic\n5. Creating some system which can exhibit intelligent behavior, learn new things by itself, demonstrate, explain, and can advise to its user.\n\n#AI\n#definition\n#article\n\n",
    "tags": [
      "AI",
      "definition",
      "article"
    ],
    "htmlContent": "<p>![[Pasted image 20240914214657.png]]\nArtificial intelligence is a field of science concerned with building computers and machines that can reason, learn, and act in such a way that would normally require human intelligence or that involves data whose scale exceeds what humans can analyze. </p>\n<p>AI is a broad field that encompasses many different disciplines, including computer science, data analytics and statistics, hardware and software engineering, linguistics, neuroscience, and even philosophy and psychology. </p>\n<p>On an operational level for business use, AI is a set of technologies that are based primarily on machine learning and deep learning, used for data analytics, predictions and forecasting, object categorization, natural language processing, recommendations, intelligent data retrieval, and more.</p>\n<p>Four stages of AI development are commonly recognized:</p>\n<ol>\n<li><strong>Reactive machines:</strong> Limited AI that only reacts to different kinds of stimuli based on preprogrammed rules. Does not use memory and thus cannot learn with new data. IBM’s Deep Blue that beat chess champion Garry Kasparov in 1997 was an example of a reactive machine.</li>\n<li><strong>Limited memory:</strong> Most modern AI is considered to be limited memory. It can use memory to improve over time by being trained with new data, typically through an artificial neural network or other training model. Deep learning, a subset of machine learning, is considered limited memory artificial intelligence.</li>\n<li><strong>Theory of mind:</strong> Theory of mind AI does not currently exist, but research is ongoing into its possibilities. It describes AI that can emulate the human mind and has decision-making capabilities equal to that of a human, including recognizing and remembering emotions and reacting in social situations as a human would. </li>\n<li><strong>Self aware:</strong> A step above theory of mind AI, self-aware AI describes a mythical machine that is aware of its own existence and has the intellectual and emotional capabilities of a human. Like theory of mind AI, self-aware AI does not currently exist.</li>\n</ol>\n<h2>Goals of Artificial Intelligence</h2>\n<p>Following are the main goals of Artificial Intelligence:</p>\n<ol>\n<li>Replicate human intelligence</li>\n<li>Solve Knowledge-intensive tasks</li>\n<li>An intelligent connection of perception and action</li>\n<li>Building a machine which can perform tasks that requires human intelligence such as:<ul>\n<li>Proving a theorem</li>\n<li>Playing chess</li>\n<li>Plan some surgical operation</li>\n<li>Driving a car in traffic</li>\n</ul>\n</li>\n<li>Creating some system which can exhibit intelligent behavior, learn new things by itself, demonstrate, explain, and can advise to its user.</li>\n</ol>\n<p>#AI\n#definition\n#article</p>\n"
  }
]